{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial:CITE-seq (well-labeled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will show how to cluster CITE-seq data using scMAGCA. As an example, we use a human peripheral blood sample dataset '10Xkpbmc' containing 713 cells. It contains two omics data, with ADT containing 17 features and RNA containing 33,538 features, and is well-labeled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scMAGCA import *\n",
    "from preprocess import *\n",
    "\n",
    "from preprocess import read_dataset, preprocess_dataset\n",
    "from utils import *\n",
    "from scMAGCA import scMultiCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "random.seed(3407)\n",
    "np.random.seed(3407)\n",
    "torch.manual_seed(3407)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CITE-seq dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The required input files include: \n",
    "1) x1: protein abundance matrix (data format is h5ad file) : 10x1kpbmc_adt.h5ad; \\\n",
    "2) x2: Gene expression matrix (data format is h5ad file) : 10x1kpbmc_rna.h5ad; \\\n",
    "3) Real label (stored as csv file) : 10x1kpbmc_label.csv.\n",
    "\n",
    "To ensure reproducibility of the results, please read the above data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.array(sc.read_h5ad('../datasets/10x1kpbmc/10x1kpbmc_adt.h5ad').to_df()).astype('float32')\n",
    "x2 = np.array(sc.read_h5ad('../datasets/10x1kpbmc/10x1kpbmc_rna.h5ad').to_df()).astype('float32')\n",
    "y = np.array(pd.read_csv('../datasets/10x1kpbmc/10x1kpbmc_label.csv')['Cluster']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[3.000e+00, 6.000e+00, 2.000e+00, ..., 3.000e+00, 4.000e+00,\n",
       "         1.000e+00],\n",
       "        [3.444e+03, 3.995e+03, 4.900e+01, ..., 6.000e+00, 8.000e+00,\n",
       "         2.000e+00],\n",
       "        [1.733e+03, 3.401e+03, 2.300e+01, ..., 1.000e+00, 6.000e+00,\n",
       "         0.000e+00],\n",
       "        ...,\n",
       "        [3.000e+00, 1.190e+02, 1.800e+01, ..., 1.000e+00, 1.000e+00,\n",
       "         2.000e+00],\n",
       "        [1.700e+01, 8.190e+02, 1.100e+01, ..., 3.000e+00, 2.000e+00,\n",
       "         2.000e+00],\n",
       "        [9.000e+00, 1.300e+01, 1.000e+01, ..., 4.000e+00, 1.100e+01,\n",
       "         5.000e+00]], dtype=float32),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n",
       " array([5., 1., 1., 1., 1., 3., 3., 3., 1., 1., 3., 1., 1., 1., 5., 3., 3.,\n",
       "        3., 3., 2., 3., 1., 2., 1., 3., 4., 2., 5., 1., 1., 2., 5., 1., 4.,\n",
       "        2., 1., 3., 5., 2., 4., 1., 1., 3., 1., 1., 5., 1., 1., 1., 5., 5.,\n",
       "        2., 4., 1., 3., 3., 1., 4., 2., 5., 2., 1., 1., 1., 5., 1., 3., 2.,\n",
       "        3., 4., 2., 1., 2., 4., 3., 1., 3., 1., 1., 1., 1., 3., 4., 4., 2.,\n",
       "        4., 2., 3., 5., 5., 2., 4., 3., 4., 1., 1., 5., 2., 1., 1., 2., 1.,\n",
       "        1., 3., 1., 4., 1., 4., 1., 3., 4., 2., 5., 1., 1., 4., 1., 4., 2.,\n",
       "        5., 4., 4., 4., 2., 1., 5., 2., 1., 1., 3., 2., 2., 1., 1., 4., 3.,\n",
       "        4., 1., 4., 3., 1., 2., 1., 1., 5., 1., 3., 3., 3., 3., 5., 4., 3.,\n",
       "        4., 1., 1., 1., 2., 3., 3., 3., 2., 2., 1., 4., 3., 3., 4., 4., 4.,\n",
       "        1., 4., 1., 3., 5., 3., 5., 2., 3., 5., 1., 1., 2., 1., 3., 1., 2.,\n",
       "        1., 1., 5., 4., 4., 4., 2., 2., 5., 1., 2., 2., 2., 5., 2., 2., 1.,\n",
       "        2., 4., 3., 4., 1., 4., 3., 4., 1., 4., 3., 3., 2., 1., 2., 3., 4.,\n",
       "        3., 1., 2., 2., 2., 3., 4., 3., 5., 1., 2., 2., 3., 1., 2., 1., 4.,\n",
       "        5., 4., 2., 5., 1., 5., 2., 2., 3., 1., 1., 1., 1., 4., 5., 3., 4.,\n",
       "        3., 3., 4., 4., 1., 1., 1., 1., 4., 2., 1., 1., 1., 1., 3., 2., 2.,\n",
       "        1., 3., 2., 1., 4., 4., 4., 4., 2., 4., 3., 2., 1., 1., 5., 4., 1.,\n",
       "        2., 1., 2., 2., 1., 4., 1., 4., 1., 1., 3., 1., 4., 3., 1., 5., 2.,\n",
       "        3., 2., 1., 2., 2., 1., 4., 4., 1., 2., 2., 5., 1., 2., 1., 1., 3.,\n",
       "        2., 1., 1., 1., 4., 2., 2., 4., 4., 4., 4., 4., 4., 1., 2., 4., 3.,\n",
       "        4., 4., 2., 3., 4., 4., 1., 2., 1., 1., 1., 1., 5., 3., 2., 3., 1.,\n",
       "        1., 5., 3., 4., 1., 1., 3., 5., 2., 1., 5., 2., 1., 2., 3., 1., 1.,\n",
       "        1., 4., 3., 3., 2., 1., 3., 4., 2., 3., 1., 3., 1., 2., 2., 4., 1.,\n",
       "        3., 3., 4., 1., 1., 1., 1., 1., 5., 2., 1., 5., 5., 1., 3., 2., 1.,\n",
       "        1., 4., 4., 4., 3., 2., 5., 1., 3., 1., 1., 2., 2., 1., 1., 4., 3.,\n",
       "        1., 5., 5., 1., 4., 4., 1., 2., 1., 2., 2., 3., 1., 1., 2., 1., 1.,\n",
       "        5., 4., 5., 3., 4., 5., 1., 2., 1., 2., 5., 4., 3., 3., 1., 1., 3.,\n",
       "        1., 2., 5., 1., 3., 2., 5., 1., 3., 2., 1., 2., 5., 2., 1., 2., 1.,\n",
       "        1., 2., 3., 1., 2., 3., 2., 2., 2., 5., 1., 4., 5., 1., 3., 4., 5.,\n",
       "        4., 2., 1., 1., 1., 2., 5., 2., 3., 4., 4., 5., 1., 2., 1., 2., 1.,\n",
       "        4., 5., 5., 1., 3., 5., 3., 1., 2., 1., 4., 1., 1., 5., 5., 2., 4.,\n",
       "        2., 1., 4., 2., 3., 4., 3., 4., 3., 2., 5., 4., 1., 3., 3., 3., 2.,\n",
       "        2., 3., 1., 1., 1., 1., 2., 1., 4., 2., 3., 3., 1., 2., 4., 2., 4.,\n",
       "        2., 1., 4., 4., 1., 1., 2., 5., 3., 1., 1., 3., 2., 4., 1., 4., 2.,\n",
       "        1., 4., 4., 2., 4., 1., 4., 4., 1., 5., 4., 2., 3., 1., 5., 1., 4.,\n",
       "        2., 1., 1., 1., 3., 5., 3., 2., 3., 1., 1., 2., 5., 4., 1., 3., 4.,\n",
       "        4., 1., 2., 4., 2., 5., 1., 3., 3., 3., 3., 2., 1., 4., 2., 2., 3.,\n",
       "        5., 3., 1., 1., 3., 5., 2., 5., 4., 3., 4., 1., 2., 1., 2., 5., 2.,\n",
       "        5., 3., 1., 3., 1., 1., 1., 2., 4., 2., 1., 4., 2., 2., 3., 1., 3.,\n",
       "        1., 3., 2., 1., 3., 5., 5., 4., 2., 3., 2., 5., 3., 1., 2., 4., 1.,\n",
       "        3., 2., 3., 1., 4., 1., 4., 2., 2., 2., 1., 1., 2., 5., 1., 1., 2.,\n",
       "        2., 1., 5., 5., 5., 1., 3., 2., 1., 1., 4., 1., 2., 4., 3., 5.],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1,x2,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the small number of features in ADT omics data and the large gap between the feature dimensions of RNA omics, for CITE-seq data, we only select high-expression features for RNA omics (the default number of chosen genes is 2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen offset: 0.21\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x252 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importantGenes = geneSelection(x2, n=2000)\n",
    "x2 = x2[:, importantGenes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Autoencoder: Successfully preprocessed 17 features and 713 cells.\n"
     ]
    }
   ],
   "source": [
    "adata1 = sc.AnnData(x1)\n",
    "adata1 = read_dataset(adata1, copy=True)\n",
    "adata1 = preprocess_dataset(adata1, normalize_input=True, logtrans_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 713 × 17\n",
       "    obs: 'DCA_split', 'size_factors'\n",
       "    var: 'mean', 'std'\n",
       "    uns: 'log1p'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Autoencoder: Successfully preprocessed 1999 features and 713 cells.\n"
     ]
    }
   ],
   "source": [
    "adata2 = sc.AnnData(x2)\n",
    "adata2 = read_dataset(adata2, copy=True)\n",
    "adata2 = preprocess_dataset(adata2, normalize_input=True, logtrans_input=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 713 × 1999\n",
       "    obs: 'DCA_split', 'size_factors'\n",
       "    var: 'mean', 'std'\n",
       "    uns: 'log1p'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model training is divided into two stages: pre-training stage and formal training stage. The number of epochs in the pre-training phase is set to 400, while the number in the formal training is 2000. In formal training, if the change in training results reaches a set threshold, it will end early. <br>\n",
    "\n",
    "After the training, the potential representations and predicted label values obtained by scMAGCA are saved to the corresponding folder of the data set and can be used for subsequent downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = scMultiCluster(input_dim1=adata1.n_vars, input_dim2=adata2.n_vars, device='cuda').to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scMultiCluster(\n",
       "  (encoder): Encoder(\n",
       "    (stacked_gnn): ModuleList(\n",
       "      (0): GCNConv(2016, 1024)\n",
       "      (1): GCNConv(1024, 256)\n",
       "      (2): GCNConv(256, 64)\n",
       "      (3): GCNConv(64, 32)\n",
       "    )\n",
       "    (stacked_bns): ModuleList(\n",
       "      (0): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (1): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): BatchNorm1d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (3): BatchNorm1d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (stacked_prelus): ModuleList(\n",
       "      (0-3): 4 x PReLU(num_parameters=1)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=512, bias=True)\n",
       "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): PReLU(num_parameters=1)\n",
       "    (3): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): PReLU(num_parameters=1)\n",
       "    (6): Linear(in_features=1024, out_features=2016, bias=True)\n",
       "  )\n",
       "  (dec_mean): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=2016, bias=True)\n",
       "    (3): MeanAct()\n",
       "  )\n",
       "  (dec_disp): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=2016, bias=True)\n",
       "    (3): DispAct()\n",
       "  )\n",
       "  (dec_pi): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=2016, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (zinb_loss): ZINBLoss()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining stage\n",
      "Pretrain epoch 1, recon_loss:1.179670, zinb_loss:3.310244, adversial_loss:1.358601\n",
      "Pretrain epoch 2, recon_loss:1.053315, zinb_loss:2.773893, adversial_loss:1.373735\n",
      "Pretrain epoch 3, recon_loss:0.862565, zinb_loss:2.396230, adversial_loss:1.360926\n",
      "Pretrain epoch 4, recon_loss:0.777968, zinb_loss:2.083947, adversial_loss:1.360451\n",
      "Pretrain epoch 5, recon_loss:0.754381, zinb_loss:1.846060, adversial_loss:1.360216\n",
      "Pretrain epoch 6, recon_loss:0.733581, zinb_loss:1.646314, adversial_loss:1.355564\n",
      "Pretrain epoch 7, recon_loss:0.721840, zinb_loss:1.484166, adversial_loss:1.350406\n",
      "Pretrain epoch 8, recon_loss:0.717826, zinb_loss:1.361452, adversial_loss:1.347699\n",
      "Pretrain epoch 9, recon_loss:0.708908, zinb_loss:1.277065, adversial_loss:1.346102\n",
      "Pretrain epoch 10, recon_loss:0.694630, zinb_loss:1.224692, adversial_loss:1.344238\n",
      "Pretrain epoch 11, recon_loss:0.684225, zinb_loss:1.194159, adversial_loss:1.342163\n",
      "Pretrain epoch 12, recon_loss:0.680018, zinb_loss:1.175642, adversial_loss:1.340560\n",
      "Pretrain epoch 13, recon_loss:0.677840, zinb_loss:1.162826, adversial_loss:1.339098\n",
      "Pretrain epoch 14, recon_loss:0.675129, zinb_loss:1.152876, adversial_loss:1.337435\n",
      "Pretrain epoch 15, recon_loss:0.672355, zinb_loss:1.144369, adversial_loss:1.335139\n",
      "Pretrain epoch 16, recon_loss:0.670228, zinb_loss:1.136601, adversial_loss:1.332293\n",
      "Pretrain epoch 17, recon_loss:0.667790, zinb_loss:1.129140, adversial_loss:1.329263\n",
      "Pretrain epoch 18, recon_loss:0.664680, zinb_loss:1.121876, adversial_loss:1.326783\n",
      "Pretrain epoch 19, recon_loss:0.662127, zinb_loss:1.115053, adversial_loss:1.324961\n",
      "Pretrain epoch 20, recon_loss:0.660377, zinb_loss:1.108180, adversial_loss:1.323852\n",
      "Pretrain epoch 21, recon_loss:0.659001, zinb_loss:1.100873, adversial_loss:1.323825\n",
      "Pretrain epoch 22, recon_loss:0.656459, zinb_loss:1.093486, adversial_loss:1.322779\n",
      "Pretrain epoch 23, recon_loss:0.654088, zinb_loss:1.086390, adversial_loss:1.321610\n",
      "Pretrain epoch 24, recon_loss:0.652294, zinb_loss:1.079503, adversial_loss:1.320213\n",
      "Pretrain epoch 25, recon_loss:0.650671, zinb_loss:1.072774, adversial_loss:1.318725\n",
      "Pretrain epoch 26, recon_loss:0.648966, zinb_loss:1.066303, adversial_loss:1.317523\n",
      "Pretrain epoch 27, recon_loss:0.646991, zinb_loss:1.060190, adversial_loss:1.316257\n",
      "Pretrain epoch 28, recon_loss:0.645398, zinb_loss:1.054652, adversial_loss:1.314740\n",
      "Pretrain epoch 29, recon_loss:0.643983, zinb_loss:1.049268, adversial_loss:1.312217\n",
      "Pretrain epoch 30, recon_loss:0.643025, zinb_loss:1.043892, adversial_loss:1.308721\n",
      "Pretrain epoch 31, recon_loss:0.642111, zinb_loss:1.039183, adversial_loss:1.306067\n",
      "Pretrain epoch 32, recon_loss:0.640455, zinb_loss:1.034951, adversial_loss:1.304514\n",
      "Pretrain epoch 33, recon_loss:0.639247, zinb_loss:1.031011, adversial_loss:1.303380\n",
      "Pretrain epoch 34, recon_loss:0.637743, zinb_loss:1.027282, adversial_loss:1.301915\n",
      "Pretrain epoch 35, recon_loss:0.636664, zinb_loss:1.023664, adversial_loss:1.300623\n",
      "Pretrain epoch 36, recon_loss:0.635682, zinb_loss:1.020120, adversial_loss:1.299578\n",
      "Pretrain epoch 37, recon_loss:0.634332, zinb_loss:1.016628, adversial_loss:1.298586\n",
      "Pretrain epoch 38, recon_loss:0.633481, zinb_loss:1.013218, adversial_loss:1.298119\n",
      "Pretrain epoch 39, recon_loss:0.632329, zinb_loss:1.010160, adversial_loss:1.296602\n",
      "Pretrain epoch 40, recon_loss:0.631456, zinb_loss:1.007311, adversial_loss:1.295990\n",
      "Pretrain epoch 41, recon_loss:0.630563, zinb_loss:1.004686, adversial_loss:1.294802\n",
      "Pretrain epoch 42, recon_loss:0.629735, zinb_loss:1.002095, adversial_loss:1.295299\n",
      "Pretrain epoch 43, recon_loss:0.629020, zinb_loss:1.000048, adversial_loss:1.293201\n",
      "Pretrain epoch 44, recon_loss:0.628373, zinb_loss:0.997680, adversial_loss:1.293849\n",
      "Pretrain epoch 45, recon_loss:0.627905, zinb_loss:0.995719, adversial_loss:1.290645\n",
      "Pretrain epoch 46, recon_loss:0.626810, zinb_loss:0.993385, adversial_loss:1.290701\n",
      "Pretrain epoch 47, recon_loss:0.626094, zinb_loss:0.991341, adversial_loss:1.289930\n",
      "Pretrain epoch 48, recon_loss:0.625388, zinb_loss:0.989542, adversial_loss:1.288692\n",
      "Pretrain epoch 49, recon_loss:0.624706, zinb_loss:0.987548, adversial_loss:1.288829\n",
      "Pretrain epoch 50, recon_loss:0.624136, zinb_loss:0.986056, adversial_loss:1.287461\n",
      "Pretrain epoch 51, recon_loss:0.623274, zinb_loss:0.984164, adversial_loss:1.287607\n",
      "Pretrain epoch 52, recon_loss:0.622424, zinb_loss:0.982464, adversial_loss:1.286898\n",
      "Pretrain epoch 53, recon_loss:0.621879, zinb_loss:0.981260, adversial_loss:1.285860\n",
      "Pretrain epoch 54, recon_loss:0.621108, zinb_loss:0.979639, adversial_loss:1.285778\n",
      "Pretrain epoch 55, recon_loss:0.620530, zinb_loss:0.978340, adversial_loss:1.284826\n",
      "Pretrain epoch 56, recon_loss:0.619800, zinb_loss:0.977073, adversial_loss:1.284936\n",
      "Pretrain epoch 57, recon_loss:0.619347, zinb_loss:0.975783, adversial_loss:1.283673\n",
      "Pretrain epoch 58, recon_loss:0.618823, zinb_loss:0.974526, adversial_loss:1.284123\n",
      "Pretrain epoch 59, recon_loss:0.618686, zinb_loss:0.973556, adversial_loss:1.282676\n",
      "Pretrain epoch 60, recon_loss:0.617441, zinb_loss:0.972172, adversial_loss:1.283096\n",
      "Pretrain epoch 61, recon_loss:0.616835, zinb_loss:0.970980, adversial_loss:1.281648\n",
      "Pretrain epoch 62, recon_loss:0.615886, zinb_loss:0.969648, adversial_loss:1.281288\n",
      "Pretrain epoch 63, recon_loss:0.615350, zinb_loss:0.968580, adversial_loss:1.281277\n",
      "Pretrain epoch 64, recon_loss:0.614922, zinb_loss:0.967744, adversial_loss:1.280465\n",
      "Pretrain epoch 65, recon_loss:0.614932, zinb_loss:0.967338, adversial_loss:1.280521\n",
      "Pretrain epoch 66, recon_loss:0.614976, zinb_loss:0.966357, adversial_loss:1.280103\n",
      "Pretrain epoch 67, recon_loss:0.613583, zinb_loss:0.965226, adversial_loss:1.280383\n",
      "Pretrain epoch 68, recon_loss:0.613921, zinb_loss:0.965229, adversial_loss:1.278780\n",
      "Pretrain epoch 69, recon_loss:0.612545, zinb_loss:0.963646, adversial_loss:1.279052\n",
      "Pretrain epoch 70, recon_loss:0.612793, zinb_loss:0.963037, adversial_loss:1.279510\n",
      "Pretrain epoch 71, recon_loss:0.611815, zinb_loss:0.961470, adversial_loss:1.278643\n",
      "Pretrain epoch 72, recon_loss:0.611546, zinb_loss:0.960857, adversial_loss:1.278122\n",
      "Pretrain epoch 73, recon_loss:0.610706, zinb_loss:0.959825, adversial_loss:1.278297\n",
      "Pretrain epoch 74, recon_loss:0.610377, zinb_loss:0.959457, adversial_loss:1.278214\n",
      "Pretrain epoch 75, recon_loss:0.608972, zinb_loss:0.958782, adversial_loss:1.277103\n",
      "Pretrain epoch 76, recon_loss:0.609311, zinb_loss:0.957827, adversial_loss:1.276618\n",
      "Pretrain epoch 77, recon_loss:0.608211, zinb_loss:0.957331, adversial_loss:1.277107\n",
      "Pretrain epoch 78, recon_loss:0.607739, zinb_loss:0.956897, adversial_loss:1.276694\n",
      "Pretrain epoch 79, recon_loss:0.607406, zinb_loss:0.956075, adversial_loss:1.276365\n",
      "Pretrain epoch 80, recon_loss:0.607084, zinb_loss:0.955484, adversial_loss:1.276402\n",
      "Pretrain epoch 81, recon_loss:0.605922, zinb_loss:0.954734, adversial_loss:1.275925\n",
      "Pretrain epoch 82, recon_loss:0.605686, zinb_loss:0.954194, adversial_loss:1.275973\n",
      "Pretrain epoch 83, recon_loss:0.605507, zinb_loss:0.954741, adversial_loss:1.275807\n",
      "Pretrain epoch 84, recon_loss:0.606017, zinb_loss:0.955828, adversial_loss:1.275457\n",
      "Pretrain epoch 85, recon_loss:0.606689, zinb_loss:0.955475, adversial_loss:1.274885\n",
      "Pretrain epoch 86, recon_loss:0.603597, zinb_loss:0.952265, adversial_loss:1.275342\n",
      "Pretrain epoch 87, recon_loss:0.603961, zinb_loss:0.952641, adversial_loss:1.275476\n",
      "Pretrain epoch 88, recon_loss:0.603907, zinb_loss:0.952613, adversial_loss:1.274445\n",
      "Pretrain epoch 89, recon_loss:0.602533, zinb_loss:0.950886, adversial_loss:1.273964\n",
      "Pretrain epoch 90, recon_loss:0.601846, zinb_loss:0.951025, adversial_loss:1.274571\n",
      "Pretrain epoch 91, recon_loss:0.601666, zinb_loss:0.950418, adversial_loss:1.274107\n",
      "Pretrain epoch 92, recon_loss:0.600451, zinb_loss:0.950003, adversial_loss:1.272773\n",
      "Pretrain epoch 93, recon_loss:0.600263, zinb_loss:0.949291, adversial_loss:1.273564\n",
      "Pretrain epoch 94, recon_loss:0.599480, zinb_loss:0.948868, adversial_loss:1.273637\n",
      "Pretrain epoch 95, recon_loss:0.599118, zinb_loss:0.948717, adversial_loss:1.272256\n",
      "Pretrain epoch 96, recon_loss:0.598330, zinb_loss:0.947870, adversial_loss:1.272520\n",
      "Pretrain epoch 97, recon_loss:0.598428, zinb_loss:0.948256, adversial_loss:1.272994\n",
      "Pretrain epoch 98, recon_loss:0.599205, zinb_loss:0.948368, adversial_loss:1.272520\n",
      "Pretrain epoch 99, recon_loss:0.600360, zinb_loss:0.950071, adversial_loss:1.271988\n",
      "Pretrain epoch 100, recon_loss:0.597603, zinb_loss:0.946913, adversial_loss:1.272954\n",
      "Pretrain epoch 101, recon_loss:0.598265, zinb_loss:0.948654, adversial_loss:1.273010\n",
      "Pretrain epoch 102, recon_loss:0.598125, zinb_loss:0.946708, adversial_loss:1.272140\n",
      "Pretrain epoch 103, recon_loss:0.596699, zinb_loss:0.946644, adversial_loss:1.271546\n",
      "Pretrain epoch 104, recon_loss:0.596948, zinb_loss:0.945447, adversial_loss:1.271937\n",
      "Pretrain epoch 105, recon_loss:0.594884, zinb_loss:0.945366, adversial_loss:1.271829\n",
      "Pretrain epoch 106, recon_loss:0.595728, zinb_loss:0.944949, adversial_loss:1.270860\n",
      "Pretrain epoch 107, recon_loss:0.593774, zinb_loss:0.944627, adversial_loss:1.270213\n",
      "Pretrain epoch 108, recon_loss:0.593907, zinb_loss:0.944016, adversial_loss:1.270924\n",
      "Pretrain epoch 109, recon_loss:0.592436, zinb_loss:0.943547, adversial_loss:1.270654\n",
      "Pretrain epoch 110, recon_loss:0.593074, zinb_loss:0.943505, adversial_loss:1.269729\n",
      "Pretrain epoch 111, recon_loss:0.591259, zinb_loss:0.942827, adversial_loss:1.269440\n",
      "Pretrain epoch 112, recon_loss:0.591416, zinb_loss:0.943134, adversial_loss:1.269742\n",
      "Pretrain epoch 113, recon_loss:0.590118, zinb_loss:0.942558, adversial_loss:1.268840\n",
      "Pretrain epoch 114, recon_loss:0.591088, zinb_loss:0.942681, adversial_loss:1.268550\n",
      "Pretrain epoch 115, recon_loss:0.591063, zinb_loss:0.943514, adversial_loss:1.268707\n",
      "Pretrain epoch 116, recon_loss:0.591478, zinb_loss:0.946264, adversial_loss:1.268885\n",
      "Pretrain epoch 117, recon_loss:0.592222, zinb_loss:0.947532, adversial_loss:1.267890\n",
      "Pretrain epoch 118, recon_loss:0.590538, zinb_loss:0.942911, adversial_loss:1.267889\n",
      "Pretrain epoch 119, recon_loss:0.588685, zinb_loss:0.942405, adversial_loss:1.267961\n",
      "Pretrain epoch 120, recon_loss:0.590820, zinb_loss:0.943007, adversial_loss:1.267911\n",
      "Pretrain epoch 121, recon_loss:0.587976, zinb_loss:0.941211, adversial_loss:1.267495\n",
      "Pretrain epoch 122, recon_loss:0.588107, zinb_loss:0.941682, adversial_loss:1.267016\n",
      "Pretrain epoch 123, recon_loss:0.587850, zinb_loss:0.941220, adversial_loss:1.267151\n",
      "Pretrain epoch 124, recon_loss:0.586103, zinb_loss:0.940096, adversial_loss:1.266919\n",
      "Pretrain epoch 125, recon_loss:0.586695, zinb_loss:0.940915, adversial_loss:1.266283\n",
      "Pretrain epoch 126, recon_loss:0.584600, zinb_loss:0.939462, adversial_loss:1.266199\n",
      "Pretrain epoch 127, recon_loss:0.584715, zinb_loss:0.939992, adversial_loss:1.266392\n",
      "Pretrain epoch 128, recon_loss:0.583646, zinb_loss:0.939460, adversial_loss:1.265532\n",
      "Pretrain epoch 129, recon_loss:0.583115, zinb_loss:0.938871, adversial_loss:1.265500\n",
      "Pretrain epoch 130, recon_loss:0.582615, zinb_loss:0.939027, adversial_loss:1.265729\n",
      "Pretrain epoch 131, recon_loss:0.581923, zinb_loss:0.938283, adversial_loss:1.265340\n",
      "Pretrain epoch 132, recon_loss:0.581585, zinb_loss:0.938320, adversial_loss:1.264889\n",
      "Pretrain epoch 133, recon_loss:0.580901, zinb_loss:0.937896, adversial_loss:1.265080\n",
      "Pretrain epoch 134, recon_loss:0.580363, zinb_loss:0.937661, adversial_loss:1.264922\n",
      "Pretrain epoch 135, recon_loss:0.579973, zinb_loss:0.937575, adversial_loss:1.264256\n",
      "Pretrain epoch 136, recon_loss:0.579230, zinb_loss:0.937157, adversial_loss:1.264609\n",
      "Pretrain epoch 137, recon_loss:0.578799, zinb_loss:0.937015, adversial_loss:1.264434\n",
      "Pretrain epoch 138, recon_loss:0.578477, zinb_loss:0.936980, adversial_loss:1.263689\n",
      "Pretrain epoch 139, recon_loss:0.578071, zinb_loss:0.936623, adversial_loss:1.264085\n",
      "Pretrain epoch 140, recon_loss:0.577605, zinb_loss:0.936654, adversial_loss:1.263607\n",
      "Pretrain epoch 141, recon_loss:0.577493, zinb_loss:0.936722, adversial_loss:1.263513\n",
      "Pretrain epoch 142, recon_loss:0.577291, zinb_loss:0.937000, adversial_loss:1.263335\n",
      "Pretrain epoch 143, recon_loss:0.576545, zinb_loss:0.937728, adversial_loss:1.263499\n",
      "Pretrain epoch 144, recon_loss:0.578736, zinb_loss:0.939613, adversial_loss:1.262442\n",
      "Pretrain epoch 145, recon_loss:0.582711, zinb_loss:0.939815, adversial_loss:1.263414\n",
      "Pretrain epoch 146, recon_loss:0.582419, zinb_loss:0.936777, adversial_loss:1.262378\n",
      "Pretrain epoch 147, recon_loss:0.577070, zinb_loss:0.935723, adversial_loss:1.262114\n",
      "Pretrain epoch 148, recon_loss:0.577505, zinb_loss:0.937018, adversial_loss:1.262499\n",
      "Pretrain epoch 149, recon_loss:0.577640, zinb_loss:0.935947, adversial_loss:1.261826\n",
      "Pretrain epoch 150, recon_loss:0.575486, zinb_loss:0.934979, adversial_loss:1.261736\n",
      "Pretrain epoch 151, recon_loss:0.575607, zinb_loss:0.935294, adversial_loss:1.262205\n",
      "Pretrain epoch 152, recon_loss:0.574304, zinb_loss:0.935022, adversial_loss:1.261621\n",
      "Pretrain epoch 153, recon_loss:0.575306, zinb_loss:0.934522, adversial_loss:1.261178\n",
      "Pretrain epoch 154, recon_loss:0.572280, zinb_loss:0.934396, adversial_loss:1.261574\n",
      "Pretrain epoch 155, recon_loss:0.572240, zinb_loss:0.934089, adversial_loss:1.261276\n",
      "Pretrain epoch 156, recon_loss:0.571514, zinb_loss:0.934011, adversial_loss:1.261041\n",
      "Pretrain epoch 157, recon_loss:0.570485, zinb_loss:0.933899, adversial_loss:1.260774\n",
      "Pretrain epoch 158, recon_loss:0.569664, zinb_loss:0.933655, adversial_loss:1.260707\n",
      "Pretrain epoch 159, recon_loss:0.569227, zinb_loss:0.933532, adversial_loss:1.260713\n",
      "Pretrain epoch 160, recon_loss:0.568005, zinb_loss:0.933317, adversial_loss:1.260352\n",
      "Pretrain epoch 161, recon_loss:0.568140, zinb_loss:0.933409, adversial_loss:1.260047\n",
      "Pretrain epoch 162, recon_loss:0.568237, zinb_loss:0.933763, adversial_loss:1.260389\n",
      "Pretrain epoch 163, recon_loss:0.567785, zinb_loss:0.935789, adversial_loss:1.259585\n",
      "Pretrain epoch 164, recon_loss:0.572782, zinb_loss:0.941099, adversial_loss:1.260909\n",
      "Pretrain epoch 165, recon_loss:0.574854, zinb_loss:0.941256, adversial_loss:1.260053\n",
      "Pretrain epoch 166, recon_loss:0.571536, zinb_loss:0.934069, adversial_loss:1.259973\n",
      "Pretrain epoch 167, recon_loss:0.574416, zinb_loss:0.936030, adversial_loss:1.260518\n",
      "Pretrain epoch 168, recon_loss:0.569643, zinb_loss:0.934969, adversial_loss:1.259938\n",
      "Pretrain epoch 169, recon_loss:0.569789, zinb_loss:0.933940, adversial_loss:1.259906\n",
      "Pretrain epoch 170, recon_loss:0.567910, zinb_loss:0.933777, adversial_loss:1.260010\n",
      "Pretrain epoch 171, recon_loss:0.568514, zinb_loss:0.933285, adversial_loss:1.259891\n",
      "Pretrain epoch 172, recon_loss:0.565946, zinb_loss:0.933049, adversial_loss:1.259461\n",
      "Pretrain epoch 173, recon_loss:0.566411, zinb_loss:0.932422, adversial_loss:1.259835\n",
      "Pretrain epoch 174, recon_loss:0.563918, zinb_loss:0.932656, adversial_loss:1.259749\n",
      "Pretrain epoch 175, recon_loss:0.564549, zinb_loss:0.932068, adversial_loss:1.259296\n",
      "Pretrain epoch 176, recon_loss:0.562717, zinb_loss:0.931993, adversial_loss:1.259141\n",
      "Pretrain epoch 177, recon_loss:0.562190, zinb_loss:0.931494, adversial_loss:1.259244\n",
      "Pretrain epoch 178, recon_loss:0.561238, zinb_loss:0.931572, adversial_loss:1.259254\n",
      "Pretrain epoch 179, recon_loss:0.560794, zinb_loss:0.931173, adversial_loss:1.258906\n",
      "Pretrain epoch 180, recon_loss:0.559483, zinb_loss:0.931114, adversial_loss:1.258742\n",
      "Pretrain epoch 181, recon_loss:0.558810, zinb_loss:0.930846, adversial_loss:1.258673\n",
      "Pretrain epoch 182, recon_loss:0.557942, zinb_loss:0.930764, adversial_loss:1.258663\n",
      "Pretrain epoch 183, recon_loss:0.557357, zinb_loss:0.930695, adversial_loss:1.258276\n",
      "Pretrain epoch 184, recon_loss:0.556984, zinb_loss:0.930571, adversial_loss:1.258297\n",
      "Pretrain epoch 185, recon_loss:0.556746, zinb_loss:0.930732, adversial_loss:1.257903\n",
      "Pretrain epoch 186, recon_loss:0.558162, zinb_loss:0.931001, adversial_loss:1.258457\n",
      "Pretrain epoch 187, recon_loss:0.563326, zinb_loss:0.931754, adversial_loss:1.257512\n",
      "Pretrain epoch 188, recon_loss:0.562017, zinb_loss:0.931675, adversial_loss:1.258373\n",
      "Pretrain epoch 189, recon_loss:0.558887, zinb_loss:0.931083, adversial_loss:1.256987\n",
      "Pretrain epoch 190, recon_loss:0.555452, zinb_loss:0.930072, adversial_loss:1.257520\n",
      "Pretrain epoch 191, recon_loss:0.556445, zinb_loss:0.930590, adversial_loss:1.257479\n",
      "Pretrain epoch 192, recon_loss:0.555254, zinb_loss:0.931529, adversial_loss:1.257116\n",
      "Pretrain epoch 193, recon_loss:0.555493, zinb_loss:0.930609, adversial_loss:1.257220\n",
      "Pretrain epoch 194, recon_loss:0.554808, zinb_loss:0.929856, adversial_loss:1.256895\n",
      "Pretrain epoch 195, recon_loss:0.554252, zinb_loss:0.929679, adversial_loss:1.256472\n",
      "Pretrain epoch 196, recon_loss:0.553550, zinb_loss:0.929222, adversial_loss:1.257241\n",
      "Pretrain epoch 197, recon_loss:0.550400, zinb_loss:0.928963, adversial_loss:1.256553\n",
      "Pretrain epoch 198, recon_loss:0.550799, zinb_loss:0.929040, adversial_loss:1.256077\n",
      "Pretrain epoch 199, recon_loss:0.550205, zinb_loss:0.928932, adversial_loss:1.256700\n",
      "Pretrain epoch 200, recon_loss:0.548488, zinb_loss:0.928861, adversial_loss:1.256489\n",
      "Pretrain epoch 201, recon_loss:0.549529, zinb_loss:0.929483, adversial_loss:1.255842\n",
      "Pretrain epoch 202, recon_loss:0.552430, zinb_loss:0.930490, adversial_loss:1.255978\n",
      "Pretrain epoch 203, recon_loss:0.555417, zinb_loss:0.932157, adversial_loss:1.256537\n",
      "Pretrain epoch 204, recon_loss:0.552969, zinb_loss:0.932155, adversial_loss:1.255958\n",
      "Pretrain epoch 205, recon_loss:0.548828, zinb_loss:0.928827, adversial_loss:1.255473\n",
      "Pretrain epoch 206, recon_loss:0.547778, zinb_loss:0.928655, adversial_loss:1.255564\n",
      "Pretrain epoch 207, recon_loss:0.549267, zinb_loss:0.929921, adversial_loss:1.255289\n",
      "Pretrain epoch 208, recon_loss:0.547404, zinb_loss:0.929111, adversial_loss:1.255101\n",
      "Pretrain epoch 209, recon_loss:0.545754, zinb_loss:0.928058, adversial_loss:1.255139\n",
      "Pretrain epoch 210, recon_loss:0.545914, zinb_loss:0.928491, adversial_loss:1.255020\n",
      "Pretrain epoch 211, recon_loss:0.544403, zinb_loss:0.928265, adversial_loss:1.254906\n",
      "Pretrain epoch 212, recon_loss:0.543415, zinb_loss:0.927735, adversial_loss:1.255028\n",
      "Pretrain epoch 213, recon_loss:0.543553, zinb_loss:0.927718, adversial_loss:1.254846\n",
      "Pretrain epoch 214, recon_loss:0.540635, zinb_loss:0.927378, adversial_loss:1.254630\n",
      "Pretrain epoch 215, recon_loss:0.541757, zinb_loss:0.927329, adversial_loss:1.254627\n",
      "Pretrain epoch 216, recon_loss:0.540345, zinb_loss:0.927143, adversial_loss:1.254506\n",
      "Pretrain epoch 217, recon_loss:0.538196, zinb_loss:0.926944, adversial_loss:1.254498\n",
      "Pretrain epoch 218, recon_loss:0.538600, zinb_loss:0.926930, adversial_loss:1.254115\n",
      "Pretrain epoch 219, recon_loss:0.537008, zinb_loss:0.926748, adversial_loss:1.254303\n",
      "Pretrain epoch 220, recon_loss:0.536594, zinb_loss:0.926706, adversial_loss:1.254115\n",
      "Pretrain epoch 221, recon_loss:0.539298, zinb_loss:0.926827, adversial_loss:1.253990\n",
      "Pretrain epoch 222, recon_loss:0.545875, zinb_loss:0.927305, adversial_loss:1.253899\n",
      "Pretrain epoch 223, recon_loss:0.547195, zinb_loss:0.927331, adversial_loss:1.254571\n",
      "Pretrain epoch 224, recon_loss:0.542174, zinb_loss:0.927121, adversial_loss:1.253541\n",
      "Pretrain epoch 225, recon_loss:0.541037, zinb_loss:0.926618, adversial_loss:1.253116\n",
      "Pretrain epoch 226, recon_loss:0.541850, zinb_loss:0.926372, adversial_loss:1.253573\n",
      "Pretrain epoch 227, recon_loss:0.537266, zinb_loss:0.926366, adversial_loss:1.253625\n",
      "Pretrain epoch 228, recon_loss:0.538527, zinb_loss:0.926530, adversial_loss:1.253038\n",
      "Pretrain epoch 229, recon_loss:0.536627, zinb_loss:0.926048, adversial_loss:1.253560\n",
      "Pretrain epoch 230, recon_loss:0.534582, zinb_loss:0.925871, adversial_loss:1.253318\n",
      "Pretrain epoch 231, recon_loss:0.534135, zinb_loss:0.925740, adversial_loss:1.253361\n",
      "Pretrain epoch 232, recon_loss:0.532720, zinb_loss:0.925627, adversial_loss:1.253266\n",
      "Pretrain epoch 233, recon_loss:0.531950, zinb_loss:0.925653, adversial_loss:1.252956\n",
      "Pretrain epoch 234, recon_loss:0.531895, zinb_loss:0.925733, adversial_loss:1.253239\n",
      "Pretrain epoch 235, recon_loss:0.532459, zinb_loss:0.926130, adversial_loss:1.252955\n",
      "Pretrain epoch 236, recon_loss:0.536625, zinb_loss:0.927588, adversial_loss:1.252945\n",
      "Pretrain epoch 237, recon_loss:0.539024, zinb_loss:0.930635, adversial_loss:1.253257\n",
      "Pretrain epoch 238, recon_loss:0.537922, zinb_loss:0.931437, adversial_loss:1.252468\n",
      "Pretrain epoch 239, recon_loss:0.532929, zinb_loss:0.928103, adversial_loss:1.252972\n",
      "Pretrain epoch 240, recon_loss:0.535495, zinb_loss:0.926489, adversial_loss:1.252351\n",
      "Pretrain epoch 241, recon_loss:0.533118, zinb_loss:0.926977, adversial_loss:1.252387\n",
      "Pretrain epoch 242, recon_loss:0.532192, zinb_loss:0.926168, adversial_loss:1.252556\n",
      "Pretrain epoch 243, recon_loss:0.531266, zinb_loss:0.925452, adversial_loss:1.252050\n",
      "Pretrain epoch 244, recon_loss:0.529536, zinb_loss:0.925518, adversial_loss:1.252217\n",
      "Pretrain epoch 245, recon_loss:0.529919, zinb_loss:0.925040, adversial_loss:1.252160\n",
      "Pretrain epoch 246, recon_loss:0.526950, zinb_loss:0.924811, adversial_loss:1.252068\n",
      "Pretrain epoch 247, recon_loss:0.526884, zinb_loss:0.924734, adversial_loss:1.252079\n",
      "Pretrain epoch 248, recon_loss:0.524632, zinb_loss:0.924482, adversial_loss:1.252126\n",
      "Pretrain epoch 249, recon_loss:0.523845, zinb_loss:0.924345, adversial_loss:1.251854\n",
      "Pretrain epoch 250, recon_loss:0.523529, zinb_loss:0.924314, adversial_loss:1.252120\n",
      "Pretrain epoch 251, recon_loss:0.521685, zinb_loss:0.924291, adversial_loss:1.251458\n",
      "Pretrain epoch 252, recon_loss:0.520432, zinb_loss:0.924136, adversial_loss:1.251710\n",
      "Pretrain epoch 253, recon_loss:0.520313, zinb_loss:0.924272, adversial_loss:1.251487\n",
      "Pretrain epoch 254, recon_loss:0.521664, zinb_loss:0.924356, adversial_loss:1.251635\n",
      "Pretrain epoch 255, recon_loss:0.523035, zinb_loss:0.924369, adversial_loss:1.251112\n",
      "Pretrain epoch 256, recon_loss:0.525831, zinb_loss:0.924372, adversial_loss:1.251610\n",
      "Pretrain epoch 257, recon_loss:0.522973, zinb_loss:0.924103, adversial_loss:1.250789\n",
      "Pretrain epoch 258, recon_loss:0.518241, zinb_loss:0.923893, adversial_loss:1.251200\n",
      "Pretrain epoch 259, recon_loss:0.517817, zinb_loss:0.923991, adversial_loss:1.250929\n",
      "Pretrain epoch 260, recon_loss:0.518039, zinb_loss:0.923839, adversial_loss:1.250690\n",
      "Pretrain epoch 261, recon_loss:0.515956, zinb_loss:0.923447, adversial_loss:1.250928\n",
      "Pretrain epoch 262, recon_loss:0.513895, zinb_loss:0.923440, adversial_loss:1.250620\n",
      "Pretrain epoch 263, recon_loss:0.513835, zinb_loss:0.923419, adversial_loss:1.250605\n",
      "Pretrain epoch 264, recon_loss:0.512982, zinb_loss:0.923185, adversial_loss:1.250534\n",
      "Pretrain epoch 265, recon_loss:0.512673, zinb_loss:0.923089, adversial_loss:1.250627\n",
      "Pretrain epoch 266, recon_loss:0.512133, zinb_loss:0.923116, adversial_loss:1.250002\n",
      "Pretrain epoch 267, recon_loss:0.511962, zinb_loss:0.923176, adversial_loss:1.250749\n",
      "Pretrain epoch 268, recon_loss:0.512107, zinb_loss:0.924047, adversial_loss:1.249946\n",
      "Pretrain epoch 269, recon_loss:0.514833, zinb_loss:0.925737, adversial_loss:1.250677\n",
      "Pretrain epoch 270, recon_loss:0.517847, zinb_loss:0.926574, adversial_loss:1.249720\n",
      "Pretrain epoch 271, recon_loss:0.517943, zinb_loss:0.924881, adversial_loss:1.250278\n",
      "Pretrain epoch 272, recon_loss:0.514191, zinb_loss:0.922930, adversial_loss:1.250168\n",
      "Pretrain epoch 273, recon_loss:0.521242, zinb_loss:0.925202, adversial_loss:1.249156\n",
      "Pretrain epoch 274, recon_loss:0.517442, zinb_loss:0.925336, adversial_loss:1.250511\n",
      "Pretrain epoch 275, recon_loss:0.518384, zinb_loss:0.925294, adversial_loss:1.249870\n",
      "Pretrain epoch 276, recon_loss:0.521161, zinb_loss:0.927005, adversial_loss:1.249135\n",
      "Pretrain epoch 277, recon_loss:0.514256, zinb_loss:0.923433, adversial_loss:1.249893\n",
      "Pretrain epoch 278, recon_loss:0.515535, zinb_loss:0.923530, adversial_loss:1.249849\n",
      "Pretrain epoch 279, recon_loss:0.512503, zinb_loss:0.923560, adversial_loss:1.249354\n",
      "Pretrain epoch 280, recon_loss:0.515305, zinb_loss:0.922990, adversial_loss:1.249665\n",
      "Pretrain epoch 281, recon_loss:0.509805, zinb_loss:0.922676, adversial_loss:1.249541\n",
      "Pretrain epoch 282, recon_loss:0.510216, zinb_loss:0.922475, adversial_loss:1.249405\n",
      "Pretrain epoch 283, recon_loss:0.507578, zinb_loss:0.922051, adversial_loss:1.249196\n",
      "Pretrain epoch 284, recon_loss:0.506245, zinb_loss:0.922554, adversial_loss:1.249519\n",
      "Pretrain epoch 285, recon_loss:0.504669, zinb_loss:0.922000, adversial_loss:1.249220\n",
      "Pretrain epoch 286, recon_loss:0.502729, zinb_loss:0.921837, adversial_loss:1.248951\n",
      "Pretrain epoch 287, recon_loss:0.501774, zinb_loss:0.921657, adversial_loss:1.249160\n",
      "Pretrain epoch 288, recon_loss:0.501260, zinb_loss:0.921655, adversial_loss:1.248994\n",
      "Pretrain epoch 289, recon_loss:0.499360, zinb_loss:0.921550, adversial_loss:1.249006\n",
      "Pretrain epoch 290, recon_loss:0.498534, zinb_loss:0.921686, adversial_loss:1.248650\n",
      "Pretrain epoch 291, recon_loss:0.497990, zinb_loss:0.921559, adversial_loss:1.248952\n",
      "Pretrain epoch 292, recon_loss:0.498962, zinb_loss:0.921546, adversial_loss:1.248601\n",
      "Pretrain epoch 293, recon_loss:0.500745, zinb_loss:0.921814, adversial_loss:1.248916\n",
      "Pretrain epoch 294, recon_loss:0.501947, zinb_loss:0.922106, adversial_loss:1.248188\n",
      "Pretrain epoch 295, recon_loss:0.498946, zinb_loss:0.921893, adversial_loss:1.248592\n",
      "Pretrain epoch 296, recon_loss:0.496131, zinb_loss:0.921547, adversial_loss:1.248443\n",
      "Pretrain epoch 297, recon_loss:0.496319, zinb_loss:0.921698, adversial_loss:1.248167\n",
      "Pretrain epoch 298, recon_loss:0.496336, zinb_loss:0.921654, adversial_loss:1.248361\n",
      "Pretrain epoch 299, recon_loss:0.496867, zinb_loss:0.921532, adversial_loss:1.248230\n",
      "Pretrain epoch 300, recon_loss:0.495937, zinb_loss:0.921501, adversial_loss:1.248012\n",
      "Pretrain epoch 301, recon_loss:0.498234, zinb_loss:0.922171, adversial_loss:1.248614\n",
      "Pretrain epoch 302, recon_loss:0.503863, zinb_loss:0.923424, adversial_loss:1.247572\n",
      "Pretrain epoch 303, recon_loss:0.495321, zinb_loss:0.922800, adversial_loss:1.248073\n",
      "Pretrain epoch 304, recon_loss:0.498044, zinb_loss:0.921611, adversial_loss:1.248363\n",
      "Pretrain epoch 305, recon_loss:0.494356, zinb_loss:0.921310, adversial_loss:1.247588\n",
      "Pretrain epoch 306, recon_loss:0.490891, zinb_loss:0.920596, adversial_loss:1.247740\n",
      "Pretrain epoch 307, recon_loss:0.491591, zinb_loss:0.921038, adversial_loss:1.247965\n",
      "Pretrain epoch 308, recon_loss:0.490003, zinb_loss:0.921139, adversial_loss:1.247654\n",
      "Pretrain epoch 309, recon_loss:0.489223, zinb_loss:0.920694, adversial_loss:1.247563\n",
      "Pretrain epoch 310, recon_loss:0.487935, zinb_loss:0.920680, adversial_loss:1.247849\n",
      "Pretrain epoch 311, recon_loss:0.486295, zinb_loss:0.920362, adversial_loss:1.247628\n",
      "Pretrain epoch 312, recon_loss:0.484374, zinb_loss:0.920141, adversial_loss:1.247453\n",
      "Pretrain epoch 313, recon_loss:0.483633, zinb_loss:0.920165, adversial_loss:1.247648\n",
      "Pretrain epoch 314, recon_loss:0.482767, zinb_loss:0.920006, adversial_loss:1.247262\n",
      "Pretrain epoch 315, recon_loss:0.482459, zinb_loss:0.920056, adversial_loss:1.247328\n",
      "Pretrain epoch 316, recon_loss:0.484225, zinb_loss:0.920175, adversial_loss:1.247292\n",
      "Pretrain epoch 317, recon_loss:0.487041, zinb_loss:0.920193, adversial_loss:1.247450\n",
      "Pretrain epoch 318, recon_loss:0.488344, zinb_loss:0.920604, adversial_loss:1.247184\n",
      "Pretrain epoch 319, recon_loss:0.482620, zinb_loss:0.920529, adversial_loss:1.246988\n",
      "Pretrain epoch 320, recon_loss:0.479926, zinb_loss:0.920262, adversial_loss:1.247065\n",
      "Pretrain epoch 321, recon_loss:0.483461, zinb_loss:0.920427, adversial_loss:1.246775\n",
      "Pretrain epoch 322, recon_loss:0.482188, zinb_loss:0.920349, adversial_loss:1.247039\n",
      "Pretrain epoch 323, recon_loss:0.480952, zinb_loss:0.920759, adversial_loss:1.246691\n",
      "Pretrain epoch 324, recon_loss:0.479341, zinb_loss:0.921360, adversial_loss:1.247012\n",
      "Pretrain epoch 325, recon_loss:0.484663, zinb_loss:0.921780, adversial_loss:1.246749\n",
      "Pretrain epoch 326, recon_loss:0.482796, zinb_loss:0.921111, adversial_loss:1.246708\n",
      "Pretrain epoch 327, recon_loss:0.479651, zinb_loss:0.919901, adversial_loss:1.246666\n",
      "Pretrain epoch 328, recon_loss:0.475342, zinb_loss:0.919579, adversial_loss:1.246480\n",
      "Pretrain epoch 329, recon_loss:0.477140, zinb_loss:0.920015, adversial_loss:1.246821\n",
      "Pretrain epoch 330, recon_loss:0.477093, zinb_loss:0.920330, adversial_loss:1.246401\n",
      "Pretrain epoch 331, recon_loss:0.476431, zinb_loss:0.920010, adversial_loss:1.246523\n",
      "Pretrain epoch 332, recon_loss:0.473098, zinb_loss:0.919427, adversial_loss:1.246268\n",
      "Pretrain epoch 333, recon_loss:0.471720, zinb_loss:0.919005, adversial_loss:1.246389\n",
      "Pretrain epoch 334, recon_loss:0.470440, zinb_loss:0.919068, adversial_loss:1.246033\n",
      "Pretrain epoch 335, recon_loss:0.468932, zinb_loss:0.918952, adversial_loss:1.246140\n",
      "Pretrain epoch 336, recon_loss:0.468013, zinb_loss:0.918944, adversial_loss:1.246304\n",
      "Pretrain epoch 337, recon_loss:0.471349, zinb_loss:0.919161, adversial_loss:1.245710\n",
      "Pretrain epoch 338, recon_loss:0.470129, zinb_loss:0.919169, adversial_loss:1.246209\n",
      "Pretrain epoch 339, recon_loss:0.473457, zinb_loss:0.919853, adversial_loss:1.245862\n",
      "Pretrain epoch 340, recon_loss:0.475349, zinb_loss:0.920651, adversial_loss:1.246094\n",
      "Pretrain epoch 341, recon_loss:0.474336, zinb_loss:0.920240, adversial_loss:1.245935\n",
      "Pretrain epoch 342, recon_loss:0.468043, zinb_loss:0.918994, adversial_loss:1.245606\n",
      "Pretrain epoch 343, recon_loss:0.468887, zinb_loss:0.918801, adversial_loss:1.245953\n",
      "Pretrain epoch 344, recon_loss:0.467698, zinb_loss:0.918980, adversial_loss:1.245598\n",
      "Pretrain epoch 345, recon_loss:0.464630, zinb_loss:0.918694, adversial_loss:1.245645\n",
      "Pretrain epoch 346, recon_loss:0.466442, zinb_loss:0.918619, adversial_loss:1.245765\n",
      "Pretrain epoch 347, recon_loss:0.462846, zinb_loss:0.918705, adversial_loss:1.245506\n",
      "Pretrain epoch 348, recon_loss:0.463364, zinb_loss:0.918919, adversial_loss:1.245496\n",
      "Pretrain epoch 349, recon_loss:0.466677, zinb_loss:0.919709, adversial_loss:1.245865\n",
      "Pretrain epoch 350, recon_loss:0.463831, zinb_loss:0.919662, adversial_loss:1.245411\n",
      "Pretrain epoch 351, recon_loss:0.468532, zinb_loss:0.919222, adversial_loss:1.245589\n",
      "Pretrain epoch 352, recon_loss:0.463319, zinb_loss:0.919005, adversial_loss:1.245463\n",
      "Pretrain epoch 353, recon_loss:0.464628, zinb_loss:0.918722, adversial_loss:1.245402\n",
      "Pretrain epoch 354, recon_loss:0.466382, zinb_loss:0.918665, adversial_loss:1.245361\n",
      "Pretrain epoch 355, recon_loss:0.463741, zinb_loss:0.918424, adversial_loss:1.245294\n",
      "Pretrain epoch 356, recon_loss:0.456510, zinb_loss:0.917770, adversial_loss:1.245330\n",
      "Pretrain epoch 357, recon_loss:0.454428, zinb_loss:0.917779, adversial_loss:1.244992\n",
      "Pretrain epoch 358, recon_loss:0.454976, zinb_loss:0.917737, adversial_loss:1.245449\n",
      "Pretrain epoch 359, recon_loss:0.454311, zinb_loss:0.917862, adversial_loss:1.244968\n",
      "Pretrain epoch 360, recon_loss:0.452632, zinb_loss:0.917909, adversial_loss:1.245039\n",
      "Pretrain epoch 361, recon_loss:0.453067, zinb_loss:0.917687, adversial_loss:1.244955\n",
      "Pretrain epoch 362, recon_loss:0.456525, zinb_loss:0.917979, adversial_loss:1.245360\n",
      "Pretrain epoch 363, recon_loss:0.462370, zinb_loss:0.918319, adversial_loss:1.244389\n",
      "Pretrain epoch 364, recon_loss:0.454625, zinb_loss:0.917606, adversial_loss:1.245090\n",
      "Pretrain epoch 365, recon_loss:0.446788, zinb_loss:0.917397, adversial_loss:1.244783\n",
      "Pretrain epoch 366, recon_loss:0.449447, zinb_loss:0.917623, adversial_loss:1.244616\n",
      "Pretrain epoch 367, recon_loss:0.449955, zinb_loss:0.917494, adversial_loss:1.244825\n",
      "Pretrain epoch 368, recon_loss:0.448117, zinb_loss:0.917450, adversial_loss:1.244515\n",
      "Pretrain epoch 369, recon_loss:0.449342, zinb_loss:0.917591, adversial_loss:1.244497\n",
      "Pretrain epoch 370, recon_loss:0.448283, zinb_loss:0.917546, adversial_loss:1.244743\n",
      "Pretrain epoch 371, recon_loss:0.445914, zinb_loss:0.917302, adversial_loss:1.244316\n",
      "Pretrain epoch 372, recon_loss:0.443342, zinb_loss:0.917304, adversial_loss:1.244421\n",
      "Pretrain epoch 373, recon_loss:0.443727, zinb_loss:0.917965, adversial_loss:1.244472\n",
      "Pretrain epoch 374, recon_loss:0.450613, zinb_loss:0.920401, adversial_loss:1.244195\n",
      "Pretrain epoch 375, recon_loss:0.458434, zinb_loss:0.923473, adversial_loss:1.244600\n",
      "Pretrain epoch 376, recon_loss:0.466628, zinb_loss:0.923974, adversial_loss:1.244055\n",
      "Pretrain epoch 377, recon_loss:0.448002, zinb_loss:0.918008, adversial_loss:1.244360\n",
      "Pretrain epoch 378, recon_loss:0.453877, zinb_loss:0.919228, adversial_loss:1.244228\n",
      "Pretrain epoch 379, recon_loss:0.454729, zinb_loss:0.920082, adversial_loss:1.244211\n",
      "Pretrain epoch 380, recon_loss:0.445237, zinb_loss:0.917129, adversial_loss:1.244172\n",
      "Pretrain epoch 381, recon_loss:0.450492, zinb_loss:0.917859, adversial_loss:1.243852\n",
      "Pretrain epoch 382, recon_loss:0.442563, zinb_loss:0.917322, adversial_loss:1.244273\n",
      "Pretrain epoch 383, recon_loss:0.441668, zinb_loss:0.916980, adversial_loss:1.244167\n",
      "Pretrain epoch 384, recon_loss:0.439400, zinb_loss:0.916999, adversial_loss:1.243751\n",
      "Pretrain epoch 385, recon_loss:0.436498, zinb_loss:0.916621, adversial_loss:1.243968\n",
      "Pretrain epoch 386, recon_loss:0.434738, zinb_loss:0.916643, adversial_loss:1.243971\n",
      "Pretrain epoch 387, recon_loss:0.433600, zinb_loss:0.916510, adversial_loss:1.243769\n",
      "Pretrain epoch 388, recon_loss:0.432909, zinb_loss:0.916476, adversial_loss:1.243826\n",
      "Pretrain epoch 389, recon_loss:0.433671, zinb_loss:0.916366, adversial_loss:1.243977\n",
      "Pretrain epoch 390, recon_loss:0.440959, zinb_loss:0.916790, adversial_loss:1.243476\n",
      "Pretrain epoch 391, recon_loss:0.441706, zinb_loss:0.916533, adversial_loss:1.244172\n",
      "Pretrain epoch 392, recon_loss:0.437726, zinb_loss:0.916482, adversial_loss:1.243456\n",
      "Pretrain epoch 393, recon_loss:0.427984, zinb_loss:0.916146, adversial_loss:1.243696\n",
      "Pretrain epoch 394, recon_loss:0.428263, zinb_loss:0.916296, adversial_loss:1.243844\n",
      "Pretrain epoch 395, recon_loss:0.431406, zinb_loss:0.916571, adversial_loss:1.243382\n",
      "Pretrain epoch 396, recon_loss:0.424839, zinb_loss:0.916067, adversial_loss:1.243597\n",
      "Pretrain epoch 397, recon_loss:0.426324, zinb_loss:0.916186, adversial_loss:1.243752\n",
      "Pretrain epoch 398, recon_loss:0.432253, zinb_loss:0.916296, adversial_loss:1.243196\n",
      "Pretrain epoch 399, recon_loss:0.433320, zinb_loss:0.916364, adversial_loss:1.243449\n",
      "Pretrain epoch 400, recon_loss:0.431458, zinb_loss:0.916175, adversial_loss:1.243666\n"
     ]
    }
   ],
   "source": [
    "pretrain_latent = model.pretrain_autoencoder(\n",
    "                        X1=adata1.X, X2=adata2.X, X1_raw=adata1.raw.X, X2_raw=adata2.raw.X, \n",
    "                        epochs=400, file='10x1kpbmc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering stage\n",
      "Initializing cluster centers with kmeans.\n",
      "Initializing k-means: AMI= 0.8205, NMI= 0.8218, ARI= 0.8344, ACC= 0.9201\n",
      "Training epoch 1, recon_loss:0.430522, zinb_loss:0.916023, cluster_loss:0.154342\n",
      "Clustering   1: AMI= 0.8205, NMI= 0.8218, ARI= 0.8344, ACC= 0.9201\n",
      "0.0\n",
      "Training epoch 2, recon_loss:0.846306, zinb_loss:1.077583, cluster_loss:0.171737\n",
      "Clustering   2: AMI= 0.8006, NMI= 0.8021, ARI= 0.8141, ACC= 0.9088\n",
      "0.014025245441795231\n",
      "Training epoch 3, recon_loss:0.778181, zinb_loss:1.139828, cluster_loss:0.164231\n",
      "Clustering   3: AMI= 0.8304, NMI= 0.8316, ARI= 0.8507, ACC= 0.9341\n",
      "0.03225806451612903\n",
      "Training epoch 4, recon_loss:0.784476, zinb_loss:1.364775, cluster_loss:0.169950\n",
      "Clustering   4: AMI= 0.8110, NMI= 0.8124, ARI= 0.8221, ACC= 0.9159\n",
      "0.03927068723702665\n",
      "Training epoch 5, recon_loss:0.830803, zinb_loss:1.707875, cluster_loss:0.176492\n",
      "Clustering   5: AMI= 0.8033, NMI= 0.8047, ARI= 0.7921, ACC= 0.8780\n",
      "0.06591865357643759\n",
      "Training epoch 6, recon_loss:0.802670, zinb_loss:1.205563, cluster_loss:0.177979\n",
      "Clustering   6: AMI= 0.8130, NMI= 0.8144, ARI= 0.8361, ACC= 0.9229\n",
      "0.08134642356241234\n",
      "Training epoch 7, recon_loss:0.773048, zinb_loss:1.173137, cluster_loss:0.170710\n",
      "Clustering   7: AMI= 0.8174, NMI= 0.8187, ARI= 0.8373, ACC= 0.9243\n",
      "0.005610098176718092\n",
      "Training epoch 8, recon_loss:0.715895, zinb_loss:1.001829, cluster_loss:0.163364\n",
      "Clustering   8: AMI= 0.8115, NMI= 0.8128, ARI= 0.8306, ACC= 0.9186\n",
      "0.008415147265077139\n",
      "Training epoch 9, recon_loss:0.707180, zinb_loss:0.976355, cluster_loss:0.150441\n",
      "Clustering   9: AMI= 0.8095, NMI= 0.8109, ARI= 0.8083, ACC= 0.9018\n",
      "0.037868162692847124\n",
      "Training epoch 10, recon_loss:0.661050, zinb_loss:0.958861, cluster_loss:0.151975\n",
      "Clustering   10: AMI= 0.8213, NMI= 0.8226, ARI= 0.8308, ACC= 0.9186\n",
      "0.019635343618513323\n",
      "Training epoch 11, recon_loss:0.652488, zinb_loss:0.952982, cluster_loss:0.149777\n",
      "Clustering   11: AMI= 0.8103, NMI= 0.8116, ARI= 0.8189, ACC= 0.9102\n",
      "0.011220196353436185\n",
      "Training epoch 12, recon_loss:0.642588, zinb_loss:0.953146, cluster_loss:0.151356\n",
      "Clustering   12: AMI= 0.8215, NMI= 0.8228, ARI= 0.8335, ACC= 0.9201\n",
      "0.009817671809256662\n",
      "Training epoch 13, recon_loss:0.638285, zinb_loss:0.949473, cluster_loss:0.149443\n",
      "Clustering   13: AMI= 0.8164, NMI= 0.8177, ARI= 0.8254, ACC= 0.9159\n",
      "0.0070126227208976155\n",
      "Training epoch 14, recon_loss:0.641145, zinb_loss:0.953004, cluster_loss:0.147145\n",
      "Clustering   14: AMI= 0.8178, NMI= 0.8192, ARI= 0.8276, ACC= 0.9159\n",
      "0.002805049088359046\n",
      "Training epoch 15, recon_loss:0.637767, zinb_loss:0.952127, cluster_loss:0.148271\n",
      "Clustering   15: AMI= 0.8203, NMI= 0.8216, ARI= 0.8315, ACC= 0.9186\n",
      "0.002805049088359046\n",
      "Training epoch 16, recon_loss:0.625828, zinb_loss:0.957454, cluster_loss:0.145889\n",
      "Clustering   16: AMI= 0.8140, NMI= 0.8154, ARI= 0.8209, ACC= 0.9116\n",
      "0.009817671809256662\n",
      "Training epoch 17, recon_loss:0.611839, zinb_loss:0.962478, cluster_loss:0.148376\n",
      "Clustering   17: AMI= 0.8260, NMI= 0.8273, ARI= 0.8380, ACC= 0.9229\n",
      "0.015427769985974754\n",
      "Training epoch 18, recon_loss:0.621567, zinb_loss:0.977118, cluster_loss:0.145853\n",
      "Clustering   18: AMI= 0.8140, NMI= 0.8154, ARI= 0.8209, ACC= 0.9116\n",
      "0.015427769985974754\n",
      "Training epoch 19, recon_loss:0.607203, zinb_loss:0.988093, cluster_loss:0.149063\n",
      "Clustering   19: AMI= 0.8275, NMI= 0.8288, ARI= 0.8401, ACC= 0.9257\n",
      "0.021037868162692847\n",
      "Training epoch 20, recon_loss:0.615731, zinb_loss:0.995491, cluster_loss:0.145251\n",
      "Clustering   20: AMI= 0.8140, NMI= 0.8154, ARI= 0.8209, ACC= 0.9116\n",
      "0.021037868162692847\n",
      "Training epoch 21, recon_loss:0.609800, zinb_loss:0.997153, cluster_loss:0.147204\n",
      "Clustering   21: AMI= 0.8261, NMI= 0.8274, ARI= 0.8380, ACC= 0.9243\n",
      "0.019635343618513323\n",
      "Training epoch 22, recon_loss:0.621488, zinb_loss:0.992326, cluster_loss:0.146616\n",
      "Clustering   22: AMI= 0.8182, NMI= 0.8195, ARI= 0.8240, ACC= 0.9130\n",
      "0.0182328190743338\n",
      "Training epoch 23, recon_loss:0.611237, zinb_loss:0.988998, cluster_loss:0.145771\n",
      "Clustering   23: AMI= 0.8203, NMI= 0.8216, ARI= 0.8315, ACC= 0.9186\n",
      "0.008415147265077139\n",
      "Training epoch 24, recon_loss:0.600035, zinb_loss:0.983440, cluster_loss:0.144918\n",
      "Clustering   24: AMI= 0.8253, NMI= 0.8265, ARI= 0.8355, ACC= 0.9215\n",
      "0.002805049088359046\n",
      "Training epoch 25, recon_loss:0.596902, zinb_loss:0.978649, cluster_loss:0.143721\n",
      "Clustering   25: AMI= 0.8182, NMI= 0.8195, ARI= 0.8240, ACC= 0.9130\n",
      "0.011220196353436185\n",
      "Training epoch 26, recon_loss:0.606475, zinb_loss:0.980079, cluster_loss:0.145489\n",
      "Clustering   26: AMI= 0.8304, NMI= 0.8316, ARI= 0.8440, ACC= 0.9285\n",
      "0.025245441795231416\n",
      "Training epoch 27, recon_loss:0.620056, zinb_loss:0.975876, cluster_loss:0.146040\n",
      "Clustering   27: AMI= 0.8160, NMI= 0.8173, ARI= 0.8204, ACC= 0.9102\n",
      "0.028050490883590462\n",
      "Training epoch 28, recon_loss:0.627696, zinb_loss:0.977644, cluster_loss:0.149002\n",
      "Clustering   28: AMI= 0.8264, NMI= 0.8277, ARI= 0.8437, ACC= 0.9285\n",
      "0.0364656381486676\n",
      "Training epoch 29, recon_loss:0.607567, zinb_loss:0.963646, cluster_loss:0.145189\n",
      "Clustering   29: AMI= 0.8171, NMI= 0.8184, ARI= 0.8222, ACC= 0.9116\n",
      "0.03506311360448808\n",
      "Training epoch 30, recon_loss:0.596643, zinb_loss:0.960702, cluster_loss:0.144895\n",
      "Clustering   30: AMI= 0.8280, NMI= 0.8292, ARI= 0.8395, ACC= 0.9257\n",
      "0.019635343618513323\n",
      "Training epoch 31, recon_loss:0.586386, zinb_loss:0.957384, cluster_loss:0.143485\n",
      "Clustering   31: AMI= 0.8190, NMI= 0.8204, ARI= 0.8296, ACC= 0.9173\n",
      "0.011220196353436185\n",
      "Training epoch 32, recon_loss:0.587456, zinb_loss:0.956871, cluster_loss:0.142214\n",
      "Clustering   32: AMI= 0.8189, NMI= 0.8202, ARI= 0.8294, ACC= 0.9186\n",
      "0.004207573632538569\n",
      "Training epoch 33, recon_loss:0.586300, zinb_loss:0.957902, cluster_loss:0.142721\n",
      "Clustering   33: AMI= 0.8203, NMI= 0.8216, ARI= 0.8315, ACC= 0.9186\n",
      "0.002805049088359046\n",
      "Training epoch 34, recon_loss:0.597041, zinb_loss:0.956997, cluster_loss:0.141408\n",
      "Clustering   34: AMI= 0.8152, NMI= 0.8166, ARI= 0.8235, ACC= 0.9144\n",
      "0.004207573632538569\n",
      "Training epoch 35, recon_loss:0.582191, zinb_loss:0.959904, cluster_loss:0.142487\n",
      "Clustering   35: AMI= 0.8228, NMI= 0.8241, ARI= 0.8355, ACC= 0.9215\n",
      "0.0070126227208976155\n",
      "Training epoch 36, recon_loss:0.579865, zinb_loss:0.960015, cluster_loss:0.141827\n",
      "Clustering   36: AMI= 0.8166, NMI= 0.8180, ARI= 0.8217, ACC= 0.9130\n",
      "0.011220196353436185\n",
      "Training epoch 37, recon_loss:0.579633, zinb_loss:0.963965, cluster_loss:0.142911\n",
      "Clustering   37: AMI= 0.8275, NMI= 0.8288, ARI= 0.8401, ACC= 0.9257\n",
      "0.016830294530154277\n",
      "Training epoch 38, recon_loss:0.591656, zinb_loss:0.964938, cluster_loss:0.143914\n",
      "Clustering   38: AMI= 0.8103, NMI= 0.8117, ARI= 0.8149, ACC= 0.9088\n",
      "0.021037868162692847\n",
      "Training epoch 39, recon_loss:0.598165, zinb_loss:0.971153, cluster_loss:0.144402\n",
      "Clustering   39: AMI= 0.8260, NMI= 0.8273, ARI= 0.8394, ACC= 0.9257\n",
      "0.02244039270687237\n",
      "Training epoch 40, recon_loss:0.586254, zinb_loss:0.966595, cluster_loss:0.142439\n",
      "Clustering   40: AMI= 0.8155, NMI= 0.8169, ARI= 0.8199, ACC= 0.9116\n",
      "0.019635343618513323\n",
      "Training epoch 41, recon_loss:0.576397, zinb_loss:0.964681, cluster_loss:0.141448\n",
      "Clustering   41: AMI= 0.8202, NMI= 0.8215, ARI= 0.8314, ACC= 0.9201\n",
      "0.011220196353436185\n",
      "Training epoch 42, recon_loss:0.580564, zinb_loss:0.965172, cluster_loss:0.142515\n",
      "Clustering   42: AMI= 0.8164, NMI= 0.8177, ARI= 0.8254, ACC= 0.9159\n",
      "0.004207573632538569\n",
      "Training epoch 43, recon_loss:0.581782, zinb_loss:0.966008, cluster_loss:0.141712\n",
      "Clustering   43: AMI= 0.8178, NMI= 0.8192, ARI= 0.8276, ACC= 0.9159\n",
      "0.002805049088359046\n",
      "Training epoch 44, recon_loss:0.578958, zinb_loss:0.961043, cluster_loss:0.142084\n",
      "Clustering   44: AMI= 0.8202, NMI= 0.8215, ARI= 0.8314, ACC= 0.9201\n",
      "0.0070126227208976155\n",
      "Training epoch 45, recon_loss:0.578888, zinb_loss:0.958669, cluster_loss:0.141906\n",
      "Clustering   45: AMI= 0.8182, NMI= 0.8195, ARI= 0.8240, ACC= 0.9130\n",
      "0.012622720897615708\n",
      "Training epoch 46, recon_loss:0.572623, zinb_loss:0.953206, cluster_loss:0.141412\n",
      "Clustering   46: AMI= 0.8215, NMI= 0.8228, ARI= 0.8334, ACC= 0.9215\n",
      "0.014025245441795231\n",
      "Training epoch 47, recon_loss:0.573183, zinb_loss:0.951851, cluster_loss:0.141826\n",
      "Clustering   47: AMI= 0.8171, NMI= 0.8184, ARI= 0.8222, ACC= 0.9116\n",
      "0.015427769985974754\n",
      "Training epoch 48, recon_loss:0.582879, zinb_loss:0.955231, cluster_loss:0.141006\n",
      "Clustering   48: AMI= 0.8252, NMI= 0.8265, ARI= 0.8354, ACC= 0.9229\n",
      "0.016830294530154277\n",
      "Training epoch 49, recon_loss:0.577148, zinb_loss:0.950773, cluster_loss:0.141801\n",
      "Clustering   49: AMI= 0.8182, NMI= 0.8195, ARI= 0.8240, ACC= 0.9130\n",
      "0.015427769985974754\n",
      "Training epoch 50, recon_loss:0.582462, zinb_loss:0.950802, cluster_loss:0.140044\n",
      "Clustering   50: AMI= 0.8189, NMI= 0.8202, ARI= 0.8294, ACC= 0.9186\n",
      "0.011220196353436185\n",
      "Training epoch 51, recon_loss:0.578021, zinb_loss:0.947385, cluster_loss:0.141623\n",
      "Clustering   51: AMI= 0.8176, NMI= 0.8190, ARI= 0.8274, ACC= 0.9173\n",
      "0.001402524544179523\n",
      "Training epoch 52, recon_loss:0.593130, zinb_loss:0.945707, cluster_loss:0.141130\n",
      "Clustering   52: AMI= 0.8155, NMI= 0.8169, ARI= 0.8199, ACC= 0.9116\n",
      "0.008415147265077139\n",
      "Training epoch 53, recon_loss:0.584805, zinb_loss:0.945096, cluster_loss:0.142527\n",
      "Clustering   53: AMI= 0.8202, NMI= 0.8215, ARI= 0.8314, ACC= 0.9201\n",
      "0.011220196353436185\n",
      "Training epoch 54, recon_loss:0.585467, zinb_loss:0.943358, cluster_loss:0.140558\n",
      "Clustering   54: AMI= 0.8144, NMI= 0.8158, ARI= 0.8180, ACC= 0.9102\n",
      "0.012622720897615708\n",
      "Training epoch 55, recon_loss:0.568052, zinb_loss:0.941190, cluster_loss:0.141217\n",
      "Clustering   55: AMI= 0.8202, NMI= 0.8215, ARI= 0.8314, ACC= 0.9201\n",
      "0.012622720897615708\n",
      "Training epoch 56, recon_loss:0.577989, zinb_loss:0.941180, cluster_loss:0.139027\n",
      "Clustering   56: AMI= 0.8117, NMI= 0.8131, ARI= 0.8154, ACC= 0.9088\n",
      "0.014025245441795231\n",
      "Training epoch 57, recon_loss:0.572676, zinb_loss:0.940440, cluster_loss:0.141063\n",
      "Clustering   57: AMI= 0.8242, NMI= 0.8255, ARI= 0.8375, ACC= 0.9243\n",
      "0.0182328190743338\n",
      "Training epoch 58, recon_loss:0.580458, zinb_loss:0.941732, cluster_loss:0.139396\n",
      "Clustering   58: AMI= 0.8117, NMI= 0.8131, ARI= 0.8154, ACC= 0.9088\n",
      "0.0182328190743338\n",
      "Training epoch 59, recon_loss:0.564884, zinb_loss:0.940472, cluster_loss:0.141210\n",
      "Clustering   59: AMI= 0.8215, NMI= 0.8228, ARI= 0.8334, ACC= 0.9215\n",
      "0.015427769985974754\n",
      "Training epoch 60, recon_loss:0.566060, zinb_loss:0.942304, cluster_loss:0.139360\n",
      "Clustering   60: AMI= 0.8144, NMI= 0.8158, ARI= 0.8180, ACC= 0.9102\n",
      "0.014025245441795231\n",
      "Training epoch 61, recon_loss:0.561706, zinb_loss:0.942914, cluster_loss:0.141014\n",
      "Clustering   61: AMI= 0.8202, NMI= 0.8215, ARI= 0.8314, ACC= 0.9201\n",
      "0.012622720897615708\n",
      "Training epoch 62, recon_loss:0.577613, zinb_loss:0.950187, cluster_loss:0.139490\n",
      "Clustering   62: AMI= 0.8155, NMI= 0.8169, ARI= 0.8199, ACC= 0.9116\n",
      "0.011220196353436185\n",
      "Training epoch 63, recon_loss:0.569885, zinb_loss:0.951495, cluster_loss:0.140008\n",
      "Clustering   63: AMI= 0.8176, NMI= 0.8190, ARI= 0.8274, ACC= 0.9173\n",
      "0.008415147265077139\n",
      "Training epoch 64, recon_loss:0.569891, zinb_loss:0.955939, cluster_loss:0.139665\n",
      "Clustering   64: AMI= 0.8176, NMI= 0.8190, ARI= 0.8274, ACC= 0.9173\n",
      "0.0\n",
      "delta_label  0.0 < tol  0.001\n",
      "Reach tolerance threshold. Stopping training.\n",
      "Final Result : AMI= 0.8176, NMI= 0.8190, ARI= 0.8274, ACC= 0.9173\n"
     ]
    }
   ],
   "source": [
    "y_pred, final_latent = model.fit(y=y, n_clusters=5, file='10x1kpbmc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
