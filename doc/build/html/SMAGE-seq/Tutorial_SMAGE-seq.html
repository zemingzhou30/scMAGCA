

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Tutorial:SMAGE-seq (no label) &mdash; scMAGCA 1.0.1 文档</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=eafc0fe6" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />

  
      <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js?v=3ff59fb2"></script>
      <script src="../_static/doctools.js?v=888ff710"></script>
      <script src="../_static/sphinx_highlight.js?v=4825356b"></script>
      <script src="../_static/translations.js?v=beaddf03"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            scMAGCA
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <!-- Local TOC -->
              <div class="local-toc"><ul>
<li><a class="reference internal" href="#">Tutorial:SMAGE-seq (no label)</a><ul>
<li><a class="reference internal" href="#Loading-package">Loading package</a></li>
<li><a class="reference internal" href="#Reading-SMAGE-seq-dataset">Reading SMAGE-seq dataset</a></li>
<li><a class="reference internal" href="#Training-the-model">Training the model</a></li>
</ul>
</li>
</ul>
</div>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">scMAGCA</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Tutorial:SMAGE-seq (no label)</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/SMAGE-seq/Tutorial_SMAGE-seq.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="Tutorial:SMAGE-seq-(no-label)">
<h1>Tutorial:SMAGE-seq (no label)<a class="headerlink" href="#Tutorial:SMAGE-seq-(no-label)" title="此标题的永久链接">¶</a></h1>
<p>In this tutorial, we will show how to cluster SMAGE-seq data using scMAGCA. As an example, we use a human peripheral blood mononuclear sample dataset ‘GSM4949911’ containing 8213 cells. It contains two omics data, with ATAC containing 66828 features and RNA containing 36601 features, and is not labeled.</p>
<section id="Loading-package">
<h2>Loading package<a class="headerlink" href="#Loading-package" title="此标题的永久链接">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">scanpy</span> <span class="k">as</span> <span class="nn">sc</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">preprocess</span> <span class="kn">import</span> <span class="n">read_dataset</span><span class="p">,</span> <span class="n">preprocess_dataset</span>
<span class="kn">from</span> <span class="nn">utils</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">scMAGCA</span> <span class="kn">import</span> <span class="n">scMultiCluster</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># set seed</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3407</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3407</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">3407</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
</pre></div>
</div>
</div>
</section>
<section id="Reading-SMAGE-seq-dataset">
<h2>Reading SMAGE-seq dataset<a class="headerlink" href="#Reading-SMAGE-seq-dataset" title="此标题的永久链接">¶</a></h2>
<p>The required input files include:</p>
<ol class="arabic simple">
<li><p>x1: Chromatin accessibility matrix (data format is h5ad file) : GSM4949911_tea_atac.h5ad;</p></li>
<li><p>x2: Gene expression matrix (data format is h5ad file) : GSM4949911_tea_rna.h5ad.</p></li>
</ol>
<p>To ensure reproducibility of the results, please read the above data as follows:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">read_h5ad</span><span class="p">(</span><span class="s1">&#39;../datasets/GSM4949911_tea/GSM4949911_tea_atac.h5ad&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_df</span><span class="p">())</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">sc</span><span class="o">.</span><span class="n">read_h5ad</span><span class="p">(</span><span class="s1">&#39;../datasets/GSM4949911_tea/GSM4949911_tea_rna.h5ad&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to_df</span><span class="p">())</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x1</span><span class="p">,</span><span class="n">x2</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
(array([[0., 0., 0., ..., 0., 0., 0.],
        [0., 2., 0., ..., 0., 0., 0.],
        [8., 2., 0., ..., 0., 0., 0.],
        ...,
        [0., 0., 2., ..., 0., 0., 2.],
        [0., 2., 0., ..., 0., 0., 0.],
        [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),
 array([[  0.,   0.,   0., ..., 102.,  70.,  43.],
        [  0.,   0.,   0., ...,  22.,   8.,  27.],
        [  1.,   0.,   0., ...,  11.,  12.,  11.],
        ...,
        [  0.,   0.,   0., ...,  27.,  30.,  38.],
        [  0.,   0.,   0., ...,  20.,  19.,  19.],
        [  5.,   0.,   0., ...,  11.,  16.,  17.]], dtype=float32))
</pre></div></div>
</div>
<p>We select the two omics data for high expression, and the number of chosen features are both set to 2000.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">importantGenes</span> <span class="o">=</span> <span class="n">geneSelection</span><span class="p">(</span><span class="n">x1</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
<span class="n">x1</span> <span class="o">=</span> <span class="n">x1</span><span class="p">[:,</span> <span class="n">importantGenes</span><span class="p">]</span>
<span class="n">importantGenes</span> <span class="o">=</span> <span class="n">geneSelection</span><span class="p">(</span><span class="n">x2</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">2000</span><span class="p">)</span>
<span class="n">x2</span> <span class="o">=</span> <span class="n">x2</span><span class="p">[:,</span> <span class="n">importantGenes</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Chosen offset: 1.24
Chosen offset: 0.33
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/SMAGE-seq_Tutorial_SMAGE-seq_11_1.png" src="../_images/SMAGE-seq_Tutorial_SMAGE-seq_11_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/SMAGE-seq_Tutorial_SMAGE-seq_11_2.png" src="../_images/SMAGE-seq_Tutorial_SMAGE-seq_11_2.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adata1</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">x1</span><span class="p">)</span>
<span class="n">adata1</span> <span class="o">=</span> <span class="n">read_dataset</span><span class="p">(</span><span class="n">adata1</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">adata1</span> <span class="o">=</span> <span class="n">preprocess_dataset</span><span class="p">(</span><span class="n">adata1</span><span class="p">,</span> <span class="n">normalize_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">logtrans_input</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
### Autoencoder: Successfully preprocessed 2000 features and 8213 cells.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adata1</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
AnnData object with n_obs × n_vars = 8213 × 2000
    obs: &#39;DCA_split&#39;, &#39;size_factors&#39;
    var: &#39;mean&#39;, &#39;std&#39;
    uns: &#39;log1p&#39;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adata2</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">AnnData</span><span class="p">(</span><span class="n">x2</span><span class="p">)</span>
<span class="n">adata2</span> <span class="o">=</span> <span class="n">read_dataset</span><span class="p">(</span><span class="n">adata2</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">adata2</span> <span class="o">=</span> <span class="n">preprocess_dataset</span><span class="p">(</span><span class="n">adata2</span><span class="p">,</span> <span class="n">normalize_input</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">logtrans_input</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
### Autoencoder: Successfully preprocessed 2000 features and 8213 cells.
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">adata2</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
AnnData object with n_obs × n_vars = 8213 × 2000
    obs: &#39;DCA_split&#39;, &#39;size_factors&#39;
    var: &#39;mean&#39;, &#39;std&#39;
    uns: &#39;log1p&#39;
</pre></div></div>
</div>
</section>
<section id="Training-the-model">
<h2>Training the model<a class="headerlink" href="#Training-the-model" title="此标题的永久链接">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">scMultiCluster</span><span class="p">(</span><span class="n">input_dim1</span><span class="o">=</span><span class="n">adata1</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">input_dim2</span><span class="o">=</span><span class="n">adata2</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
scMultiCluster(
  (encoder): Encoder(
    (stacked_gnn): ModuleList(
      (0): GCNConv(4000, 1024)
      (1): GCNConv(1024, 256)
      (2): GCNConv(256, 64)
      (3): GCNConv(64, 32)
    )
    (stacked_bns): ModuleList(
      (0): BatchNorm1d(1024, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
      (1): BatchNorm1d(256, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
      (2): BatchNorm1d(64, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
      (3): BatchNorm1d(32, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)
    )
    (stacked_prelus): ModuleList(
      (0-3): 4 x PReLU(num_parameters=1)
    )
  )
  (decoder): Sequential(
    (0): Linear(in_features=32, out_features=512, bias=True)
    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): PReLU(num_parameters=1)
    (3): Linear(in_features=512, out_features=1024, bias=True)
    (4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): PReLU(num_parameters=1)
    (6): Linear(in_features=1024, out_features=4000, bias=True)
  )
  (dec_mean): Sequential(
    (0): Linear(in_features=32, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=512, bias=True)
    (2): Linear(in_features=512, out_features=4000, bias=True)
    (3): MeanAct()
  )
  (dec_disp): Sequential(
    (0): Linear(in_features=32, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=512, bias=True)
    (2): Linear(in_features=512, out_features=4000, bias=True)
    (3): DispAct()
  )
  (dec_pi): Sequential(
    (0): Linear(in_features=32, out_features=256, bias=True)
    (1): Linear(in_features=256, out_features=512, bias=True)
    (2): Linear(in_features=512, out_features=4000, bias=True)
    (3): Sigmoid()
  )
  (zinb_loss): ZINBLoss()
  (discriminator): Discriminator(
    (fc1): Linear(in_features=32, out_features=32, bias=True)
    (fc2): Linear(in_features=32, out_features=1, bias=True)
  )
)
</pre></div></div>
</div>
<p>The ad_out parameter is set to 32 in the SMAGE-seq dataset.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pretrain_latent</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">pretrain_autoencoder</span><span class="p">(</span>
                        <span class="n">X1</span><span class="o">=</span><span class="n">adata1</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">X2</span><span class="o">=</span><span class="n">adata2</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">X1_raw</span><span class="o">=</span><span class="n">adata1</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">X2_raw</span><span class="o">=</span><span class="n">adata2</span><span class="o">.</span><span class="n">raw</span><span class="o">.</span><span class="n">X</span><span class="p">,</span>
                        <span class="n">epochs</span><span class="o">=</span><span class="mi">400</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="s1">&#39;GSM4949911_tea&#39;</span><span class="p">,</span><span class="n">ad_out</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Pretraining stage
Pretrain epoch 1, recon_loss:1.177419, zinb_loss:0.945166, adversial_loss:1.372231
Pretrain epoch 2, recon_loss:1.087229, zinb_loss:0.921236, adversial_loss:1.373194
Pretrain epoch 3, recon_loss:0.948224, zinb_loss:0.890657, adversial_loss:1.373617
Pretrain epoch 4, recon_loss:0.885800, zinb_loss:0.858559, adversial_loss:1.358683
Pretrain epoch 5, recon_loss:0.866452, zinb_loss:0.824501, adversial_loss:1.359133
Pretrain epoch 6, recon_loss:0.856318, zinb_loss:0.789515, adversial_loss:1.355022
Pretrain epoch 7, recon_loss:0.850889, zinb_loss:0.759701, adversial_loss:1.351529
Pretrain epoch 8, recon_loss:0.842909, zinb_loss:0.738662, adversial_loss:1.351824
Pretrain epoch 9, recon_loss:0.836522, zinb_loss:0.726100, adversial_loss:1.351907
Pretrain epoch 10, recon_loss:0.829639, zinb_loss:0.718908, adversial_loss:1.350247
Pretrain epoch 11, recon_loss:0.824786, zinb_loss:0.713263, adversial_loss:1.348227
Pretrain epoch 12, recon_loss:0.821581, zinb_loss:0.707017, adversial_loss:1.347948
Pretrain epoch 13, recon_loss:0.818954, zinb_loss:0.699969, adversial_loss:1.349329
Pretrain epoch 14, recon_loss:0.816677, zinb_loss:0.693693, adversial_loss:1.350878
Pretrain epoch 15, recon_loss:0.813920, zinb_loss:0.688917, adversial_loss:1.350498
Pretrain epoch 16, recon_loss:0.811877, zinb_loss:0.685424, adversial_loss:1.349127
Pretrain epoch 17, recon_loss:0.809966, zinb_loss:0.682478, adversial_loss:1.348064
Pretrain epoch 18, recon_loss:0.808354, zinb_loss:0.679629, adversial_loss:1.347751
Pretrain epoch 19, recon_loss:0.807258, zinb_loss:0.676862, adversial_loss:1.347479
Pretrain epoch 20, recon_loss:0.806017, zinb_loss:0.674137, adversial_loss:1.346404
Pretrain epoch 21, recon_loss:0.804428, zinb_loss:0.671521, adversial_loss:1.344638
Pretrain epoch 22, recon_loss:0.802824, zinb_loss:0.668903, adversial_loss:1.343253
Pretrain epoch 23, recon_loss:0.801624, zinb_loss:0.666379, adversial_loss:1.341949
Pretrain epoch 24, recon_loss:0.800622, zinb_loss:0.663973, adversial_loss:1.340480
Pretrain epoch 25, recon_loss:0.799793, zinb_loss:0.661805, adversial_loss:1.340241
Pretrain epoch 26, recon_loss:0.799017, zinb_loss:0.659948, adversial_loss:1.340883
Pretrain epoch 27, recon_loss:0.798392, zinb_loss:0.658303, adversial_loss:1.340143
Pretrain epoch 28, recon_loss:0.797557, zinb_loss:0.656784, adversial_loss:1.339819
Pretrain epoch 29, recon_loss:0.796525, zinb_loss:0.655244, adversial_loss:1.339375
Pretrain epoch 30, recon_loss:0.795610, zinb_loss:0.653714, adversial_loss:1.339210
Pretrain epoch 31, recon_loss:0.794745, zinb_loss:0.652404, adversial_loss:1.337723
Pretrain epoch 32, recon_loss:0.794299, zinb_loss:0.651255, adversial_loss:1.338467
Pretrain epoch 33, recon_loss:0.793691, zinb_loss:0.650216, adversial_loss:1.335549
Pretrain epoch 34, recon_loss:0.792576, zinb_loss:0.648704, adversial_loss:1.335775
Pretrain epoch 35, recon_loss:0.792066, zinb_loss:0.647766, adversial_loss:1.335634
Pretrain epoch 36, recon_loss:0.791833, zinb_loss:0.647147, adversial_loss:1.333670
Pretrain epoch 37, recon_loss:0.790898, zinb_loss:0.646018, adversial_loss:1.333558
Pretrain epoch 38, recon_loss:0.790367, zinb_loss:0.645174, adversial_loss:1.333227
Pretrain epoch 39, recon_loss:0.789837, zinb_loss:0.644639, adversial_loss:1.331793
Pretrain epoch 40, recon_loss:0.789169, zinb_loss:0.643823, adversial_loss:1.332080
Pretrain epoch 41, recon_loss:0.788582, zinb_loss:0.643115, adversial_loss:1.331233
Pretrain epoch 42, recon_loss:0.788083, zinb_loss:0.642528, adversial_loss:1.329755
Pretrain epoch 43, recon_loss:0.787743, zinb_loss:0.642012, adversial_loss:1.330270
Pretrain epoch 44, recon_loss:0.787233, zinb_loss:0.641469, adversial_loss:1.329388
Pretrain epoch 45, recon_loss:0.786937, zinb_loss:0.641088, adversial_loss:1.328254
Pretrain epoch 46, recon_loss:0.786540, zinb_loss:0.640810, adversial_loss:1.328790
Pretrain epoch 47, recon_loss:0.786258, zinb_loss:0.640202, adversial_loss:1.327587
Pretrain epoch 48, recon_loss:0.785733, zinb_loss:0.639601, adversial_loss:1.327571
Pretrain epoch 49, recon_loss:0.785445, zinb_loss:0.639265, adversial_loss:1.327048
Pretrain epoch 50, recon_loss:0.785088, zinb_loss:0.638992, adversial_loss:1.325881
Pretrain epoch 51, recon_loss:0.784727, zinb_loss:0.638529, adversial_loss:1.326414
Pretrain epoch 52, recon_loss:0.784363, zinb_loss:0.638133, adversial_loss:1.325543
Pretrain epoch 53, recon_loss:0.784103, zinb_loss:0.637940, adversial_loss:1.324549
Pretrain epoch 54, recon_loss:0.783760, zinb_loss:0.637597, adversial_loss:1.325459
Pretrain epoch 55, recon_loss:0.783446, zinb_loss:0.637262, adversial_loss:1.324351
Pretrain epoch 56, recon_loss:0.783150, zinb_loss:0.637093, adversial_loss:1.324194
Pretrain epoch 57, recon_loss:0.782939, zinb_loss:0.636965, adversial_loss:1.323673
Pretrain epoch 58, recon_loss:0.782717, zinb_loss:0.636879, adversial_loss:1.324108
Pretrain epoch 59, recon_loss:0.782628, zinb_loss:0.637086, adversial_loss:1.321680
Pretrain epoch 60, recon_loss:0.782271, zinb_loss:0.636703, adversial_loss:1.323040
Pretrain epoch 61, recon_loss:0.781838, zinb_loss:0.636147, adversial_loss:1.320967
Pretrain epoch 62, recon_loss:0.781431, zinb_loss:0.635768, adversial_loss:1.320497
Pretrain epoch 63, recon_loss:0.781378, zinb_loss:0.635902, adversial_loss:1.320936
Pretrain epoch 64, recon_loss:0.781003, zinb_loss:0.635670, adversial_loss:1.319416
Pretrain epoch 65, recon_loss:0.780600, zinb_loss:0.635297, adversial_loss:1.319215
Pretrain epoch 66, recon_loss:0.780387, zinb_loss:0.635358, adversial_loss:1.319530
Pretrain epoch 67, recon_loss:0.780119, zinb_loss:0.635134, adversial_loss:1.317977
Pretrain epoch 68, recon_loss:0.779724, zinb_loss:0.634855, adversial_loss:1.317650
Pretrain epoch 69, recon_loss:0.779647, zinb_loss:0.634964, adversial_loss:1.318024
Pretrain epoch 70, recon_loss:0.779239, zinb_loss:0.634626, adversial_loss:1.316499
Pretrain epoch 71, recon_loss:0.778984, zinb_loss:0.634477, adversial_loss:1.316283
Pretrain epoch 72, recon_loss:0.778745, zinb_loss:0.634437, adversial_loss:1.316512
Pretrain epoch 73, recon_loss:0.778422, zinb_loss:0.634171, adversial_loss:1.315362
Pretrain epoch 74, recon_loss:0.778190, zinb_loss:0.634086, adversial_loss:1.314840
Pretrain epoch 75, recon_loss:0.777988, zinb_loss:0.634006, adversial_loss:1.314906
Pretrain epoch 76, recon_loss:0.777692, zinb_loss:0.633817, adversial_loss:1.314137
Pretrain epoch 77, recon_loss:0.777451, zinb_loss:0.633776, adversial_loss:1.313697
Pretrain epoch 78, recon_loss:0.777205, zinb_loss:0.633718, adversial_loss:1.313863
Pretrain epoch 79, recon_loss:0.776992, zinb_loss:0.633652, adversial_loss:1.312968
Pretrain epoch 80, recon_loss:0.776972, zinb_loss:0.633797, adversial_loss:1.312713
Pretrain epoch 81, recon_loss:0.776964, zinb_loss:0.634136, adversial_loss:1.312556
Pretrain epoch 82, recon_loss:0.777046, zinb_loss:0.634610, adversial_loss:1.311600
Pretrain epoch 83, recon_loss:0.776634, zinb_loss:0.634098, adversial_loss:1.311629
Pretrain epoch 84, recon_loss:0.775969, zinb_loss:0.633054, adversial_loss:1.311265
Pretrain epoch 85, recon_loss:0.776029, zinb_loss:0.633389, adversial_loss:1.310533
Pretrain epoch 86, recon_loss:0.775819, zinb_loss:0.633396, adversial_loss:1.310469
Pretrain epoch 87, recon_loss:0.775534, zinb_loss:0.632921, adversial_loss:1.309945
Pretrain epoch 88, recon_loss:0.775337, zinb_loss:0.632915, adversial_loss:1.309785
Pretrain epoch 89, recon_loss:0.775196, zinb_loss:0.632826, adversial_loss:1.309403
Pretrain epoch 90, recon_loss:0.775106, zinb_loss:0.632720, adversial_loss:1.308682
Pretrain epoch 91, recon_loss:0.774817, zinb_loss:0.632539, adversial_loss:1.308952
Pretrain epoch 92, recon_loss:0.774637, zinb_loss:0.632432, adversial_loss:1.308161
Pretrain epoch 93, recon_loss:0.774580, zinb_loss:0.632434, adversial_loss:1.307136
Pretrain epoch 94, recon_loss:0.774255, zinb_loss:0.632254, adversial_loss:1.307646
Pretrain epoch 95, recon_loss:0.774129, zinb_loss:0.632149, adversial_loss:1.306916
Pretrain epoch 96, recon_loss:0.773953, zinb_loss:0.632100, adversial_loss:1.306219
Pretrain epoch 97, recon_loss:0.773769, zinb_loss:0.631987, adversial_loss:1.306318
Pretrain epoch 98, recon_loss:0.773663, zinb_loss:0.631933, adversial_loss:1.305686
Pretrain epoch 99, recon_loss:0.773468, zinb_loss:0.631802, adversial_loss:1.305677
Pretrain epoch 100, recon_loss:0.773266, zinb_loss:0.631716, adversial_loss:1.305090
Pretrain epoch 101, recon_loss:0.773141, zinb_loss:0.631620, adversial_loss:1.305019
Pretrain epoch 102, recon_loss:0.772991, zinb_loss:0.631532, adversial_loss:1.304864
Pretrain epoch 103, recon_loss:0.772879, zinb_loss:0.631514, adversial_loss:1.303902
Pretrain epoch 104, recon_loss:0.772725, zinb_loss:0.631433, adversial_loss:1.304510
Pretrain epoch 105, recon_loss:0.772648, zinb_loss:0.631401, adversial_loss:1.303271
Pretrain epoch 106, recon_loss:0.772535, zinb_loss:0.631453, adversial_loss:1.303749
Pretrain epoch 107, recon_loss:0.772562, zinb_loss:0.631585, adversial_loss:1.302562
Pretrain epoch 108, recon_loss:0.772743, zinb_loss:0.631804, adversial_loss:1.303632
Pretrain epoch 109, recon_loss:0.773139, zinb_loss:0.632166, adversial_loss:1.301710
Pretrain epoch 110, recon_loss:0.772615, zinb_loss:0.631620, adversial_loss:1.302210
Pretrain epoch 111, recon_loss:0.772099, zinb_loss:0.631244, adversial_loss:1.302199
Pretrain epoch 112, recon_loss:0.772691, zinb_loss:0.631441, adversial_loss:1.300339
Pretrain epoch 113, recon_loss:0.771753, zinb_loss:0.630972, adversial_loss:1.301244
Pretrain epoch 114, recon_loss:0.771948, zinb_loss:0.631223, adversial_loss:1.301844
Pretrain epoch 115, recon_loss:0.771766, zinb_loss:0.630892, adversial_loss:1.300058
Pretrain epoch 116, recon_loss:0.771387, zinb_loss:0.630823, adversial_loss:1.300245
Pretrain epoch 117, recon_loss:0.771327, zinb_loss:0.630725, adversial_loss:1.300648
Pretrain epoch 118, recon_loss:0.770896, zinb_loss:0.630538, adversial_loss:1.299725
Pretrain epoch 119, recon_loss:0.771083, zinb_loss:0.630620, adversial_loss:1.299314
Pretrain epoch 120, recon_loss:0.770678, zinb_loss:0.630338, adversial_loss:1.298796
Pretrain epoch 121, recon_loss:0.770595, zinb_loss:0.630327, adversial_loss:1.299041
Pretrain epoch 122, recon_loss:0.770426, zinb_loss:0.630228, adversial_loss:1.298796
Pretrain epoch 123, recon_loss:0.770400, zinb_loss:0.630227, adversial_loss:1.297851
Pretrain epoch 124, recon_loss:0.769996, zinb_loss:0.630014, adversial_loss:1.297896
Pretrain epoch 125, recon_loss:0.770002, zinb_loss:0.630018, adversial_loss:1.297887
Pretrain epoch 126, recon_loss:0.769764, zinb_loss:0.629883, adversial_loss:1.297321
Pretrain epoch 127, recon_loss:0.769703, zinb_loss:0.629920, adversial_loss:1.297207
Pretrain epoch 128, recon_loss:0.769471, zinb_loss:0.629776, adversial_loss:1.296510
Pretrain epoch 129, recon_loss:0.769474, zinb_loss:0.629844, adversial_loss:1.296746
Pretrain epoch 130, recon_loss:0.769316, zinb_loss:0.629907, adversial_loss:1.296185
Pretrain epoch 131, recon_loss:0.769345, zinb_loss:0.630119, adversial_loss:1.296040
Pretrain epoch 132, recon_loss:0.769921, zinb_loss:0.630883, adversial_loss:1.295672
Pretrain epoch 133, recon_loss:0.769987, zinb_loss:0.631382, adversial_loss:1.295606
Pretrain epoch 134, recon_loss:0.770319, zinb_loss:0.630958, adversial_loss:1.295570
Pretrain epoch 135, recon_loss:0.769544, zinb_loss:0.630117, adversial_loss:1.293905
Pretrain epoch 136, recon_loss:0.769243, zinb_loss:0.630311, adversial_loss:1.294124
Pretrain epoch 137, recon_loss:0.769668, zinb_loss:0.630274, adversial_loss:1.294208
Pretrain epoch 138, recon_loss:0.768874, zinb_loss:0.629551, adversial_loss:1.293011
Pretrain epoch 139, recon_loss:0.769396, zinb_loss:0.630022, adversial_loss:1.292869
Pretrain epoch 140, recon_loss:0.768710, zinb_loss:0.629450, adversial_loss:1.292766
Pretrain epoch 141, recon_loss:0.768588, zinb_loss:0.629526, adversial_loss:1.292793
Pretrain epoch 142, recon_loss:0.768435, zinb_loss:0.629493, adversial_loss:1.291975
Pretrain epoch 143, recon_loss:0.768048, zinb_loss:0.629232, adversial_loss:1.291733
Pretrain epoch 144, recon_loss:0.767937, zinb_loss:0.629348, adversial_loss:1.292000
Pretrain epoch 145, recon_loss:0.767733, zinb_loss:0.629056, adversial_loss:1.291455
Pretrain epoch 146, recon_loss:0.767740, zinb_loss:0.629110, adversial_loss:1.290631
Pretrain epoch 147, recon_loss:0.767510, zinb_loss:0.628934, adversial_loss:1.290836
Pretrain epoch 148, recon_loss:0.767375, zinb_loss:0.628849, adversial_loss:1.291117
Pretrain epoch 149, recon_loss:0.767231, zinb_loss:0.628824, adversial_loss:1.290537
Pretrain epoch 150, recon_loss:0.767011, zinb_loss:0.628681, adversial_loss:1.289755
Pretrain epoch 151, recon_loss:0.766930, zinb_loss:0.628695, adversial_loss:1.289879
Pretrain epoch 152, recon_loss:0.766698, zinb_loss:0.628563, adversial_loss:1.289621
Pretrain epoch 153, recon_loss:0.766584, zinb_loss:0.628529, adversial_loss:1.289369
Pretrain epoch 154, recon_loss:0.766406, zinb_loss:0.628483, adversial_loss:1.288932
Pretrain epoch 155, recon_loss:0.766286, zinb_loss:0.628409, adversial_loss:1.288240
Pretrain epoch 156, recon_loss:0.766156, zinb_loss:0.628336, adversial_loss:1.287966
Pretrain epoch 157, recon_loss:0.765973, zinb_loss:0.628333, adversial_loss:1.288143
Pretrain epoch 158, recon_loss:0.765870, zinb_loss:0.628206, adversial_loss:1.287627
Pretrain epoch 159, recon_loss:0.765755, zinb_loss:0.628209, adversial_loss:1.287160
Pretrain epoch 160, recon_loss:0.765601, zinb_loss:0.628156, adversial_loss:1.286916
Pretrain epoch 161, recon_loss:0.765482, zinb_loss:0.628089, adversial_loss:1.286921
Pretrain epoch 162, recon_loss:0.765553, zinb_loss:0.628178, adversial_loss:1.285903
Pretrain epoch 163, recon_loss:0.765706, zinb_loss:0.628333, adversial_loss:1.286662
Pretrain epoch 164, recon_loss:0.766546, zinb_loss:0.629138, adversial_loss:1.285251
Pretrain epoch 165, recon_loss:0.767097, zinb_loss:0.629627, adversial_loss:1.285976
Pretrain epoch 166, recon_loss:0.766208, zinb_loss:0.628702, adversial_loss:1.284390
Pretrain epoch 167, recon_loss:0.765260, zinb_loss:0.628191, adversial_loss:1.283949
Pretrain epoch 168, recon_loss:0.766244, zinb_loss:0.628701, adversial_loss:1.284614
Pretrain epoch 169, recon_loss:0.765279, zinb_loss:0.628139, adversial_loss:1.283516
Pretrain epoch 170, recon_loss:0.765658, zinb_loss:0.628244, adversial_loss:1.283159
Pretrain epoch 171, recon_loss:0.765288, zinb_loss:0.628052, adversial_loss:1.283587
Pretrain epoch 172, recon_loss:0.764857, zinb_loss:0.627844, adversial_loss:1.283251
Pretrain epoch 173, recon_loss:0.765260, zinb_loss:0.628118, adversial_loss:1.282436
Pretrain epoch 174, recon_loss:0.764392, zinb_loss:0.627717, adversial_loss:1.282285
Pretrain epoch 175, recon_loss:0.764773, zinb_loss:0.627935, adversial_loss:1.282586
Pretrain epoch 176, recon_loss:0.764257, zinb_loss:0.627658, adversial_loss:1.281763
Pretrain epoch 177, recon_loss:0.764276, zinb_loss:0.627682, adversial_loss:1.281396
Pretrain epoch 178, recon_loss:0.764062, zinb_loss:0.627596, adversial_loss:1.281657
Pretrain epoch 179, recon_loss:0.763986, zinb_loss:0.627492, adversial_loss:1.281358
Pretrain epoch 180, recon_loss:0.763848, zinb_loss:0.627575, adversial_loss:1.280781
Pretrain epoch 181, recon_loss:0.763658, zinb_loss:0.627387, adversial_loss:1.280916
Pretrain epoch 182, recon_loss:0.763669, zinb_loss:0.627456, adversial_loss:1.280822
Pretrain epoch 183, recon_loss:0.763358, zinb_loss:0.627285, adversial_loss:1.280413
Pretrain epoch 184, recon_loss:0.763430, zinb_loss:0.627338, adversial_loss:1.279923
Pretrain epoch 185, recon_loss:0.763196, zinb_loss:0.627269, adversial_loss:1.279783
Pretrain epoch 186, recon_loss:0.763281, zinb_loss:0.627313, adversial_loss:1.280205
Pretrain epoch 187, recon_loss:0.763191, zinb_loss:0.627381, adversial_loss:1.279038
Pretrain epoch 188, recon_loss:0.763060, zinb_loss:0.627429, adversial_loss:1.278970
Pretrain epoch 189, recon_loss:0.763346, zinb_loss:0.627577, adversial_loss:1.279608
Pretrain epoch 190, recon_loss:0.762973, zinb_loss:0.627280, adversial_loss:1.278903
Pretrain epoch 191, recon_loss:0.763026, zinb_loss:0.627135, adversial_loss:1.278417
Pretrain epoch 192, recon_loss:0.762511, zinb_loss:0.626993, adversial_loss:1.278164
Pretrain epoch 193, recon_loss:0.762645, zinb_loss:0.627139, adversial_loss:1.278583
Pretrain epoch 194, recon_loss:0.762589, zinb_loss:0.627038, adversial_loss:1.277658
Pretrain epoch 195, recon_loss:0.762198, zinb_loss:0.626901, adversial_loss:1.277149
Pretrain epoch 196, recon_loss:0.762336, zinb_loss:0.626877, adversial_loss:1.277972
Pretrain epoch 197, recon_loss:0.762059, zinb_loss:0.626925, adversial_loss:1.276962
Pretrain epoch 198, recon_loss:0.761929, zinb_loss:0.626830, adversial_loss:1.276672
Pretrain epoch 199, recon_loss:0.761676, zinb_loss:0.626703, adversial_loss:1.276777
Pretrain epoch 200, recon_loss:0.761598, zinb_loss:0.626732, adversial_loss:1.276787
Pretrain epoch 201, recon_loss:0.761551, zinb_loss:0.626729, adversial_loss:1.276282
Pretrain epoch 202, recon_loss:0.761438, zinb_loss:0.626608, adversial_loss:1.275815
Pretrain epoch 203, recon_loss:0.761329, zinb_loss:0.626583, adversial_loss:1.276529
Pretrain epoch 204, recon_loss:0.761202, zinb_loss:0.626573, adversial_loss:1.275519
Pretrain epoch 205, recon_loss:0.761257, zinb_loss:0.626585, adversial_loss:1.275652
Pretrain epoch 206, recon_loss:0.761152, zinb_loss:0.626577, adversial_loss:1.275099
Pretrain epoch 207, recon_loss:0.761234, zinb_loss:0.626690, adversial_loss:1.275626
Pretrain epoch 208, recon_loss:0.761665, zinb_loss:0.627107, adversial_loss:1.273614
Pretrain epoch 209, recon_loss:0.761999, zinb_loss:0.627263, adversial_loss:1.275154
Pretrain epoch 210, recon_loss:0.761713, zinb_loss:0.627031, adversial_loss:1.273631
Pretrain epoch 211, recon_loss:0.760860, zinb_loss:0.626554, adversial_loss:1.273066
Pretrain epoch 212, recon_loss:0.761342, zinb_loss:0.626922, adversial_loss:1.274019
Pretrain epoch 213, recon_loss:0.762381, zinb_loss:0.627192, adversial_loss:1.272925
Pretrain epoch 214, recon_loss:0.761405, zinb_loss:0.626692, adversial_loss:1.273736
Pretrain epoch 215, recon_loss:0.761456, zinb_loss:0.626911, adversial_loss:1.272705
Pretrain epoch 216, recon_loss:0.760689, zinb_loss:0.626513, adversial_loss:1.272339
Pretrain epoch 217, recon_loss:0.760589, zinb_loss:0.626463, adversial_loss:1.273166
Pretrain epoch 218, recon_loss:0.760831, zinb_loss:0.626679, adversial_loss:1.272440
Pretrain epoch 219, recon_loss:0.760364, zinb_loss:0.626378, adversial_loss:1.271747
Pretrain epoch 220, recon_loss:0.760391, zinb_loss:0.626402, adversial_loss:1.272083
Pretrain epoch 221, recon_loss:0.759937, zinb_loss:0.626285, adversial_loss:1.272450
Pretrain epoch 222, recon_loss:0.760152, zinb_loss:0.626306, adversial_loss:1.271766
Pretrain epoch 223, recon_loss:0.759920, zinb_loss:0.626314, adversial_loss:1.271065
Pretrain epoch 224, recon_loss:0.759479, zinb_loss:0.626046, adversial_loss:1.271957
Pretrain epoch 225, recon_loss:0.759670, zinb_loss:0.626167, adversial_loss:1.271603
Pretrain epoch 226, recon_loss:0.759341, zinb_loss:0.626084, adversial_loss:1.270462
Pretrain epoch 227, recon_loss:0.759355, zinb_loss:0.626023, adversial_loss:1.271136
Pretrain epoch 228, recon_loss:0.758976, zinb_loss:0.625971, adversial_loss:1.271234
Pretrain epoch 229, recon_loss:0.759075, zinb_loss:0.625943, adversial_loss:1.270373
Pretrain epoch 230, recon_loss:0.758902, zinb_loss:0.625946, adversial_loss:1.270608
Pretrain epoch 231, recon_loss:0.758847, zinb_loss:0.625828, adversial_loss:1.270542
Pretrain epoch 232, recon_loss:0.758621, zinb_loss:0.625816, adversial_loss:1.270036
Pretrain epoch 233, recon_loss:0.758484, zinb_loss:0.625754, adversial_loss:1.269886
Pretrain epoch 234, recon_loss:0.758580, zinb_loss:0.625754, adversial_loss:1.269803
Pretrain epoch 235, recon_loss:0.758282, zinb_loss:0.625766, adversial_loss:1.269494
Pretrain epoch 236, recon_loss:0.758247, zinb_loss:0.625758, adversial_loss:1.269161
Pretrain epoch 237, recon_loss:0.758274, zinb_loss:0.625919, adversial_loss:1.269464
Pretrain epoch 238, recon_loss:0.758416, zinb_loss:0.626123, adversial_loss:1.269094
Pretrain epoch 239, recon_loss:0.759425, zinb_loss:0.627000, adversial_loss:1.268666
Pretrain epoch 240, recon_loss:0.759433, zinb_loss:0.627312, adversial_loss:1.269424
Pretrain epoch 241, recon_loss:0.758946, zinb_loss:0.626515, adversial_loss:1.268044
Pretrain epoch 242, recon_loss:0.758398, zinb_loss:0.625859, adversial_loss:1.267596
Pretrain epoch 243, recon_loss:0.758400, zinb_loss:0.626189, adversial_loss:1.267879
Pretrain epoch 244, recon_loss:0.758251, zinb_loss:0.625972, adversial_loss:1.267945
Pretrain epoch 245, recon_loss:0.757926, zinb_loss:0.625754, adversial_loss:1.267376
Pretrain epoch 246, recon_loss:0.758450, zinb_loss:0.625991, adversial_loss:1.267111
Pretrain epoch 247, recon_loss:0.757817, zinb_loss:0.625638, adversial_loss:1.267705
Pretrain epoch 248, recon_loss:0.757740, zinb_loss:0.625709, adversial_loss:1.267026
Pretrain epoch 249, recon_loss:0.757581, zinb_loss:0.625628, adversial_loss:1.266837
Pretrain epoch 250, recon_loss:0.757324, zinb_loss:0.625543, adversial_loss:1.267304
Pretrain epoch 251, recon_loss:0.757314, zinb_loss:0.625634, adversial_loss:1.266793
Pretrain epoch 252, recon_loss:0.756889, zinb_loss:0.625389, adversial_loss:1.266628
Pretrain epoch 253, recon_loss:0.756935, zinb_loss:0.625487, adversial_loss:1.266536
Pretrain epoch 254, recon_loss:0.756694, zinb_loss:0.625405, adversial_loss:1.266254
Pretrain epoch 255, recon_loss:0.756546, zinb_loss:0.625338, adversial_loss:1.265859
Pretrain epoch 256, recon_loss:0.756459, zinb_loss:0.625372, adversial_loss:1.265898
Pretrain epoch 257, recon_loss:0.756208, zinb_loss:0.625240, adversial_loss:1.265420
Pretrain epoch 258, recon_loss:0.756110, zinb_loss:0.625279, adversial_loss:1.265282
Pretrain epoch 259, recon_loss:0.755972, zinb_loss:0.625202, adversial_loss:1.264920
Pretrain epoch 260, recon_loss:0.755845, zinb_loss:0.625181, adversial_loss:1.264856
Pretrain epoch 261, recon_loss:0.755776, zinb_loss:0.625212, adversial_loss:1.264385
Pretrain epoch 262, recon_loss:0.755658, zinb_loss:0.625171, adversial_loss:1.264643
Pretrain epoch 263, recon_loss:0.755740, zinb_loss:0.625268, adversial_loss:1.263762
Pretrain epoch 264, recon_loss:0.755793, zinb_loss:0.625322, adversial_loss:1.264693
Pretrain epoch 265, recon_loss:0.756047, zinb_loss:0.625576, adversial_loss:1.263003
Pretrain epoch 266, recon_loss:0.756053, zinb_loss:0.625506, adversial_loss:1.264240
Pretrain epoch 267, recon_loss:0.755714, zinb_loss:0.625297, adversial_loss:1.262850
Pretrain epoch 268, recon_loss:0.755153, zinb_loss:0.625064, adversial_loss:1.263153
Pretrain epoch 269, recon_loss:0.755243, zinb_loss:0.625092, adversial_loss:1.263150
Pretrain epoch 270, recon_loss:0.755230, zinb_loss:0.625185, adversial_loss:1.262389
Pretrain epoch 271, recon_loss:0.755256, zinb_loss:0.625203, adversial_loss:1.262950
Pretrain epoch 272, recon_loss:0.755542, zinb_loss:0.625343, adversial_loss:1.262252
Pretrain epoch 273, recon_loss:0.756221, zinb_loss:0.625609, adversial_loss:1.262175
Pretrain epoch 274, recon_loss:0.757112, zinb_loss:0.625953, adversial_loss:1.262888
Pretrain epoch 275, recon_loss:0.757585, zinb_loss:0.626125, adversial_loss:1.261826
Pretrain epoch 276, recon_loss:0.755297, zinb_loss:0.625102, adversial_loss:1.261289
Pretrain epoch 277, recon_loss:0.755384, zinb_loss:0.625368, adversial_loss:1.261689
Pretrain epoch 278, recon_loss:0.756129, zinb_loss:0.625459, adversial_loss:1.260738
Pretrain epoch 279, recon_loss:0.754724, zinb_loss:0.625007, adversial_loss:1.260598
Pretrain epoch 280, recon_loss:0.755369, zinb_loss:0.625379, adversial_loss:1.261417
Pretrain epoch 281, recon_loss:0.754782, zinb_loss:0.624991, adversial_loss:1.260518
Pretrain epoch 282, recon_loss:0.754534, zinb_loss:0.625051, adversial_loss:1.259917
Pretrain epoch 283, recon_loss:0.754491, zinb_loss:0.625008, adversial_loss:1.260628
Pretrain epoch 284, recon_loss:0.754288, zinb_loss:0.624848, adversial_loss:1.260599
Pretrain epoch 285, recon_loss:0.754080, zinb_loss:0.624923, adversial_loss:1.259742
Pretrain epoch 286, recon_loss:0.753993, zinb_loss:0.624777, adversial_loss:1.259850
Pretrain epoch 287, recon_loss:0.753858, zinb_loss:0.624777, adversial_loss:1.260215
Pretrain epoch 288, recon_loss:0.753481, zinb_loss:0.624721, adversial_loss:1.259990
Pretrain epoch 289, recon_loss:0.753600, zinb_loss:0.624683, adversial_loss:1.259371
Pretrain epoch 290, recon_loss:0.753198, zinb_loss:0.624659, adversial_loss:1.259436
Pretrain epoch 291, recon_loss:0.753150, zinb_loss:0.624620, adversial_loss:1.259738
Pretrain epoch 292, recon_loss:0.753045, zinb_loss:0.624606, adversial_loss:1.259176
Pretrain epoch 293, recon_loss:0.752695, zinb_loss:0.624578, adversial_loss:1.258881
Pretrain epoch 294, recon_loss:0.752711, zinb_loss:0.624557, adversial_loss:1.259076
Pretrain epoch 295, recon_loss:0.752386, zinb_loss:0.624516, adversial_loss:1.258735
Pretrain epoch 296, recon_loss:0.752381, zinb_loss:0.624503, adversial_loss:1.258430
Pretrain epoch 297, recon_loss:0.752095, zinb_loss:0.624473, adversial_loss:1.258393
Pretrain epoch 298, recon_loss:0.752020, zinb_loss:0.624451, adversial_loss:1.258269
Pretrain epoch 299, recon_loss:0.751884, zinb_loss:0.624454, adversial_loss:1.257985
Pretrain epoch 300, recon_loss:0.751720, zinb_loss:0.624407, adversial_loss:1.257759
Pretrain epoch 301, recon_loss:0.751619, zinb_loss:0.624393, adversial_loss:1.257720
Pretrain epoch 302, recon_loss:0.751603, zinb_loss:0.624389, adversial_loss:1.257465
Pretrain epoch 303, recon_loss:0.751616, zinb_loss:0.624417, adversial_loss:1.257201
Pretrain epoch 304, recon_loss:0.751976, zinb_loss:0.624573, adversial_loss:1.257134
Pretrain epoch 305, recon_loss:0.753156, zinb_loss:0.625050, adversial_loss:1.257288
Pretrain epoch 306, recon_loss:0.754855, zinb_loss:0.625786, adversial_loss:1.256867
Pretrain epoch 307, recon_loss:0.754816, zinb_loss:0.626012, adversial_loss:1.256853
Pretrain epoch 308, recon_loss:0.751676, zinb_loss:0.624669, adversial_loss:1.256409
Pretrain epoch 309, recon_loss:0.752470, zinb_loss:0.624667, adversial_loss:1.256081
Pretrain epoch 310, recon_loss:0.753001, zinb_loss:0.625094, adversial_loss:1.256042
Pretrain epoch 311, recon_loss:0.751207, zinb_loss:0.624419, adversial_loss:1.255652
Pretrain epoch 312, recon_loss:0.752243, zinb_loss:0.624646, adversial_loss:1.255806
Pretrain epoch 313, recon_loss:0.751611, zinb_loss:0.624558, adversial_loss:1.255658
Pretrain epoch 314, recon_loss:0.751132, zinb_loss:0.624370, adversial_loss:1.255069
Pretrain epoch 315, recon_loss:0.751409, zinb_loss:0.624456, adversial_loss:1.255266
Pretrain epoch 316, recon_loss:0.750799, zinb_loss:0.624303, adversial_loss:1.255428
Pretrain epoch 317, recon_loss:0.750899, zinb_loss:0.624351, adversial_loss:1.254581
Pretrain epoch 318, recon_loss:0.750526, zinb_loss:0.624260, adversial_loss:1.254706
Pretrain epoch 319, recon_loss:0.750601, zinb_loss:0.624306, adversial_loss:1.255149
Pretrain epoch 320, recon_loss:0.750154, zinb_loss:0.624208, adversial_loss:1.254608
Pretrain epoch 321, recon_loss:0.750454, zinb_loss:0.624261, adversial_loss:1.253649
Pretrain epoch 322, recon_loss:0.750311, zinb_loss:0.624279, adversial_loss:1.255018
Pretrain epoch 323, recon_loss:0.750246, zinb_loss:0.624426, adversial_loss:1.253833
Pretrain epoch 324, recon_loss:0.750702, zinb_loss:0.624627, adversial_loss:1.253942
Pretrain epoch 325, recon_loss:0.750848, zinb_loss:0.624686, adversial_loss:1.253212
Pretrain epoch 326, recon_loss:0.750545, zinb_loss:0.624489, adversial_loss:1.254483
Pretrain epoch 327, recon_loss:0.749625, zinb_loss:0.624184, adversial_loss:1.252910
Pretrain epoch 328, recon_loss:0.749357, zinb_loss:0.624110, adversial_loss:1.252911
Pretrain epoch 329, recon_loss:0.749682, zinb_loss:0.624217, adversial_loss:1.253526
Pretrain epoch 330, recon_loss:0.749361, zinb_loss:0.624243, adversial_loss:1.252541
Pretrain epoch 331, recon_loss:0.749046, zinb_loss:0.624085, adversial_loss:1.252763
Pretrain epoch 332, recon_loss:0.748671, zinb_loss:0.623996, adversial_loss:1.252374
Pretrain epoch 333, recon_loss:0.748825, zinb_loss:0.624106, adversial_loss:1.252345
Pretrain epoch 334, recon_loss:0.748693, zinb_loss:0.624035, adversial_loss:1.252432
Pretrain epoch 335, recon_loss:0.748310, zinb_loss:0.623969, adversial_loss:1.251544
Pretrain epoch 336, recon_loss:0.748171, zinb_loss:0.623935, adversial_loss:1.252011
Pretrain epoch 337, recon_loss:0.748107, zinb_loss:0.623957, adversial_loss:1.252016
Pretrain epoch 338, recon_loss:0.748038, zinb_loss:0.623936, adversial_loss:1.250951
Pretrain epoch 339, recon_loss:0.747790, zinb_loss:0.623863, adversial_loss:1.251737
Pretrain epoch 340, recon_loss:0.747788, zinb_loss:0.623857, adversial_loss:1.251112
Pretrain epoch 341, recon_loss:0.747594, zinb_loss:0.623835, adversial_loss:1.250883
Pretrain epoch 342, recon_loss:0.747351, zinb_loss:0.623804, adversial_loss:1.250976
Pretrain epoch 343, recon_loss:0.747299, zinb_loss:0.623808, adversial_loss:1.250553
Pretrain epoch 344, recon_loss:0.747291, zinb_loss:0.623843, adversial_loss:1.250751
Pretrain epoch 345, recon_loss:0.747353, zinb_loss:0.623880, adversial_loss:1.250244
Pretrain epoch 346, recon_loss:0.747712, zinb_loss:0.623967, adversial_loss:1.250278
Pretrain epoch 347, recon_loss:0.748533, zinb_loss:0.624176, adversial_loss:1.250290
Pretrain epoch 348, recon_loss:0.749864, zinb_loss:0.624498, adversial_loss:1.249875
Pretrain epoch 349, recon_loss:0.749792, zinb_loss:0.624604, adversial_loss:1.249688
Pretrain epoch 350, recon_loss:0.747748, zinb_loss:0.624104, adversial_loss:1.249543
Pretrain epoch 351, recon_loss:0.747056, zinb_loss:0.623864, adversial_loss:1.248984
Pretrain epoch 352, recon_loss:0.748128, zinb_loss:0.624133, adversial_loss:1.249011
Pretrain epoch 353, recon_loss:0.747624, zinb_loss:0.624018, adversial_loss:1.249153
Pretrain epoch 354, recon_loss:0.746567, zinb_loss:0.623769, adversial_loss:1.248775
Pretrain epoch 355, recon_loss:0.746866, zinb_loss:0.623964, adversial_loss:1.248478
Pretrain epoch 356, recon_loss:0.746527, zinb_loss:0.623889, adversial_loss:1.248987
Pretrain epoch 357, recon_loss:0.746377, zinb_loss:0.623701, adversial_loss:1.248239
Pretrain epoch 358, recon_loss:0.746282, zinb_loss:0.623742, adversial_loss:1.248244
Pretrain epoch 359, recon_loss:0.746046, zinb_loss:0.623740, adversial_loss:1.248407
Pretrain epoch 360, recon_loss:0.745941, zinb_loss:0.623657, adversial_loss:1.248133
Pretrain epoch 361, recon_loss:0.745735, zinb_loss:0.623707, adversial_loss:1.247800
Pretrain epoch 362, recon_loss:0.745730, zinb_loss:0.623680, adversial_loss:1.248000
Pretrain epoch 363, recon_loss:0.745833, zinb_loss:0.623627, adversial_loss:1.247833
Pretrain epoch 364, recon_loss:0.745583, zinb_loss:0.623639, adversial_loss:1.247455
Pretrain epoch 365, recon_loss:0.745557, zinb_loss:0.623658, adversial_loss:1.247508
Pretrain epoch 366, recon_loss:0.745358, zinb_loss:0.623622, adversial_loss:1.247385
Pretrain epoch 367, recon_loss:0.745166, zinb_loss:0.623627, adversial_loss:1.247007
Pretrain epoch 368, recon_loss:0.745114, zinb_loss:0.623602, adversial_loss:1.247067
Pretrain epoch 369, recon_loss:0.745092, zinb_loss:0.623547, adversial_loss:1.246902
Pretrain epoch 370, recon_loss:0.744758, zinb_loss:0.623542, adversial_loss:1.246693
Pretrain epoch 371, recon_loss:0.745036, zinb_loss:0.623572, adversial_loss:1.246650
Pretrain epoch 372, recon_loss:0.744833, zinb_loss:0.623528, adversial_loss:1.246337
Pretrain epoch 373, recon_loss:0.744253, zinb_loss:0.623511, adversial_loss:1.246203
Pretrain epoch 374, recon_loss:0.744213, zinb_loss:0.623551, adversial_loss:1.246197
Pretrain epoch 375, recon_loss:0.744185, zinb_loss:0.623590, adversial_loss:1.245750
Pretrain epoch 376, recon_loss:0.744927, zinb_loss:0.623700, adversial_loss:1.245964
Pretrain epoch 377, recon_loss:0.745542, zinb_loss:0.623854, adversial_loss:1.245949
Pretrain epoch 378, recon_loss:0.746172, zinb_loss:0.624132, adversial_loss:1.245143
Pretrain epoch 379, recon_loss:0.745374, zinb_loss:0.624021, adversial_loss:1.246134
Pretrain epoch 380, recon_loss:0.744613, zinb_loss:0.623714, adversial_loss:1.244378
Pretrain epoch 381, recon_loss:0.745395, zinb_loss:0.623964, adversial_loss:1.245559
Pretrain epoch 382, recon_loss:0.745601, zinb_loss:0.624205, adversial_loss:1.244211
Pretrain epoch 383, recon_loss:0.744020, zinb_loss:0.623674, adversial_loss:1.245310
Pretrain epoch 384, recon_loss:0.744484, zinb_loss:0.623604, adversial_loss:1.244278
Pretrain epoch 385, recon_loss:0.744280, zinb_loss:0.623744, adversial_loss:1.244271
Pretrain epoch 386, recon_loss:0.744052, zinb_loss:0.623587, adversial_loss:1.244613
Pretrain epoch 387, recon_loss:0.743644, zinb_loss:0.623512, adversial_loss:1.244011
Pretrain epoch 388, recon_loss:0.743463, zinb_loss:0.623467, adversial_loss:1.243936
Pretrain epoch 389, recon_loss:0.743408, zinb_loss:0.623382, adversial_loss:1.244285
Pretrain epoch 390, recon_loss:0.742802, zinb_loss:0.623369, adversial_loss:1.243493
Pretrain epoch 391, recon_loss:0.742870, zinb_loss:0.623338, adversial_loss:1.243549
Pretrain epoch 392, recon_loss:0.742498, zinb_loss:0.623299, adversial_loss:1.243875
Pretrain epoch 393, recon_loss:0.742168, zinb_loss:0.623262, adversial_loss:1.243256
Pretrain epoch 394, recon_loss:0.742424, zinb_loss:0.623246, adversial_loss:1.243256
Pretrain epoch 395, recon_loss:0.741983, zinb_loss:0.623228, adversial_loss:1.243176
Pretrain epoch 396, recon_loss:0.741756, zinb_loss:0.623253, adversial_loss:1.243132
Pretrain epoch 397, recon_loss:0.742005, zinb_loss:0.623249, adversial_loss:1.242527
Pretrain epoch 398, recon_loss:0.742020, zinb_loss:0.623239, adversial_loss:1.243070
Pretrain epoch 399, recon_loss:0.742514, zinb_loss:0.623436, adversial_loss:1.241964
Pretrain epoch 400, recon_loss:0.743174, zinb_loss:0.623717, adversial_loss:1.243144
</pre></div></div>
</div>
<p>When the parameter n_cluster is set to -1, scMAGCA will use GetCluster to estimate the number of clusters according to the resolution parameter and the potential representation obtained by pre-training, and use ASW, DB index and CH value to evaluate the clustering results.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_pred</span><span class="p">,</span> <span class="n">final_latent</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">2000</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="s1">&#39;GSM4949911_tea&#39;</span><span class="p">,</span>
                                 <span class="n">pretrain_latent</span><span class="o">=</span><span class="n">pretrain_latent</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Clustering stage
Initializing cluster centers with kmeans.
Initializing k-means: ASW= 0.4081, DB= 0.9771, CH= 4057.4425
Training epoch 1, recon_loss:0.744567, zinb_loss:0.624116, cluster_loss:0.184134
Clustering   1: ASW= 0.4081, DB= 0.9771, CH= 4057.4425
Training epoch 2, recon_loss:0.781684, zinb_loss:0.635306, cluster_loss:0.192307
Clustering   2: ASW= 0.5035, DB= 0.7872, CH= 7048.4868
Training epoch 3, recon_loss:0.781879, zinb_loss:0.638056, cluster_loss:0.199501
Clustering   3: ASW= 0.5203, DB= 0.7576, CH= 7181.4846
Training epoch 4, recon_loss:0.802478, zinb_loss:0.644835, cluster_loss:0.204655
Clustering   4: ASW= 0.5511, DB= 0.7052, CH= 9237.8673
Training epoch 5, recon_loss:0.788960, zinb_loss:0.637543, cluster_loss:0.195610
Clustering   5: ASW= 0.5629, DB= 0.6762, CH= 9559.8021
Training epoch 6, recon_loss:0.791756, zinb_loss:0.640890, cluster_loss:0.195503
Clustering   6: ASW= 0.5875, DB= 0.6388, CH= 10485.6587
Training epoch 7, recon_loss:0.788115, zinb_loss:0.639390, cluster_loss:0.190574
Clustering   7: ASW= 0.5878, DB= 0.6310, CH= 10706.3957
Training epoch 8, recon_loss:0.795532, zinb_loss:0.643657, cluster_loss:0.196299
Clustering   8: ASW= 0.6004, DB= 0.6067, CH= 11318.9830
Training epoch 9, recon_loss:0.793502, zinb_loss:0.644986, cluster_loss:0.191464
Clustering   9: ASW= 0.6066, DB= 0.5921, CH= 12165.7921
Training epoch 10, recon_loss:0.795640, zinb_loss:0.645226, cluster_loss:0.193899
Clustering   10: ASW= 0.6189, DB= 0.5795, CH= 12337.0980
Training epoch 11, recon_loss:0.794627, zinb_loss:0.646246, cluster_loss:0.190530
Clustering   11: ASW= 0.6209, DB= 0.5646, CH= 13181.4561
Training epoch 12, recon_loss:0.793503, zinb_loss:0.643653, cluster_loss:0.191122
Clustering   12: ASW= 0.6333, DB= 0.5539, CH= 13114.1243
Training epoch 13, recon_loss:0.790501, zinb_loss:0.643247, cluster_loss:0.185939
Clustering   13: ASW= 0.6322, DB= 0.5480, CH= 13909.9101
Training epoch 14, recon_loss:0.791912, zinb_loss:0.644665, cluster_loss:0.186220
Clustering   14: ASW= 0.6435, DB= 0.5346, CH= 13930.9664
Training epoch 15, recon_loss:0.789298, zinb_loss:0.644028, cluster_loss:0.182875
Clustering   15: ASW= 0.6452, DB= 0.5299, CH= 14541.9165
Training epoch 16, recon_loss:0.790982, zinb_loss:0.644929, cluster_loss:0.183325
Clustering   16: ASW= 0.6533, DB= 0.5175, CH= 14713.5949
Training epoch 17, recon_loss:0.789246, zinb_loss:0.643808, cluster_loss:0.181418
Clustering   17: ASW= 0.6554, DB= 0.5132, CH= 15224.9930
Training epoch 18, recon_loss:0.791492, zinb_loss:0.645494, cluster_loss:0.181958
Clustering   18: ASW= 0.6629, DB= 0.5014, CH= 15485.4823
Training epoch 19, recon_loss:0.789743, zinb_loss:0.644231, cluster_loss:0.180452
Clustering   19: ASW= 0.6651, DB= 0.4963, CH= 15993.7179
Training epoch 20, recon_loss:0.791554, zinb_loss:0.645630, cluster_loss:0.180706
Clustering   20: ASW= 0.6718, DB= 0.4855, CH= 16238.4130
Training epoch 21, recon_loss:0.789927, zinb_loss:0.644363, cluster_loss:0.179470
Clustering   21: ASW= 0.6741, DB= 0.4805, CH= 16741.5947
Training epoch 22, recon_loss:0.791409, zinb_loss:0.645626, cluster_loss:0.179546
Clustering   22: ASW= 0.6800, DB= 0.4708, CH= 16957.5644
Training epoch 23, recon_loss:0.790026, zinb_loss:0.644476, cluster_loss:0.178504
Clustering   23: ASW= 0.6824, DB= 0.4654, CH= 17467.1475
Training epoch 24, recon_loss:0.791160, zinb_loss:0.645633, cluster_loss:0.178435
Clustering   24: ASW= 0.6876, DB= 0.4572, CH= 17651.8670
Training epoch 25, recon_loss:0.790033, zinb_loss:0.644636, cluster_loss:0.177479
Clustering   25: ASW= 0.6899, DB= 0.4520, CH= 18159.1258
Training epoch 26, recon_loss:0.790941, zinb_loss:0.645726, cluster_loss:0.177350
Clustering   26: ASW= 0.6945, DB= 0.4448, CH= 18320.8315
Training epoch 27, recon_loss:0.790051, zinb_loss:0.644885, cluster_loss:0.176457
Clustering   27: ASW= 0.6965, DB= 0.4400, CH= 18799.5358
Training epoch 28, recon_loss:0.790884, zinb_loss:0.645942, cluster_loss:0.176336
Clustering   28: ASW= 0.7009, DB= 0.4337, CH= 18973.0495
Training epoch 29, recon_loss:0.790154, zinb_loss:0.645214, cluster_loss:0.175504
Clustering   29: ASW= 0.7021, DB= 0.4284, CH= 19374.2514
Training epoch 30, recon_loss:0.790992, zinb_loss:0.646239, cluster_loss:0.175394
Clustering   30: ASW= 0.7066, DB= 0.4239, CH= 19596.3244
Training epoch 31, recon_loss:0.790411, zinb_loss:0.645577, cluster_loss:0.174676
Clustering   31: ASW= 0.7069, DB= 0.4194, CH= 19914.3225
Training epoch 32, recon_loss:0.791320, zinb_loss:0.646544, cluster_loss:0.174585
Clustering   32: ASW= 0.7119, DB= 0.4148, CH= 20200.7676
Training epoch 33, recon_loss:0.790896, zinb_loss:0.645896, cluster_loss:0.174084
Clustering   33: ASW= 0.7108, DB= 0.4114, CH= 20389.9855
Training epoch 34, recon_loss:0.791883, zinb_loss:0.646757, cluster_loss:0.173998
Clustering   34: ASW= 0.7167, DB= 0.4066, CH= 20784.2287
Training epoch 35, recon_loss:0.791580, zinb_loss:0.646077, cluster_loss:0.173861
Clustering   35: ASW= 0.7142, DB= 0.4048, CH= 20818.7748
Training epoch 36, recon_loss:0.792708, zinb_loss:0.646908, cluster_loss:0.173661
Clustering   36: ASW= 0.7209, DB= 0.3997, CH= 21376.5842
Training epoch 37, recon_loss:0.792308, zinb_loss:0.646198, cluster_loss:0.173958
Clustering   37: ASW= 0.7178, DB= 0.3997, CH= 21227.3954
Training epoch 38, recon_loss:0.793536, zinb_loss:0.647071, cluster_loss:0.173452
Clustering   38: ASW= 0.7243, DB= 0.3938, CH= 21940.6146
Training epoch 39, recon_loss:0.792650, zinb_loss:0.646334, cluster_loss:0.173853
Clustering   39: ASW= 0.7216, DB= 0.3933, CH= 21605.7713
Training epoch 40, recon_loss:0.793561, zinb_loss:0.647123, cluster_loss:0.172832
Clustering   40: ASW= 0.7270, DB= 0.3889, CH= 22434.8069
Training epoch 41, recon_loss:0.792455, zinb_loss:0.646422, cluster_loss:0.173081
Clustering   41: ASW= 0.7253, DB= 0.3880, CH= 22016.1240
Training epoch 42, recon_loss:0.793121, zinb_loss:0.647158, cluster_loss:0.171864
Clustering   42: ASW= 0.7296, DB= 0.3841, CH= 22880.1381
Training epoch 43, recon_loss:0.792161, zinb_loss:0.646511, cluster_loss:0.172056
Clustering   43: ASW= 0.7285, DB= 0.3832, CH= 22441.1165
Training epoch 44, recon_loss:0.792669, zinb_loss:0.647224, cluster_loss:0.170923
Clustering   44: ASW= 0.7323, DB= 0.3801, CH= 23308.4009
Training epoch 45, recon_loss:0.791936, zinb_loss:0.646629, cluster_loss:0.171171
Clustering   45: ASW= 0.7311, DB= 0.3794, CH= 22830.8324
Training epoch 46, recon_loss:0.792408, zinb_loss:0.647386, cluster_loss:0.170139
Clustering   46: ASW= 0.7350, DB= 0.3758, CH= 23720.7644
Training epoch 47, recon_loss:0.791735, zinb_loss:0.646757, cluster_loss:0.170424
Clustering   47: ASW= 0.7334, DB= 0.3752, CH= 23184.3867
Training epoch 48, recon_loss:0.792224, zinb_loss:0.647568, cluster_loss:0.169477
Clustering   48: ASW= 0.7376, DB= 0.3716, CH= 24119.5970
Training epoch 49, recon_loss:0.791572, zinb_loss:0.646885, cluster_loss:0.169838
Clustering   49: ASW= 0.7355, DB= 0.3721, CH= 23523.7886
Training epoch 50, recon_loss:0.792151, zinb_loss:0.647766, cluster_loss:0.168988
Clustering   50: ASW= 0.7399, DB= 0.3682, CH= 24495.2883
Training epoch 51, recon_loss:0.791514, zinb_loss:0.647032, cluster_loss:0.169469
Clustering   51: ASW= 0.7374, DB= 0.3690, CH= 23838.4278
Training epoch 52, recon_loss:0.792260, zinb_loss:0.647990, cluster_loss:0.168765
Clustering   52: ASW= 0.7418, DB= 0.3664, CH= 24852.9703
Training epoch 53, recon_loss:0.791620, zinb_loss:0.647189, cluster_loss:0.169355
Clustering   53: ASW= 0.7392, DB= 0.3669, CH= 24137.3850
Training epoch 54, recon_loss:0.792565, zinb_loss:0.648117, cluster_loss:0.168693
Clustering   54: ASW= 0.7431, DB= 0.3626, CH= 25153.7847
Training epoch 55, recon_loss:0.791842, zinb_loss:0.647240, cluster_loss:0.169230
Clustering   55: ASW= 0.7412, DB= 0.3646, CH= 24445.4218
Training epoch 56, recon_loss:0.792959, zinb_loss:0.648107, cluster_loss:0.168525
Clustering   56: ASW= 0.7445, DB= 0.3594, CH= 25456.0063
Training epoch 57, recon_loss:0.791962, zinb_loss:0.647209, cluster_loss:0.168900
Clustering   57: ASW= 0.7435, DB= 0.3615, CH= 24805.0179
Training epoch 58, recon_loss:0.793046, zinb_loss:0.647981, cluster_loss:0.168251
Clustering   58: ASW= 0.7461, DB= 0.3563, CH= 25740.0570
Training epoch 59, recon_loss:0.792017, zinb_loss:0.647157, cluster_loss:0.168451
Clustering   59: ASW= 0.7455, DB= 0.3588, CH= 25160.9770
Training epoch 60, recon_loss:0.793047, zinb_loss:0.647811, cluster_loss:0.168048
Clustering   60: ASW= 0.7478, DB= 0.3540, CH= 26001.7672
Training epoch 61, recon_loss:0.792132, zinb_loss:0.647105, cluster_loss:0.168134
Clustering   61: ASW= 0.7472, DB= 0.3569, CH= 25502.1591
Training epoch 62, recon_loss:0.793054, zinb_loss:0.647648, cluster_loss:0.167881
Clustering   62: ASW= 0.7493, DB= 0.3515, CH= 26258.3489
Training epoch 63, recon_loss:0.792143, zinb_loss:0.647033, cluster_loss:0.167827
Clustering   63: ASW= 0.7487, DB= 0.3546, CH= 25811.4141
Training epoch 64, recon_loss:0.792888, zinb_loss:0.647470, cluster_loss:0.167610
Clustering   64: ASW= 0.7508, DB= 0.3495, CH= 26516.5546
Training epoch 65, recon_loss:0.791956, zinb_loss:0.646935, cluster_loss:0.167434
Clustering   65: ASW= 0.7502, DB= 0.3524, CH= 26101.7202
Training epoch 66, recon_loss:0.792565, zinb_loss:0.647317, cluster_loss:0.167206
Clustering   66: ASW= 0.7521, DB= 0.3474, CH= 26784.6218
Training epoch 67, recon_loss:0.791658, zinb_loss:0.646850, cluster_loss:0.166972
Clustering   67: ASW= 0.7517, DB= 0.3500, CH= 26380.8573
Training epoch 68, recon_loss:0.792175, zinb_loss:0.647203, cluster_loss:0.166745
Clustering   68: ASW= 0.7534, DB= 0.3456, CH= 27058.3477
Training epoch 69, recon_loss:0.791458, zinb_loss:0.646813, cluster_loss:0.166587
Clustering   69: ASW= 0.7532, DB= 0.3479, CH= 26629.1185
Training epoch 70, recon_loss:0.791937, zinb_loss:0.647191, cluster_loss:0.166368
Clustering   70: ASW= 0.7546, DB= 0.3439, CH= 27347.3599
Training epoch 71, recon_loss:0.791464, zinb_loss:0.646864, cluster_loss:0.166331
Clustering   71: ASW= 0.7546, DB= 0.3453, CH= 26882.8002
Training epoch 72, recon_loss:0.791901, zinb_loss:0.647289, cluster_loss:0.166123
Clustering   72: ASW= 0.7558, DB= 0.3417, CH= 27621.0542
Training epoch 73, recon_loss:0.791706, zinb_loss:0.647042, cluster_loss:0.166227
Clustering   73: ASW= 0.7559, DB= 0.3442, CH= 27139.2965
Training epoch 74, recon_loss:0.792051, zinb_loss:0.647543, cluster_loss:0.166005
Clustering   74: ASW= 0.7569, DB= 0.3395, CH= 27884.7212
Training epoch 75, recon_loss:0.791942, zinb_loss:0.647306, cluster_loss:0.166171
Clustering   75: ASW= 0.7572, DB= 0.3421, CH= 27372.6464
Training epoch 76, recon_loss:0.792110, zinb_loss:0.647812, cluster_loss:0.165873
Clustering   76: ASW= 0.7579, DB= 0.3380, CH= 28129.3803
Training epoch 77, recon_loss:0.791903, zinb_loss:0.647530, cluster_loss:0.166023
Clustering   77: ASW= 0.7583, DB= 0.3402, CH= 27610.8474
Training epoch 78, recon_loss:0.791952, zinb_loss:0.647974, cluster_loss:0.165621
Clustering   78: ASW= 0.7589, DB= 0.3367, CH= 28350.4636
Training epoch 79, recon_loss:0.791602, zinb_loss:0.647666, cluster_loss:0.165760
Clustering   79: ASW= 0.7593, DB= 0.3382, CH= 27862.7363
Training epoch 80, recon_loss:0.791686, zinb_loss:0.648010, cluster_loss:0.165302
Clustering   80: ASW= 0.7600, DB= 0.3357, CH= 28551.4303
Training epoch 81, recon_loss:0.791312, zinb_loss:0.647766, cluster_loss:0.165492
Clustering   81: ASW= 0.7602, DB= 0.3365, CH= 28115.4741
Training epoch 82, recon_loss:0.791460, zinb_loss:0.647985, cluster_loss:0.165009
Clustering   82: ASW= 0.7611, DB= 0.3345, CH= 28734.5324
Training epoch 83, recon_loss:0.791164, zinb_loss:0.647894, cluster_loss:0.165249
Clustering   83: ASW= 0.7610, DB= 0.3356, CH= 28402.8143
Training epoch 84, recon_loss:0.791352, zinb_loss:0.647991, cluster_loss:0.164766
Clustering   84: ASW= 0.7622, DB= 0.3332, CH= 28892.9929
Training epoch 85, recon_loss:0.791217, zinb_loss:0.648101, cluster_loss:0.165010
Clustering   85: ASW= 0.7617, DB= 0.3346, CH= 28710.5160
Training epoch 86, recon_loss:0.791365, zinb_loss:0.648078, cluster_loss:0.164574
Clustering   86: ASW= 0.7633, DB= 0.3321, CH= 29017.3921
Training epoch 87, recon_loss:0.791659, zinb_loss:0.648519, cluster_loss:0.164832
Clustering   87: ASW= 0.7624, DB= 0.3331, CH= 29044.2741
Training epoch 88, recon_loss:0.791725, zinb_loss:0.648356, cluster_loss:0.164560
Clustering   88: ASW= 0.7644, DB= 0.3316, CH= 29099.2268
Training epoch 89, recon_loss:0.792552, zinb_loss:0.649082, cluster_loss:0.164823
Clustering   89: ASW= 0.7631, DB= 0.3314, CH= 29388.3728
Training epoch 90, recon_loss:0.792114, zinb_loss:0.648588, cluster_loss:0.164634
Clustering   90: ASW= 0.7654, DB= 0.3309, CH= 29217.1969
Training epoch 91, recon_loss:0.793110, zinb_loss:0.649289, cluster_loss:0.164880
Clustering   91: ASW= 0.7637, DB= 0.3298, CH= 29646.5459
Training epoch 92, recon_loss:0.792037, zinb_loss:0.648463, cluster_loss:0.164504
Clustering   92: ASW= 0.7662, DB= 0.3299, CH= 29425.2856
Training epoch 93, recon_loss:0.793016, zinb_loss:0.649034, cluster_loss:0.164729
Clustering   93: ASW= 0.7647, DB= 0.3290, CH= 29855.6239
Training epoch 94, recon_loss:0.791845, zinb_loss:0.648197, cluster_loss:0.164285
Clustering   94: ASW= 0.7668, DB= 0.3292, CH= 29613.7612
Training epoch 95, recon_loss:0.792960, zinb_loss:0.648805, cluster_loss:0.164481
Clustering   95: ASW= 0.7659, DB= 0.3274, CH= 30072.6021
Training epoch 96, recon_loss:0.791553, zinb_loss:0.647937, cluster_loss:0.163971
Clustering   96: ASW= 0.7674, DB= 0.3287, CH= 29820.9324
Training epoch 97, recon_loss:0.792576, zinb_loss:0.648543, cluster_loss:0.164059
Clustering   97: ASW= 0.7671, DB= 0.3262, CH= 30270.7187
Training epoch 98, recon_loss:0.791022, zinb_loss:0.647711, cluster_loss:0.163519
Clustering   98: ASW= 0.7682, DB= 0.3276, CH= 30035.1755
Training epoch 99, recon_loss:0.791844, zinb_loss:0.648285, cluster_loss:0.163517
Clustering   99: ASW= 0.7680, DB= 0.3250, CH= 30463.0335
Training epoch 100, recon_loss:0.790507, zinb_loss:0.647555, cluster_loss:0.163100
Clustering   100: ASW= 0.7688, DB= 0.3264, CH= 30233.9740
Training epoch 101, recon_loss:0.791299, zinb_loss:0.648140, cluster_loss:0.163104
Clustering   101: ASW= 0.7689, DB= 0.3246, CH= 30648.5508
Training epoch 102, recon_loss:0.790149, zinb_loss:0.647484, cluster_loss:0.162793
Clustering   102: ASW= 0.7694, DB= 0.3248, CH= 30430.7393
Training epoch 103, recon_loss:0.790937, zinb_loss:0.648067, cluster_loss:0.162810
Clustering   103: ASW= 0.7697, DB= 0.3239, CH= 30831.6858
Training epoch 104, recon_loss:0.789932, zinb_loss:0.647466, cluster_loss:0.162593
Clustering   104: ASW= 0.7700, DB= 0.3237, CH= 30619.4572
Training epoch 105, recon_loss:0.790782, zinb_loss:0.648062, cluster_loss:0.162627
Clustering   105: ASW= 0.7705, DB= 0.3226, CH= 31014.7771
Training epoch 106, recon_loss:0.789860, zinb_loss:0.647489, cluster_loss:0.162502
Clustering   106: ASW= 0.7705, DB= 0.3236, CH= 30815.1758
Training epoch 107, recon_loss:0.790819, zinb_loss:0.648092, cluster_loss:0.162557
Clustering   107: ASW= 0.7713, DB= 0.3220, CH= 31183.3700
Training epoch 108, recon_loss:0.789977, zinb_loss:0.647529, cluster_loss:0.162542
Clustering   108: ASW= 0.7710, DB= 0.3228, CH= 30992.0955
Training epoch 109, recon_loss:0.791109, zinb_loss:0.648135, cluster_loss:0.162631
Clustering   109: ASW= 0.7719, DB= 0.3209, CH= 31325.5398
Training epoch 110, recon_loss:0.790383, zinb_loss:0.647578, cluster_loss:0.162762
Clustering   110: ASW= 0.7713, DB= 0.3228, CH= 31167.5080
Training epoch 111, recon_loss:0.791713, zinb_loss:0.648188, cluster_loss:0.162856
Clustering   111: ASW= 0.7726, DB= 0.3200, CH= 31440.4167
Training epoch 112, recon_loss:0.790986, zinb_loss:0.647628, cluster_loss:0.163121
Clustering   112: ASW= 0.7714, DB= 0.3222, CH= 31310.5559
Training epoch 113, recon_loss:0.792351, zinb_loss:0.648193, cluster_loss:0.163090
Clustering   113: ASW= 0.7733, DB= 0.3195, CH= 31541.7789
Training epoch 114, recon_loss:0.791462, zinb_loss:0.647629, cluster_loss:0.163362
Clustering   114: ASW= 0.7715, DB= 0.3215, CH= 31451.7911
Training epoch 115, recon_loss:0.792591, zinb_loss:0.648087, cluster_loss:0.163118
Clustering   115: ASW= 0.7739, DB= 0.3181, CH= 31619.3713
Training epoch 116, recon_loss:0.791608, zinb_loss:0.647552, cluster_loss:0.163241
Clustering   116: ASW= 0.7718, DB= 0.3206, CH= 31640.3609
Training epoch 117, recon_loss:0.792424, zinb_loss:0.647879, cluster_loss:0.162888
Clustering   117: ASW= 0.7744, DB= 0.3172, CH= 31687.6710
Training epoch 118, recon_loss:0.791625, zinb_loss:0.647466, cluster_loss:0.162862
Clustering   118: ASW= 0.7725, DB= 0.3195, CH= 31868.0086
Training epoch 119, recon_loss:0.792284, zinb_loss:0.647676, cluster_loss:0.162608
Clustering   119: ASW= 0.7748, DB= 0.3152, CH= 31723.7642
Training epoch 120, recon_loss:0.791855, zinb_loss:0.647488, cluster_loss:0.162505
Clustering   120: ASW= 0.7733, DB= 0.3188, CH= 32136.3572
Training epoch 121, recon_loss:0.792293, zinb_loss:0.647569, cluster_loss:0.162416
Clustering   121: ASW= 0.7750, DB= 0.3149, CH= 31745.1165
Training epoch 122, recon_loss:0.792150, zinb_loss:0.647669, cluster_loss:0.162275
Clustering   122: ASW= 0.7742, DB= 0.3166, CH= 32380.2880
Training epoch 123, recon_loss:0.792139, zinb_loss:0.647593, cluster_loss:0.162282
Clustering   123: ASW= 0.7750, DB= 0.3147, CH= 31769.1720
Training epoch 124, recon_loss:0.792110, zinb_loss:0.647936, cluster_loss:0.162088
Clustering   124: ASW= 0.7750, DB= 0.3154, CH= 32595.3393
Training epoch 125, recon_loss:0.791530, zinb_loss:0.647629, cluster_loss:0.162002
Clustering   125: ASW= 0.7752, DB= 0.3141, CH= 31880.2922
Training epoch 126, recon_loss:0.791491, zinb_loss:0.648025, cluster_loss:0.161784
Clustering   126: ASW= 0.7756, DB= 0.3147, CH= 32750.3761
Training epoch 127, recon_loss:0.790674, zinb_loss:0.647611, cluster_loss:0.161643
Clustering   127: ASW= 0.7757, DB= 0.3137, CH= 32057.4534
Training epoch 128, recon_loss:0.790538, zinb_loss:0.647938, cluster_loss:0.161414
Clustering   128: ASW= 0.7761, DB= 0.3131, CH= 32891.1686
Training epoch 129, recon_loss:0.789994, zinb_loss:0.647598, cluster_loss:0.161360
Clustering   129: ASW= 0.7763, DB= 0.3128, CH= 32224.6116
Training epoch 130, recon_loss:0.789937, zinb_loss:0.647914, cluster_loss:0.161178
Clustering   130: ASW= 0.7765, DB= 0.3134, CH= 33048.1193
Training epoch 131, recon_loss:0.789634, zinb_loss:0.647636, cluster_loss:0.161213
Clustering   131: ASW= 0.7768, DB= 0.3121, CH= 32376.5297
Training epoch 132, recon_loss:0.789717, zinb_loss:0.647963, cluster_loss:0.161099
Clustering   132: ASW= 0.7769, DB= 0.3128, CH= 33208.1892
Training epoch 133, recon_loss:0.789611, zinb_loss:0.647707, cluster_loss:0.161209
Clustering   133: ASW= 0.7774, DB= 0.3114, CH= 32509.1537
Training epoch 134, recon_loss:0.789891, zinb_loss:0.648032, cluster_loss:0.161167
Clustering   134: ASW= 0.7774, DB= 0.3121, CH= 33367.2963
Training epoch 135, recon_loss:0.789930, zinb_loss:0.647751, cluster_loss:0.161295
Clustering   135: ASW= 0.7779, DB= 0.3107, CH= 32634.3532
Training epoch 136, recon_loss:0.790256, zinb_loss:0.648018, cluster_loss:0.161264
Clustering   136: ASW= 0.7778, DB= 0.3106, CH= 33513.3374
Training epoch 137, recon_loss:0.790208, zinb_loss:0.647672, cluster_loss:0.161322
Clustering   137: ASW= 0.7784, DB= 0.3105, CH= 32745.6510
Training epoch 138, recon_loss:0.790391, zinb_loss:0.647878, cluster_loss:0.161230
Clustering   138: ASW= 0.7783, DB= 0.3100, CH= 33635.9323
Training epoch 139, recon_loss:0.790088, zinb_loss:0.647482, cluster_loss:0.161231
Clustering   139: ASW= 0.7788, DB= 0.3100, CH= 32859.0466
Training epoch 140, recon_loss:0.790142, zinb_loss:0.647671, cluster_loss:0.161069
Clustering   140: ASW= 0.7787, DB= 0.3103, CH= 33752.5650
Training epoch 141, recon_loss:0.789717, zinb_loss:0.647284, cluster_loss:0.161141
Clustering   141: ASW= 0.7790, DB= 0.3097, CH= 32956.8777
Training epoch 142, recon_loss:0.789876, zinb_loss:0.647508, cluster_loss:0.160954
Clustering   142: ASW= 0.7792, DB= 0.3089, CH= 33848.8049
Training epoch 143, recon_loss:0.789464, zinb_loss:0.647152, cluster_loss:0.161189
Clustering   143: ASW= 0.7792, DB= 0.3103, CH= 33052.8102
Training epoch 144, recon_loss:0.789789, zinb_loss:0.647434, cluster_loss:0.160990
Clustering   144: ASW= 0.7797, DB= 0.3078, CH= 33939.1097
Training epoch 145, recon_loss:0.789447, zinb_loss:0.647129, cluster_loss:0.161428
Clustering   145: ASW= 0.7793, DB= 0.3102, CH= 33124.0345
Training epoch 146, recon_loss:0.789799, zinb_loss:0.647474, cluster_loss:0.161149
Clustering   146: ASW= 0.7801, DB= 0.3071, CH= 34014.0696
Training epoch 147, recon_loss:0.789473, zinb_loss:0.647211, cluster_loss:0.161685
Clustering   147: ASW= 0.7793, DB= 0.3095, CH= 33217.4109
Training epoch 148, recon_loss:0.789732, zinb_loss:0.647540, cluster_loss:0.161194
Clustering   148: ASW= 0.7805, DB= 0.3067, CH= 34059.2656
Training epoch 149, recon_loss:0.789302, zinb_loss:0.647296, cluster_loss:0.161626
Clustering   149: ASW= 0.7795, DB= 0.3091, CH= 33365.1027
Training epoch 150, recon_loss:0.789441, zinb_loss:0.647519, cluster_loss:0.161005
Clustering   150: ASW= 0.7809, DB= 0.3061, CH= 34072.2818
Training epoch 151, recon_loss:0.789131, zinb_loss:0.647338, cluster_loss:0.161321
Clustering   151: ASW= 0.7797, DB= 0.3085, CH= 33545.2856
Training epoch 152, recon_loss:0.789247, zinb_loss:0.647456, cluster_loss:0.160789
Clustering   152: ASW= 0.7814, DB= 0.3055, CH= 34118.0969
Training epoch 153, recon_loss:0.789350, zinb_loss:0.647390, cluster_loss:0.161075
Clustering   153: ASW= 0.7799, DB= 0.3079, CH= 33737.9179
Training epoch 154, recon_loss:0.789473, zinb_loss:0.647395, cluster_loss:0.160680
Clustering   154: ASW= 0.7819, DB= 0.3049, CH= 34205.6265
Training epoch 155, recon_loss:0.789800, zinb_loss:0.647415, cluster_loss:0.160970
Clustering   155: ASW= 0.7801, DB= 0.3070, CH= 33895.7064
Training epoch 156, recon_loss:0.789937, zinb_loss:0.647308, cluster_loss:0.160674
Clustering   156: ASW= 0.7824, DB= 0.3045, CH= 34303.7215
Training epoch 157, recon_loss:0.790202, zinb_loss:0.647368, cluster_loss:0.160925
Clustering   157: ASW= 0.7802, DB= 0.3069, CH= 34041.6637
Training epoch 158, recon_loss:0.790305, zinb_loss:0.647213, cluster_loss:0.160733
Clustering   158: ASW= 0.7828, DB= 0.3043, CH= 34377.2423
Training epoch 159, recon_loss:0.790305, zinb_loss:0.647324, cluster_loss:0.160886
Clustering   159: ASW= 0.7803, DB= 0.3065, CH= 34148.2796
Training epoch 160, recon_loss:0.790137, zinb_loss:0.647136, cluster_loss:0.160722
Clustering   160: ASW= 0.7831, DB= 0.3042, CH= 34433.4541
Training epoch 161, recon_loss:0.789960, zinb_loss:0.647286, cluster_loss:0.160749
Clustering   161: ASW= 0.7806, DB= 0.3059, CH= 34264.2217
Training epoch 162, recon_loss:0.789572, zinb_loss:0.647085, cluster_loss:0.160563
Clustering   162: ASW= 0.7833, DB= 0.3049, CH= 34495.2659
Training epoch 163, recon_loss:0.789475, zinb_loss:0.647276, cluster_loss:0.160534
Clustering   163: ASW= 0.7811, DB= 0.3051, CH= 34416.2714
Training epoch 164, recon_loss:0.789002, zinb_loss:0.647072, cluster_loss:0.160331
Clustering   164: ASW= 0.7835, DB= 0.3048, CH= 34554.4926
Training epoch 165, recon_loss:0.789022, zinb_loss:0.647278, cluster_loss:0.160316
Clustering   165: ASW= 0.7817, DB= 0.3050, CH= 34582.6276
Training epoch 166, recon_loss:0.788554, zinb_loss:0.647097, cluster_loss:0.160096
Clustering   166: ASW= 0.7837, DB= 0.3050, CH= 34625.7116
Training epoch 167, recon_loss:0.788675, zinb_loss:0.647311, cluster_loss:0.160132
Clustering   167: ASW= 0.7822, DB= 0.3042, CH= 34739.4302
Training epoch 168, recon_loss:0.788257, zinb_loss:0.647164, cluster_loss:0.159888
Clustering   168: ASW= 0.7839, DB= 0.3046, CH= 34704.9376
Training epoch 169, recon_loss:0.788426, zinb_loss:0.647373, cluster_loss:0.159976
Clustering   169: ASW= 0.7828, DB= 0.3030, CH= 34898.1016
Training epoch 170, recon_loss:0.788167, zinb_loss:0.647290, cluster_loss:0.159731
Clustering   170: ASW= 0.7840, DB= 0.3030, CH= 34765.7245
Training epoch 171, recon_loss:0.788394, zinb_loss:0.647511, cluster_loss:0.159876
Clustering   171: ASW= 0.7832, DB= 0.3018, CH= 35037.9415
Training epoch 172, recon_loss:0.788393, zinb_loss:0.647513, cluster_loss:0.159655
Clustering   172: ASW= 0.7842, DB= 0.3026, CH= 34835.7089
Training epoch 173, recon_loss:0.788721, zinb_loss:0.647767, cluster_loss:0.159879
Clustering   173: ASW= 0.7835, DB= 0.3022, CH= 35174.6043
Training epoch 174, recon_loss:0.789079, zinb_loss:0.647865, cluster_loss:0.159703
Clustering   174: ASW= 0.7843, DB= 0.3020, CH= 34887.7394
Training epoch 175, recon_loss:0.789534, zinb_loss:0.648131, cluster_loss:0.160043
Clustering   175: ASW= 0.7837, DB= 0.3014, CH= 35251.4131
Training epoch 176, recon_loss:0.790042, zinb_loss:0.648247, cluster_loss:0.159865
Clustering   176: ASW= 0.7843, DB= 0.3019, CH= 34915.0024
Training epoch 177, recon_loss:0.790381, zinb_loss:0.648361, cluster_loss:0.160277
Clustering   177: ASW= 0.7839, DB= 0.3007, CH= 35289.9667
Training epoch 178, recon_loss:0.790610, zinb_loss:0.648408, cluster_loss:0.159975
Clustering   178: ASW= 0.7844, DB= 0.3010, CH= 34942.9135
Training epoch 179, recon_loss:0.790428, zinb_loss:0.648308, cluster_loss:0.160384
Clustering   179: ASW= 0.7840, DB= 0.3003, CH= 35323.6997
Training epoch 180, recon_loss:0.790463, zinb_loss:0.648340, cluster_loss:0.160018
Clustering   180: ASW= 0.7846, DB= 0.3009, CH= 35017.0617
Training epoch 181, recon_loss:0.789932, zinb_loss:0.648164, cluster_loss:0.160367
Clustering   181: ASW= 0.7842, DB= 0.3002, CH= 35387.8759
Training epoch 182, recon_loss:0.789944, zinb_loss:0.648180, cluster_loss:0.160067
Clustering   182: ASW= 0.7849, DB= 0.3004, CH= 35101.0235
Training epoch 183, recon_loss:0.789397, zinb_loss:0.648016, cluster_loss:0.160332
Clustering   183: ASW= 0.7844, DB= 0.3004, CH= 35452.8007
Training epoch 184, recon_loss:0.789369, zinb_loss:0.648022, cluster_loss:0.160072
Clustering   184: ASW= 0.7852, DB= 0.2998, CH= 35199.1717
Training epoch 185, recon_loss:0.788864, zinb_loss:0.647886, cluster_loss:0.160190
Clustering   185: ASW= 0.7846, DB= 0.3006, CH= 35537.0317
Training epoch 186, recon_loss:0.788791, zinb_loss:0.647859, cluster_loss:0.159958
Clustering   186: ASW= 0.7855, DB= 0.2992, CH= 35305.9777
Training epoch 187, recon_loss:0.788381, zinb_loss:0.647764, cluster_loss:0.159952
Clustering   187: ASW= 0.7849, DB= 0.3005, CH= 35640.0452
Training epoch 188, recon_loss:0.788266, zinb_loss:0.647711, cluster_loss:0.159772
Clustering   188: ASW= 0.7858, DB= 0.2988, CH= 35424.6203
Training epoch 189, recon_loss:0.787956, zinb_loss:0.647653, cluster_loss:0.159684
Clustering   189: ASW= 0.7851, DB= 0.3004, CH= 35743.0840
Training epoch 190, recon_loss:0.787825, zinb_loss:0.647595, cluster_loss:0.159570
Clustering   190: ASW= 0.7862, DB= 0.2982, CH= 35539.2503
Training epoch 191, recon_loss:0.787674, zinb_loss:0.647595, cluster_loss:0.159453
Clustering   191: ASW= 0.7855, DB= 0.3002, CH= 35852.2894
Training epoch 192, recon_loss:0.787610, zinb_loss:0.647543, cluster_loss:0.159421
Clustering   192: ASW= 0.7864, DB= 0.2994, CH= 35674.4264
Training epoch 193, recon_loss:0.787740, zinb_loss:0.647604, cluster_loss:0.159327
Clustering   193: ASW= 0.7858, DB= 0.3002, CH= 35961.0214
Training epoch 194, recon_loss:0.787893, zinb_loss:0.647555, cluster_loss:0.159423
Clustering   194: ASW= 0.7867, DB= 0.2989, CH= 35770.2504
Training epoch 195, recon_loss:0.788319, zinb_loss:0.647650, cluster_loss:0.159362
Clustering   195: ASW= 0.7862, DB= 0.2991, CH= 36035.4665
Training epoch 196, recon_loss:0.788633, zinb_loss:0.647557, cluster_loss:0.159580
Clustering   196: ASW= 0.7869, DB= 0.2986, CH= 35848.0341
Training epoch 197, recon_loss:0.788916, zinb_loss:0.647615, cluster_loss:0.159423
Clustering   197: ASW= 0.7865, DB= 0.2998, CH= 36116.0539
Training epoch 198, recon_loss:0.788901, zinb_loss:0.647423, cluster_loss:0.159595
Clustering   198: ASW= 0.7870, DB= 0.2984, CH= 35923.0315
Training epoch 199, recon_loss:0.788959, zinb_loss:0.647498, cluster_loss:0.159343
Clustering   199: ASW= 0.7869, DB= 0.2989, CH= 36158.5533
Training epoch 200, recon_loss:0.788627, zinb_loss:0.647291, cluster_loss:0.159448
Clustering   200: ASW= 0.7872, DB= 0.2981, CH= 36022.3588
Training epoch 201, recon_loss:0.788765, zinb_loss:0.647442, cluster_loss:0.159228
Clustering   201: ASW= 0.7872, DB= 0.2979, CH= 36191.0196
Training epoch 202, recon_loss:0.788382, zinb_loss:0.647327, cluster_loss:0.159301
Clustering   202: ASW= 0.7874, DB= 0.2974, CH= 36161.7040
Training epoch 203, recon_loss:0.788552, zinb_loss:0.647442, cluster_loss:0.159153
Clustering   203: ASW= 0.7875, DB= 0.2971, CH= 36218.5402
Training epoch 204, recon_loss:0.788152, zinb_loss:0.647406, cluster_loss:0.159190
Clustering   204: ASW= 0.7875, DB= 0.2978, CH= 36271.4412
Training epoch 205, recon_loss:0.788121, zinb_loss:0.647354, cluster_loss:0.159051
Clustering   205: ASW= 0.7878, DB= 0.2965, CH= 36263.0611
Training epoch 206, recon_loss:0.787602, zinb_loss:0.647322, cluster_loss:0.159021
Clustering   206: ASW= 0.7875, DB= 0.2978, CH= 36338.8404
Training epoch 207, recon_loss:0.787642, zinb_loss:0.647239, cluster_loss:0.158942
Clustering   207: ASW= 0.7880, DB= 0.2964, CH= 36324.8044
Training epoch 208, recon_loss:0.787179, zinb_loss:0.647245, cluster_loss:0.158869
Clustering   208: ASW= 0.7876, DB= 0.2979, CH= 36391.1172
Training epoch 209, recon_loss:0.787342, zinb_loss:0.647176, cluster_loss:0.158860
Clustering   209: ASW= 0.7883, DB= 0.2958, CH= 36403.2179
Training epoch 210, recon_loss:0.786963, zinb_loss:0.647211, cluster_loss:0.158753
Clustering   210: ASW= 0.7877, DB= 0.2975, CH= 36436.7100
Training epoch 211, recon_loss:0.787193, zinb_loss:0.647157, cluster_loss:0.158781
Clustering   211: ASW= 0.7886, DB= 0.2954, CH= 36500.2965
Training epoch 212, recon_loss:0.786908, zinb_loss:0.647200, cluster_loss:0.158673
Clustering   212: ASW= 0.7879, DB= 0.2967, CH= 36485.3514
Training epoch 213, recon_loss:0.787201, zinb_loss:0.647175, cluster_loss:0.158714
Clustering   213: ASW= 0.7889, DB= 0.2947, CH= 36611.0354
Training epoch 214, recon_loss:0.787015, zinb_loss:0.647202, cluster_loss:0.158642
Clustering   214: ASW= 0.7881, DB= 0.2964, CH= 36506.4855
Training epoch 215, recon_loss:0.787364, zinb_loss:0.647219, cluster_loss:0.158673
Clustering   215: ASW= 0.7891, DB= 0.2941, CH= 36734.6814
Training epoch 216, recon_loss:0.787332, zinb_loss:0.647222, cluster_loss:0.158700
Clustering   216: ASW= 0.7882, DB= 0.2958, CH= 36499.5096
Training epoch 217, recon_loss:0.787727, zinb_loss:0.647284, cluster_loss:0.158714
Clustering   217: ASW= 0.7894, DB= 0.2938, CH= 36848.7984
Training epoch 218, recon_loss:0.787858, zinb_loss:0.647252, cluster_loss:0.158845
Clustering   218: ASW= 0.7882, DB= 0.2950, CH= 36471.9399
Training epoch 219, recon_loss:0.788038, zinb_loss:0.647318, cluster_loss:0.158831
Clustering   219: ASW= 0.7896, DB= 0.2932, CH= 36922.4594
Training epoch 220, recon_loss:0.787745, zinb_loss:0.647208, cluster_loss:0.158859
Clustering   220: ASW= 0.7882, DB= 0.2958, CH= 36516.8361
Training epoch 221, recon_loss:0.787484, zinb_loss:0.647207, cluster_loss:0.158799
Clustering   221: ASW= 0.7898, DB= 0.2926, CH= 36977.5866
Training epoch 222, recon_loss:0.787212, zinb_loss:0.647100, cluster_loss:0.158749
Clustering   222: ASW= 0.7883, DB= 0.2952, CH= 36576.9621
Training epoch 223, recon_loss:0.786801, zinb_loss:0.647046, cluster_loss:0.158685
Clustering   223: ASW= 0.7900, DB= 0.2922, CH= 37038.2019
Training epoch 224, recon_loss:0.786777, zinb_loss:0.647009, cluster_loss:0.158652
Clustering   224: ASW= 0.7884, DB= 0.2944, CH= 36631.9032
Training epoch 225, recon_loss:0.786375, zinb_loss:0.646925, cluster_loss:0.158598
Clustering   225: ASW= 0.7902, DB= 0.2921, CH= 37113.1379
Training epoch 226, recon_loss:0.786578, zinb_loss:0.646966, cluster_loss:0.158660
Clustering   226: ASW= 0.7886, DB= 0.2934, CH= 36695.3175
Training epoch 227, recon_loss:0.786220, zinb_loss:0.646852, cluster_loss:0.158616
Clustering   227: ASW= 0.7903, DB= 0.2918, CH= 37180.3474
Training epoch 228, recon_loss:0.786608, zinb_loss:0.646981, cluster_loss:0.158775
Clustering   228: ASW= 0.7887, DB= 0.2930, CH= 36737.8528
Training epoch 229, recon_loss:0.786241, zinb_loss:0.646830, cluster_loss:0.158712
Clustering   229: ASW= 0.7904, DB= 0.2909, CH= 37238.2187
Training epoch 230, recon_loss:0.786718, zinb_loss:0.647037, cluster_loss:0.158915
Clustering   230: ASW= 0.7888, DB= 0.2927, CH= 36764.7003
Training epoch 231, recon_loss:0.786432, zinb_loss:0.646858, cluster_loss:0.158820
Clustering   231: ASW= 0.7905, DB= 0.2905, CH= 37291.1512
Training epoch 232, recon_loss:0.787145, zinb_loss:0.647165, cluster_loss:0.159045
Clustering   232: ASW= 0.7889, DB= 0.2923, CH= 36787.9435
Training epoch 233, recon_loss:0.787190, zinb_loss:0.647023, cluster_loss:0.158948
Clustering   233: ASW= 0.7906, DB= 0.2904, CH= 37338.3803
Training epoch 234, recon_loss:0.788264, zinb_loss:0.647473, cluster_loss:0.159215
Clustering   234: ASW= 0.7892, DB= 0.2917, CH= 36818.7903
Training epoch 235, recon_loss:0.788489, zinb_loss:0.647391, cluster_loss:0.159046
Clustering   235: ASW= 0.7908, DB= 0.2904, CH= 37401.5963
Training epoch 236, recon_loss:0.789089, zinb_loss:0.647701, cluster_loss:0.159242
Clustering   236: ASW= 0.7896, DB= 0.2911, CH= 36908.4564
Training epoch 237, recon_loss:0.788512, zinb_loss:0.647421, cluster_loss:0.158794
Clustering   237: ASW= 0.7910, DB= 0.2885, CH= 37468.2002
Training epoch 238, recon_loss:0.788288, zinb_loss:0.647432, cluster_loss:0.158921
Clustering   238: ASW= 0.7900, DB= 0.2906, CH= 37013.7336
Training epoch 239, recon_loss:0.787527, zinb_loss:0.647129, cluster_loss:0.158382
Clustering   239: ASW= 0.7910, DB= 0.2882, CH= 37499.3674
Training epoch 240, recon_loss:0.787364, zinb_loss:0.647135, cluster_loss:0.158593
Clustering   240: ASW= 0.7904, DB= 0.2899, CH= 37140.7009
Training epoch 241, recon_loss:0.786973, zinb_loss:0.646926, cluster_loss:0.158108
Clustering   241: ASW= 0.7911, DB= 0.2887, CH= 37554.2132
Training epoch 242, recon_loss:0.786919, zinb_loss:0.646965, cluster_loss:0.158426
Clustering   242: ASW= 0.7909, DB= 0.2894, CH= 37275.9489
Training epoch 243, recon_loss:0.786982, zinb_loss:0.646846, cluster_loss:0.158012
Clustering   243: ASW= 0.7910, DB= 0.2889, CH= 37611.8044
Training epoch 244, recon_loss:0.786894, zinb_loss:0.646879, cluster_loss:0.158428
Clustering   244: ASW= 0.7914, DB= 0.2889, CH= 37402.4978
Training epoch 245, recon_loss:0.787138, zinb_loss:0.646849, cluster_loss:0.158086
Clustering   245: ASW= 0.7909, DB= 0.2891, CH= 37655.5011
Training epoch 246, recon_loss:0.786808, zinb_loss:0.646853, cluster_loss:0.158535
Clustering   246: ASW= 0.7919, DB= 0.2883, CH= 37516.8700
Training epoch 247, recon_loss:0.786954, zinb_loss:0.646879, cluster_loss:0.158256
Clustering   247: ASW= 0.7908, DB= 0.2892, CH= 37681.2233
Training epoch 248, recon_loss:0.786418, zinb_loss:0.646841, cluster_loss:0.158598
Clustering   248: ASW= 0.7924, DB= 0.2879, CH= 37637.0881
Training epoch 249, recon_loss:0.786700, zinb_loss:0.646874, cluster_loss:0.158397
Clustering   249: ASW= 0.7907, DB= 0.2897, CH= 37701.8988
Training epoch 250, recon_loss:0.786047, zinb_loss:0.646830, cluster_loss:0.158618
Clustering   250: ASW= 0.7928, DB= 0.2873, CH= 37753.0344
Training epoch 251, recon_loss:0.786658, zinb_loss:0.646857, cluster_loss:0.158539
Clustering   251: ASW= 0.7907, DB= 0.2899, CH= 37706.5189
Training epoch 252, recon_loss:0.785958, zinb_loss:0.646834, cluster_loss:0.158678
Clustering   252: ASW= 0.7932, DB= 0.2870, CH= 37865.8206
Training epoch 253, recon_loss:0.786892, zinb_loss:0.646847, cluster_loss:0.158700
Clustering   253: ASW= 0.7907, DB= 0.2902, CH= 37693.9245
Training epoch 254, recon_loss:0.786172, zinb_loss:0.646860, cluster_loss:0.158787
Clustering   254: ASW= 0.7934, DB= 0.2866, CH= 37961.4993
Training epoch 255, recon_loss:0.787088, zinb_loss:0.646855, cluster_loss:0.158807
Clustering   255: ASW= 0.7908, DB= 0.2899, CH= 37687.3160
Training epoch 256, recon_loss:0.786275, zinb_loss:0.646892, cluster_loss:0.158833
Clustering   256: ASW= 0.7936, DB= 0.2860, CH= 38040.6100
Training epoch 257, recon_loss:0.787086, zinb_loss:0.646881, cluster_loss:0.158807
Clustering   257: ASW= 0.7911, DB= 0.2897, CH= 37697.1560
Training epoch 258, recon_loss:0.786307, zinb_loss:0.646957, cluster_loss:0.158836
Clustering   258: ASW= 0.7936, DB= 0.2858, CH= 38114.2956
Training epoch 259, recon_loss:0.787124, zinb_loss:0.646951, cluster_loss:0.158853
Clustering   259: ASW= 0.7915, DB= 0.2893, CH= 37732.2314
Training epoch 260, recon_loss:0.786496, zinb_loss:0.647079, cluster_loss:0.158938
Clustering   260: ASW= 0.7934, DB= 0.2857, CH= 38163.7264
Training epoch 261, recon_loss:0.787307, zinb_loss:0.647069, cluster_loss:0.159027
Clustering   261: ASW= 0.7920, DB= 0.2884, CH= 37771.1374
Training epoch 262, recon_loss:0.786772, zinb_loss:0.647206, cluster_loss:0.159157
Clustering   262: ASW= 0.7932, DB= 0.2856, CH= 38196.7233
Training epoch 263, recon_loss:0.787382, zinb_loss:0.647124, cluster_loss:0.159247
Clustering   263: ASW= 0.7924, DB= 0.2883, CH= 37814.1218
Training epoch 264, recon_loss:0.786832, zinb_loss:0.647251, cluster_loss:0.159289
Clustering   264: ASW= 0.7930, DB= 0.2863, CH= 38259.8555
Training epoch 265, recon_loss:0.787051, zinb_loss:0.647068, cluster_loss:0.159267
Clustering   265: ASW= 0.7928, DB= 0.2876, CH= 37874.0528
Training epoch 266, recon_loss:0.786587, zinb_loss:0.647170, cluster_loss:0.159177
Clustering   266: ASW= 0.7930, DB= 0.2863, CH= 38342.9050
Training epoch 267, recon_loss:0.786597, zinb_loss:0.646949, cluster_loss:0.159081
Clustering   267: ASW= 0.7933, DB= 0.2867, CH= 37964.8956
Training epoch 268, recon_loss:0.786359, zinb_loss:0.647032, cluster_loss:0.158946
Clustering   268: ASW= 0.7931, DB= 0.2860, CH= 38431.3046
Training epoch 269, recon_loss:0.786446, zinb_loss:0.646833, cluster_loss:0.158870
Clustering   269: ASW= 0.7937, DB= 0.2860, CH= 38059.9492
Training epoch 270, recon_loss:0.786403, zinb_loss:0.646913, cluster_loss:0.158752
Clustering   270: ASW= 0.7932, DB= 0.2856, CH= 38525.2092
Training epoch 271, recon_loss:0.786725, zinb_loss:0.646734, cluster_loss:0.158752
Clustering   271: ASW= 0.7940, DB= 0.2856, CH= 38133.0860
Training epoch 272, recon_loss:0.786713, zinb_loss:0.646807, cluster_loss:0.158641
Clustering   272: ASW= 0.7935, DB= 0.2858, CH= 38609.2539
Training epoch 273, recon_loss:0.787074, zinb_loss:0.646615, cluster_loss:0.158680
Clustering   273: ASW= 0.7942, DB= 0.2850, CH= 38191.5029
Training epoch 274, recon_loss:0.786879, zinb_loss:0.646687, cluster_loss:0.158559
Clustering   274: ASW= 0.7937, DB= 0.2849, CH= 38650.2062
Training epoch 275, recon_loss:0.787080, zinb_loss:0.646483, cluster_loss:0.158592
Clustering   275: ASW= 0.7943, DB= 0.2846, CH= 38265.2667
Training epoch 276, recon_loss:0.786802, zinb_loss:0.646569, cluster_loss:0.158478
Clustering   276: ASW= 0.7940, DB= 0.2844, CH= 38676.9603
Training epoch 277, recon_loss:0.786903, zinb_loss:0.646390, cluster_loss:0.158524
Clustering   277: ASW= 0.7944, DB= 0.2845, CH= 38340.0552
Training epoch 278, recon_loss:0.786682, zinb_loss:0.646510, cluster_loss:0.158427
Clustering   278: ASW= 0.7942, DB= 0.2841, CH= 38692.6829
Training epoch 279, recon_loss:0.786608, zinb_loss:0.646394, cluster_loss:0.158468
Clustering   279: ASW= 0.7945, DB= 0.2841, CH= 38425.6102
Training epoch 280, recon_loss:0.786587, zinb_loss:0.646562, cluster_loss:0.158385
Clustering   280: ASW= 0.7944, DB= 0.2838, CH= 38691.1363
Training epoch 281, recon_loss:0.786411, zinb_loss:0.646533, cluster_loss:0.158444
Clustering   281: ASW= 0.7946, DB= 0.2837, CH= 38528.6757
Training epoch 282, recon_loss:0.786670, zinb_loss:0.646774, cluster_loss:0.158411
Clustering   282: ASW= 0.7946, DB= 0.2836, CH= 38678.7303
Training epoch 283, recon_loss:0.786470, zinb_loss:0.646825, cluster_loss:0.158500
Clustering   283: ASW= 0.7947, DB= 0.2836, CH= 38648.4502
Training epoch 284, recon_loss:0.786706, zinb_loss:0.647098, cluster_loss:0.158449
Clustering   284: ASW= 0.7948, DB= 0.2832, CH= 38672.7606
Training epoch 285, recon_loss:0.786450, zinb_loss:0.647113, cluster_loss:0.158513
Clustering   285: ASW= 0.7949, DB= 0.2836, CH= 38754.3535
Training epoch 286, recon_loss:0.786486, zinb_loss:0.647346, cluster_loss:0.158366
Clustering   286: ASW= 0.7950, DB= 0.2837, CH= 38703.0693
Training epoch 287, recon_loss:0.786154, zinb_loss:0.647228, cluster_loss:0.158382
Clustering   287: ASW= 0.7951, DB= 0.2830, CH= 38846.0095
Training epoch 288, recon_loss:0.786063, zinb_loss:0.647402, cluster_loss:0.158175
Clustering   288: ASW= 0.7952, DB= 0.2835, CH= 38762.8936
Training epoch 289, recon_loss:0.785666, zinb_loss:0.647175, cluster_loss:0.158158
Clustering   289: ASW= 0.7954, DB= 0.2828, CH= 38958.1805
Training epoch 290, recon_loss:0.785566, zinb_loss:0.647319, cluster_loss:0.157980
Clustering   290: ASW= 0.7954, DB= 0.2827, CH= 38841.4063
Training epoch 291, recon_loss:0.785194, zinb_loss:0.647073, cluster_loss:0.157953
Clustering   291: ASW= 0.7958, DB= 0.2826, CH= 39073.1084
Training epoch 292, recon_loss:0.785157, zinb_loss:0.647207, cluster_loss:0.157845
Clustering   292: ASW= 0.7956, DB= 0.2823, CH= 38907.0059
Training epoch 293, recon_loss:0.784849, zinb_loss:0.646977, cluster_loss:0.157809
Clustering   293: ASW= 0.7961, DB= 0.2822, CH= 39176.9252
Training epoch 294, recon_loss:0.784885, zinb_loss:0.647112, cluster_loss:0.157785
Clustering   294: ASW= 0.7957, DB= 0.2820, CH= 38971.1153
Training epoch 295, recon_loss:0.784659, zinb_loss:0.646913, cluster_loss:0.157729
Clustering   295: ASW= 0.7965, DB= 0.2813, CH= 39267.3010
Training epoch 296, recon_loss:0.784774, zinb_loss:0.647065, cluster_loss:0.157790
Clustering   296: ASW= 0.7958, DB= 0.2818, CH= 39031.8003
Training epoch 297, recon_loss:0.784628, zinb_loss:0.646877, cluster_loss:0.157712
Clustering   297: ASW= 0.7968, DB= 0.2810, CH= 39346.3105
Training epoch 298, recon_loss:0.784813, zinb_loss:0.647039, cluster_loss:0.157856
Clustering   298: ASW= 0.7958, DB= 0.2814, CH= 39075.4216
Training epoch 299, recon_loss:0.784744, zinb_loss:0.646857, cluster_loss:0.157740
Clustering   299: ASW= 0.7971, DB= 0.2805, CH= 39409.4129
Training epoch 300, recon_loss:0.784963, zinb_loss:0.647021, cluster_loss:0.157959
Clustering   300: ASW= 0.7958, DB= 0.2809, CH= 39105.4821
Training epoch 301, recon_loss:0.784951, zinb_loss:0.646833, cluster_loss:0.157789
Clustering   301: ASW= 0.7973, DB= 0.2801, CH= 39453.4958
Training epoch 302, recon_loss:0.785138, zinb_loss:0.646986, cluster_loss:0.158054
Clustering   302: ASW= 0.7957, DB= 0.2801, CH= 39148.1492
Training epoch 303, recon_loss:0.785166, zinb_loss:0.646791, cluster_loss:0.157838
Clustering   303: ASW= 0.7976, DB= 0.2799, CH= 39481.3289
Training epoch 304, recon_loss:0.785283, zinb_loss:0.646926, cluster_loss:0.158131
Clustering   304: ASW= 0.7956, DB= 0.2797, CH= 39185.3458
Training epoch 305, recon_loss:0.785348, zinb_loss:0.646732, cluster_loss:0.157872
Clustering   305: ASW= 0.7978, DB= 0.2795, CH= 39500.4129
Training epoch 306, recon_loss:0.785432, zinb_loss:0.646834, cluster_loss:0.158187
Clustering   306: ASW= 0.7955, DB= 0.2799, CH= 39262.2548
Training epoch 307, recon_loss:0.785535, zinb_loss:0.646657, cluster_loss:0.157918
Clustering   307: ASW= 0.7981, DB= 0.2793, CH= 39515.7214
Training epoch 308, recon_loss:0.785671, zinb_loss:0.646717, cluster_loss:0.158265
Clustering   308: ASW= 0.7954, DB= 0.2799, CH= 39334.8905
Training epoch 309, recon_loss:0.785794, zinb_loss:0.646585, cluster_loss:0.158013
Clustering   309: ASW= 0.7983, DB= 0.2791, CH= 39528.2604
Training epoch 310, recon_loss:0.786066, zinb_loss:0.646601, cluster_loss:0.158389
Clustering   310: ASW= 0.7953, DB= 0.2801, CH= 39408.4300
Training epoch 311, recon_loss:0.785987, zinb_loss:0.646495, cluster_loss:0.158117
Clustering   311: ASW= 0.7986, DB= 0.2789, CH= 39538.2086
Training epoch 312, recon_loss:0.786186, zinb_loss:0.646461, cluster_loss:0.158411
Clustering   312: ASW= 0.7954, DB= 0.2803, CH= 39498.6042
Training epoch 313, recon_loss:0.785747, zinb_loss:0.646367, cluster_loss:0.158097
Clustering   313: ASW= 0.7986, DB= 0.2789, CH= 39550.1381
Training epoch 314, recon_loss:0.785798, zinb_loss:0.646298, cluster_loss:0.158266
Clustering   314: ASW= 0.7956, DB= 0.2804, CH= 39624.6997
Training epoch 315, recon_loss:0.785159, zinb_loss:0.646244, cluster_loss:0.157953
Clustering   315: ASW= 0.7986, DB= 0.2792, CH= 39563.3367
Training epoch 316, recon_loss:0.785254, zinb_loss:0.646180, cluster_loss:0.158050
Clustering   316: ASW= 0.7962, DB= 0.2800, CH= 39775.2930
Training epoch 317, recon_loss:0.784736, zinb_loss:0.646198, cluster_loss:0.157841
Clustering   317: ASW= 0.7984, DB= 0.2793, CH= 39561.8870
Training epoch 318, recon_loss:0.785061, zinb_loss:0.646195, cluster_loss:0.157938
Clustering   318: ASW= 0.7969, DB= 0.2793, CH= 39948.4093
Training epoch 319, recon_loss:0.784805, zinb_loss:0.646258, cluster_loss:0.157859
Clustering   319: ASW= 0.7982, DB= 0.2791, CH= 39533.0317
Training epoch 320, recon_loss:0.785335, zinb_loss:0.646327, cluster_loss:0.157975
Clustering   320: ASW= 0.7975, DB= 0.2784, CH= 40100.7149
Training epoch 321, recon_loss:0.785166, zinb_loss:0.646330, cluster_loss:0.157830
Clustering   321: ASW= 0.7981, DB= 0.2800, CH= 39540.4951
Training epoch 322, recon_loss:0.785838, zinb_loss:0.646426, cluster_loss:0.157942
Clustering   322: ASW= 0.7980, DB= 0.2784, CH= 40207.6920
Training epoch 323, recon_loss:0.786024, zinb_loss:0.646382, cluster_loss:0.157724
Clustering   323: ASW= 0.7980, DB= 0.2803, CH= 39585.8443
Training epoch 324, recon_loss:0.787200, zinb_loss:0.646475, cluster_loss:0.157926
Clustering   324: ASW= 0.7982, DB= 0.2784, CH= 40239.6111
Training epoch 325, recon_loss:0.787723, zinb_loss:0.646466, cluster_loss:0.157706
Clustering   325: ASW= 0.7982, DB= 0.2803, CH= 39649.3508
Training epoch 326, recon_loss:0.788941, zinb_loss:0.646481, cluster_loss:0.158034
Clustering   326: ASW= 0.7982, DB= 0.2782, CH= 40175.1510
Training epoch 327, recon_loss:0.788127, zinb_loss:0.646453, cluster_loss:0.157632
Clustering   327: ASW= 0.7985, DB= 0.2799, CH= 39732.8075
Training epoch 328, recon_loss:0.788174, zinb_loss:0.646293, cluster_loss:0.157867
Clustering   328: ASW= 0.7980, DB= 0.2780, CH= 40093.6703
Training epoch 329, recon_loss:0.787187, zinb_loss:0.646260, cluster_loss:0.157376
Clustering   329: ASW= 0.7989, DB= 0.2792, CH= 39842.3204
Training epoch 330, recon_loss:0.787006, zinb_loss:0.646065, cluster_loss:0.157621
Clustering   330: ASW= 0.7978, DB= 0.2787, CH= 40089.6482
Training epoch 331, recon_loss:0.786532, zinb_loss:0.646061, cluster_loss:0.157240
Clustering   331: ASW= 0.7994, DB= 0.2783, CH= 39963.9266
Training epoch 332, recon_loss:0.786244, zinb_loss:0.645890, cluster_loss:0.157563
Clustering   332: ASW= 0.7976, DB= 0.2783, CH= 40074.4025
Training epoch 333, recon_loss:0.786043, zinb_loss:0.645923, cluster_loss:0.157236
Clustering   333: ASW= 0.7997, DB= 0.2775, CH= 40057.8489
Training epoch 334, recon_loss:0.785571, zinb_loss:0.645771, cluster_loss:0.157590
Clustering   334: ASW= 0.7974, DB= 0.2780, CH= 40065.8502
Training epoch 335, recon_loss:0.785604, zinb_loss:0.645851, cluster_loss:0.157250
Clustering   335: ASW= 0.8001, DB= 0.2771, CH= 40163.3839
Training epoch 336, recon_loss:0.785193, zinb_loss:0.645705, cluster_loss:0.157648
Clustering   336: ASW= 0.7974, DB= 0.2782, CH= 40081.0488
Training epoch 337, recon_loss:0.785358, zinb_loss:0.645820, cluster_loss:0.157300
Clustering   337: ASW= 0.8003, DB= 0.2771, CH= 40284.0330
Training epoch 338, recon_loss:0.785027, zinb_loss:0.645683, cluster_loss:0.157771
Clustering   338: ASW= 0.7973, DB= 0.2774, CH= 40072.7514
Training epoch 339, recon_loss:0.785255, zinb_loss:0.645821, cluster_loss:0.157430
Clustering   339: ASW= 0.8006, DB= 0.2767, CH= 40381.5408
Training epoch 340, recon_loss:0.784987, zinb_loss:0.645698, cluster_loss:0.157981
Clustering   340: ASW= 0.7973, DB= 0.2775, CH= 40062.0131
Training epoch 341, recon_loss:0.785221, zinb_loss:0.645849, cluster_loss:0.157647
Clustering   341: ASW= 0.8008, DB= 0.2761, CH= 40453.8745
Training epoch 342, recon_loss:0.784933, zinb_loss:0.645746, cluster_loss:0.158185
Clustering   342: ASW= 0.7974, DB= 0.2773, CH= 40033.8847
Training epoch 343, recon_loss:0.785092, zinb_loss:0.645890, cluster_loss:0.157806
Clustering   343: ASW= 0.8009, DB= 0.2760, CH= 40508.9414
Training epoch 344, recon_loss:0.784587, zinb_loss:0.645782, cluster_loss:0.158124
Clustering   344: ASW= 0.7976, DB= 0.2772, CH= 40052.8884
Training epoch 345, recon_loss:0.784670, zinb_loss:0.645877, cluster_loss:0.157720
Clustering   345: ASW= 0.8009, DB= 0.2759, CH= 40546.2951
Training epoch 346, recon_loss:0.784024, zinb_loss:0.645771, cluster_loss:0.157836
Clustering   346: ASW= 0.7980, DB= 0.2769, CH= 40128.2500
Training epoch 347, recon_loss:0.784118, zinb_loss:0.645820, cluster_loss:0.157466
Clustering   347: ASW= 0.8009, DB= 0.2762, CH= 40603.3594
Training epoch 348, recon_loss:0.783497, zinb_loss:0.645740, cluster_loss:0.157521
Clustering   348: ASW= 0.7984, DB= 0.2768, CH= 40243.0112
Training epoch 349, recon_loss:0.783688, zinb_loss:0.645762, cluster_loss:0.157234
Clustering   349: ASW= 0.8009, DB= 0.2757, CH= 40664.2492
Training epoch 350, recon_loss:0.783155, zinb_loss:0.645719, cluster_loss:0.157285
Clustering   350: ASW= 0.7988, DB= 0.2762, CH= 40344.5852
Training epoch 351, recon_loss:0.783432, zinb_loss:0.645727, cluster_loss:0.157060
Clustering   351: ASW= 0.8011, DB= 0.2757, CH= 40735.4760
Training epoch 352, recon_loss:0.782982, zinb_loss:0.645710, cluster_loss:0.157115
Clustering   352: ASW= 0.7991, DB= 0.2758, CH= 40446.2223
Training epoch 353, recon_loss:0.783337, zinb_loss:0.645714, cluster_loss:0.156937
Clustering   353: ASW= 0.8012, DB= 0.2753, CH= 40803.3542
Training epoch 354, recon_loss:0.782993, zinb_loss:0.645717, cluster_loss:0.156994
Clustering   354: ASW= 0.7994, DB= 0.2753, CH= 40537.9631
Training epoch 355, recon_loss:0.783435, zinb_loss:0.645735, cluster_loss:0.156861
Clustering   355: ASW= 0.8013, DB= 0.2754, CH= 40868.4653
Training epoch 356, recon_loss:0.783249, zinb_loss:0.645768, cluster_loss:0.156935
Clustering   356: ASW= 0.7996, DB= 0.2753, CH= 40612.2424
Training epoch 357, recon_loss:0.783817, zinb_loss:0.645836, cluster_loss:0.156846
Clustering   357: ASW= 0.8015, DB= 0.2749, CH= 40919.6528
Training epoch 358, recon_loss:0.783946, zinb_loss:0.645938, cluster_loss:0.156968
Clustering   358: ASW= 0.7997, DB= 0.2752, CH= 40670.7753
Training epoch 359, recon_loss:0.784643, zinb_loss:0.646123, cluster_loss:0.156934
Clustering   359: ASW= 0.8016, DB= 0.2745, CH= 40952.6551
Training epoch 360, recon_loss:0.785131, zinb_loss:0.646333, cluster_loss:0.157133
Clustering   360: ASW= 0.7997, DB= 0.2753, CH= 40709.6457
Training epoch 361, recon_loss:0.785187, zinb_loss:0.646537, cluster_loss:0.157089
Clustering   361: ASW= 0.8017, DB= 0.2741, CH= 40957.8316
Training epoch 362, recon_loss:0.785484, zinb_loss:0.646701, cluster_loss:0.157191
Clustering   362: ASW= 0.7997, DB= 0.2756, CH= 40744.2463
Training epoch 363, recon_loss:0.784484, zinb_loss:0.646685, cluster_loss:0.157090
Clustering   363: ASW= 0.8018, DB= 0.2738, CH= 40976.7268
Training epoch 364, recon_loss:0.784661, zinb_loss:0.646711, cluster_loss:0.157001
Clustering   364: ASW= 0.7999, DB= 0.2756, CH= 40819.1409
Training epoch 365, recon_loss:0.783616, zinb_loss:0.646592, cluster_loss:0.156990
Clustering   365: ASW= 0.8019, DB= 0.2735, CH= 41000.1584
Training epoch 366, recon_loss:0.783898, zinb_loss:0.646617, cluster_loss:0.156852
Clustering   366: ASW= 0.8001, DB= 0.2755, CH= 40914.5288
Training epoch 367, recon_loss:0.783135, zinb_loss:0.646513, cluster_loss:0.156948
Clustering   367: ASW= 0.8019, DB= 0.2733, CH= 41027.9324
Training epoch 368, recon_loss:0.783522, zinb_loss:0.646562, cluster_loss:0.156804
Clustering   368: ASW= 0.8003, DB= 0.2753, CH= 41011.6800
Training epoch 369, recon_loss:0.782932, zinb_loss:0.646469, cluster_loss:0.156962
Clustering   369: ASW= 0.8020, DB= 0.2732, CH= 41067.3155
Training epoch 370, recon_loss:0.783347, zinb_loss:0.646534, cluster_loss:0.156801
Clustering   370: ASW= 0.8005, DB= 0.2751, CH= 41097.3987
Training epoch 371, recon_loss:0.782807, zinb_loss:0.646430, cluster_loss:0.156972
Clustering   371: ASW= 0.8020, DB= 0.2729, CH= 41109.3090
Training epoch 372, recon_loss:0.783209, zinb_loss:0.646492, cluster_loss:0.156778
Clustering   372: ASW= 0.8008, DB= 0.2744, CH= 41171.1664
Training epoch 373, recon_loss:0.782648, zinb_loss:0.646365, cluster_loss:0.156949
Clustering   373: ASW= 0.8021, DB= 0.2729, CH= 41160.4034
Training epoch 374, recon_loss:0.783032, zinb_loss:0.646417, cluster_loss:0.156736
Clustering   374: ASW= 0.8010, DB= 0.2740, CH= 41250.9416
Training epoch 375, recon_loss:0.782515, zinb_loss:0.646286, cluster_loss:0.156919
Clustering   375: ASW= 0.8022, DB= 0.2728, CH= 41216.0965
Training epoch 376, recon_loss:0.782903, zinb_loss:0.646333, cluster_loss:0.156712
Clustering   376: ASW= 0.8013, DB= 0.2736, CH= 41324.4518
Training epoch 377, recon_loss:0.782488, zinb_loss:0.646203, cluster_loss:0.156925
Clustering   377: ASW= 0.8022, DB= 0.2725, CH= 41264.1971
Training epoch 378, recon_loss:0.782908, zinb_loss:0.646238, cluster_loss:0.156751
Clustering   378: ASW= 0.8016, DB= 0.2731, CH= 41389.2264
Training epoch 379, recon_loss:0.782692, zinb_loss:0.646116, cluster_loss:0.157020
Clustering   379: ASW= 0.8022, DB= 0.2727, CH= 41290.6948
Training epoch 380, recon_loss:0.783153, zinb_loss:0.646126, cluster_loss:0.156918
Clustering   380: ASW= 0.8018, DB= 0.2726, CH= 41435.4682
Training epoch 381, recon_loss:0.783252, zinb_loss:0.646026, cluster_loss:0.157251
Clustering   381: ASW= 0.8020, DB= 0.2726, CH= 41275.4083
Training epoch 382, recon_loss:0.783548, zinb_loss:0.645969, cluster_loss:0.157223
Clustering   382: ASW= 0.8019, DB= 0.2727, CH= 41434.1137
Training epoch 383, recon_loss:0.783832, zinb_loss:0.645914, cluster_loss:0.157466
Clustering   383: ASW= 0.8020, DB= 0.2727, CH= 41281.0251
Training epoch 384, recon_loss:0.783618, zinb_loss:0.645785, cluster_loss:0.157459
Clustering   384: ASW= 0.8021, DB= 0.2723, CH= 41414.9984
Training epoch 385, recon_loss:0.784032, zinb_loss:0.645786, cluster_loss:0.157538
Clustering   385: ASW= 0.8019, DB= 0.2727, CH= 41290.4623
Training epoch 386, recon_loss:0.783367, zinb_loss:0.645607, cluster_loss:0.157531
Clustering   386: ASW= 0.8021, DB= 0.2723, CH= 41392.3360
Training epoch 387, recon_loss:0.783855, zinb_loss:0.645688, cluster_loss:0.157443
Clustering   387: ASW= 0.8020, DB= 0.2727, CH= 41327.3356
Training epoch 388, recon_loss:0.782986, zinb_loss:0.645506, cluster_loss:0.157428
Clustering   388: ASW= 0.8023, DB= 0.2721, CH= 41412.7919
Training epoch 389, recon_loss:0.783655, zinb_loss:0.645650, cluster_loss:0.157300
Clustering   389: ASW= 0.8021, DB= 0.2723, CH= 41349.7366
Training epoch 390, recon_loss:0.782935, zinb_loss:0.645518, cluster_loss:0.157319
Clustering   390: ASW= 0.8024, DB= 0.2721, CH= 41447.6609
Training epoch 391, recon_loss:0.783760, zinb_loss:0.645714, cluster_loss:0.157195
Clustering   391: ASW= 0.8023, DB= 0.2721, CH= 41368.2446
Training epoch 392, recon_loss:0.783295, zinb_loss:0.645631, cluster_loss:0.157276
Clustering   392: ASW= 0.8025, DB= 0.2721, CH= 41467.0872
Training epoch 393, recon_loss:0.783961, zinb_loss:0.645831, cluster_loss:0.157075
Clustering   393: ASW= 0.8026, DB= 0.2714, CH= 41391.1979
Training epoch 394, recon_loss:0.783588, zinb_loss:0.645717, cluster_loss:0.157175
Clustering   394: ASW= 0.8026, DB= 0.2716, CH= 41504.7855
Training epoch 395, recon_loss:0.783971, zinb_loss:0.645875, cluster_loss:0.156943
Clustering   395: ASW= 0.8027, DB= 0.2711, CH= 41413.4835
Training epoch 396, recon_loss:0.783731, zinb_loss:0.645721, cluster_loss:0.157071
Clustering   396: ASW= 0.8026, DB= 0.2714, CH= 41567.0369
Training epoch 397, recon_loss:0.783928, zinb_loss:0.645854, cluster_loss:0.156864
Clustering   397: ASW= 0.8028, DB= 0.2709, CH= 41421.8283
Training epoch 398, recon_loss:0.783817, zinb_loss:0.645672, cluster_loss:0.157010
Clustering   398: ASW= 0.8029, DB= 0.2710, CH= 41623.6251
Training epoch 399, recon_loss:0.783943, zinb_loss:0.645799, cluster_loss:0.156887
Clustering   399: ASW= 0.8028, DB= 0.2708, CH= 41409.6842
Training epoch 400, recon_loss:0.783811, zinb_loss:0.645585, cluster_loss:0.156979
Clustering   400: ASW= 0.8031, DB= 0.2707, CH= 41701.9741
Training epoch 401, recon_loss:0.783887, zinb_loss:0.645714, cluster_loss:0.156941
Clustering   401: ASW= 0.8029, DB= 0.2702, CH= 41391.6178
Training epoch 402, recon_loss:0.783523, zinb_loss:0.645475, cluster_loss:0.156873
Clustering   402: ASW= 0.8032, DB= 0.2705, CH= 41779.6771
Training epoch 403, recon_loss:0.783517, zinb_loss:0.645600, cluster_loss:0.156855
Clustering   403: ASW= 0.8031, DB= 0.2699, CH= 41439.2827
Training epoch 404, recon_loss:0.782992, zinb_loss:0.645342, cluster_loss:0.156709
Clustering   404: ASW= 0.8032, DB= 0.2705, CH= 41849.7804
Training epoch 405, recon_loss:0.783020, zinb_loss:0.645486, cluster_loss:0.156713
Clustering   405: ASW= 0.8033, DB= 0.2696, CH= 41521.0471
Training epoch 406, recon_loss:0.782500, zinb_loss:0.645229, cluster_loss:0.156569
Clustering   406: ASW= 0.8033, DB= 0.2706, CH= 41913.7505
Training epoch 407, recon_loss:0.782619, zinb_loss:0.645398, cluster_loss:0.156615
Clustering   407: ASW= 0.8035, DB= 0.2692, CH= 41600.9177
Training epoch 408, recon_loss:0.782161, zinb_loss:0.645145, cluster_loss:0.156476
Clustering   408: ASW= 0.8033, DB= 0.2708, CH= 41979.3412
Training epoch 409, recon_loss:0.782339, zinb_loss:0.645332, cluster_loss:0.156558
Clustering   409: ASW= 0.8037, DB= 0.2689, CH= 41673.6319
Training epoch 410, recon_loss:0.781991, zinb_loss:0.645082, cluster_loss:0.156423
Clustering   410: ASW= 0.8034, DB= 0.2708, CH= 42039.2813
Training epoch 411, recon_loss:0.782239, zinb_loss:0.645280, cluster_loss:0.156537
Clustering   411: ASW= 0.8039, DB= 0.2689, CH= 41743.5516
Training epoch 412, recon_loss:0.782046, zinb_loss:0.645029, cluster_loss:0.156411
Clustering   412: ASW= 0.8034, DB= 0.2708, CH= 42094.1068
Training epoch 413, recon_loss:0.782291, zinb_loss:0.645225, cluster_loss:0.156547
Clustering   413: ASW= 0.8040, DB= 0.2688, CH= 41804.2023
Training epoch 414, recon_loss:0.782210, zinb_loss:0.644979, cluster_loss:0.156436
Clustering   414: ASW= 0.8035, DB= 0.2709, CH= 42138.9944
Training epoch 415, recon_loss:0.782168, zinb_loss:0.645153, cluster_loss:0.156560
Clustering   415: ASW= 0.8041, DB= 0.2686, CH= 41862.9103
Training epoch 416, recon_loss:0.782156, zinb_loss:0.644922, cluster_loss:0.156448
Clustering   416: ASW= 0.8035, DB= 0.2707, CH= 42174.9479
Training epoch 417, recon_loss:0.782045, zinb_loss:0.645084, cluster_loss:0.156555
Clustering   417: ASW= 0.8041, DB= 0.2684, CH= 41912.7899
Training epoch 418, recon_loss:0.782157, zinb_loss:0.644887, cluster_loss:0.156476
Clustering   418: ASW= 0.8036, DB= 0.2706, CH= 42212.3904
Training epoch 419, recon_loss:0.782355, zinb_loss:0.645083, cluster_loss:0.156609
Clustering   419: ASW= 0.8041, DB= 0.2681, CH= 41932.8975
Training epoch 420, recon_loss:0.782541, zinb_loss:0.644936, cluster_loss:0.156559
Clustering   420: ASW= 0.8037, DB= 0.2705, CH= 42242.9432
Training epoch 421, recon_loss:0.783104, zinb_loss:0.645197, cluster_loss:0.156689
Clustering   421: ASW= 0.8041, DB= 0.2681, CH= 41947.9524
Training epoch 422, recon_loss:0.782922, zinb_loss:0.645078, cluster_loss:0.156609
Clustering   422: ASW= 0.8038, DB= 0.2701, CH= 42261.6981
Training epoch 423, recon_loss:0.783453, zinb_loss:0.645352, cluster_loss:0.156645
Clustering   423: ASW= 0.8041, DB= 0.2681, CH= 41964.3545
Training epoch 424, recon_loss:0.782791, zinb_loss:0.645249, cluster_loss:0.156517
Clustering   424: ASW= 0.8041, DB= 0.2697, CH= 42304.6991
Training epoch 425, recon_loss:0.783186, zinb_loss:0.645497, cluster_loss:0.156497
Clustering   425: ASW= 0.8040, DB= 0.2682, CH= 41990.7505
Training epoch 426, recon_loss:0.782374, zinb_loss:0.645421, cluster_loss:0.156370
Clustering   426: ASW= 0.8044, DB= 0.2693, CH= 42360.4523
Training epoch 427, recon_loss:0.782788, zinb_loss:0.645659, cluster_loss:0.156373
Clustering   427: ASW= 0.8040, DB= 0.2682, CH= 42025.9546
Training epoch 428, recon_loss:0.781998, zinb_loss:0.645603, cluster_loss:0.156259
Clustering   428: ASW= 0.8046, DB= 0.2689, CH= 42428.8099
Training epoch 429, recon_loss:0.782397, zinb_loss:0.645810, cluster_loss:0.156301
Clustering   429: ASW= 0.8039, DB= 0.2686, CH= 42063.8559
Training epoch 430, recon_loss:0.781668, zinb_loss:0.645776, cluster_loss:0.156176
Clustering   430: ASW= 0.8050, DB= 0.2683, CH= 42502.7234
Training epoch 431, recon_loss:0.782070, zinb_loss:0.645920, cluster_loss:0.156266
Clustering   431: ASW= 0.8039, DB= 0.2686, CH= 42095.0676
Training epoch 432, recon_loss:0.781397, zinb_loss:0.645904, cluster_loss:0.156120
Clustering   432: ASW= 0.8053, DB= 0.2678, CH= 42573.0110
Training epoch 433, recon_loss:0.781764, zinb_loss:0.645975, cluster_loss:0.156248
Clustering   433: ASW= 0.8039, DB= 0.2686, CH= 42122.1112
Training epoch 434, recon_loss:0.781163, zinb_loss:0.645964, cluster_loss:0.156066
Clustering   434: ASW= 0.8056, DB= 0.2672, CH= 42643.4703
Training epoch 435, recon_loss:0.781488, zinb_loss:0.645980, cluster_loss:0.156224
Clustering   435: ASW= 0.8040, DB= 0.2686, CH= 42157.9828
Training epoch 436, recon_loss:0.781028, zinb_loss:0.645971, cluster_loss:0.156016
Clustering   436: ASW= 0.8059, DB= 0.2669, CH= 42706.4407
Training epoch 437, recon_loss:0.781396, zinb_loss:0.646009, cluster_loss:0.156229
Clustering   437: ASW= 0.8040, DB= 0.2685, CH= 42189.7299
Training epoch 438, recon_loss:0.781202, zinb_loss:0.646021, cluster_loss:0.156027
Clustering   438: ASW= 0.8061, DB= 0.2669, CH= 42757.8668
Training epoch 439, recon_loss:0.781787, zinb_loss:0.646141, cluster_loss:0.156332
Clustering   439: ASW= 0.8041, DB= 0.2683, CH= 42213.2693
Training epoch 440, recon_loss:0.781872, zinb_loss:0.646158, cluster_loss:0.156149
Clustering   440: ASW= 0.8063, DB= 0.2667, CH= 42792.5731
Training epoch 441, recon_loss:0.782709, zinb_loss:0.646264, cluster_loss:0.156557
Clustering   441: ASW= 0.8041, DB= 0.2680, CH= 42226.4646
Training epoch 442, recon_loss:0.782786, zinb_loss:0.646134, cluster_loss:0.156328
Clustering   442: ASW= 0.8064, DB= 0.2671, CH= 42785.2483
Training epoch 443, recon_loss:0.783539, zinb_loss:0.646057, cluster_loss:0.156781
Clustering   443: ASW= 0.8040, DB= 0.2681, CH= 42225.7401
Training epoch 444, recon_loss:0.783658, zinb_loss:0.645823, cluster_loss:0.156513
Clustering   444: ASW= 0.8063, DB= 0.2669, CH= 42714.9748
Training epoch 445, recon_loss:0.784057, zinb_loss:0.645686, cluster_loss:0.156963
Clustering   445: ASW= 0.8039, DB= 0.2681, CH= 42212.4398
Training epoch 446, recon_loss:0.784271, zinb_loss:0.645471, cluster_loss:0.156662
Clustering   446: ASW= 0.8063, DB= 0.2670, CH= 42647.6379
Training epoch 447, recon_loss:0.784022, zinb_loss:0.645337, cluster_loss:0.157054
Clustering   447: ASW= 0.8039, DB= 0.2679, CH= 42207.8667
Training epoch 448, recon_loss:0.784171, zinb_loss:0.645173, cluster_loss:0.156692
Clustering   448: ASW= 0.8062, DB= 0.2677, CH= 42635.0963
Training epoch 449, recon_loss:0.783479, zinb_loss:0.645044, cluster_loss:0.156997
Clustering   449: ASW= 0.8041, DB= 0.2681, CH= 42247.4413
Training epoch 450, recon_loss:0.783575, zinb_loss:0.644946, cluster_loss:0.156609
Clustering   450: ASW= 0.8062, DB= 0.2675, CH= 42667.0624
Training epoch 451, recon_loss:0.782723, zinb_loss:0.644834, cluster_loss:0.156819
Clustering   451: ASW= 0.8043, DB= 0.2678, CH= 42296.4157
Training epoch 452, recon_loss:0.782901, zinb_loss:0.644782, cluster_loss:0.156461
Clustering   452: ASW= 0.8062, DB= 0.2674, CH= 42713.3822
Training epoch 453, recon_loss:0.782083, zinb_loss:0.644685, cluster_loss:0.156610
Clustering   453: ASW= 0.8046, DB= 0.2674, CH= 42357.9854
Training epoch 454, recon_loss:0.782394, zinb_loss:0.644658, cluster_loss:0.156294
Clustering   454: ASW= 0.8062, DB= 0.2674, CH= 42766.5342
Training epoch 455, recon_loss:0.781705, zinb_loss:0.644589, cluster_loss:0.156417
Clustering   455: ASW= 0.8049, DB= 0.2668, CH= 42433.6958
Training epoch 456, recon_loss:0.782064, zinb_loss:0.644581, cluster_loss:0.156152
Clustering   456: ASW= 0.8062, DB= 0.2675, CH= 42826.2027
Training epoch 457, recon_loss:0.781430, zinb_loss:0.644544, cluster_loss:0.156243
Clustering   457: ASW= 0.8052, DB= 0.2666, CH= 42521.7148
Training epoch 458, recon_loss:0.781874, zinb_loss:0.644533, cluster_loss:0.156021
Clustering   458: ASW= 0.8062, DB= 0.2669, CH= 42869.8353
Training epoch 459, recon_loss:0.781307, zinb_loss:0.644540, cluster_loss:0.156071
Clustering   459: ASW= 0.8056, DB= 0.2665, CH= 42632.2811
Training epoch 460, recon_loss:0.781876, zinb_loss:0.644515, cluster_loss:0.155935
Clustering   460: ASW= 0.8062, DB= 0.2664, CH= 42906.1827
Training epoch 461, recon_loss:0.781477, zinb_loss:0.644597, cluster_loss:0.155954
Clustering   461: ASW= 0.8059, DB= 0.2662, CH= 42738.7006
Training epoch 462, recon_loss:0.782171, zinb_loss:0.644557, cluster_loss:0.155950
Clustering   462: ASW= 0.8063, DB= 0.2657, CH= 42927.0080
Training epoch 463, recon_loss:0.781933, zinb_loss:0.644721, cluster_loss:0.155947
Clustering   463: ASW= 0.8061, DB= 0.2660, CH= 42803.4954
Training epoch 464, recon_loss:0.782661, zinb_loss:0.644673, cluster_loss:0.156098
Clustering   464: ASW= 0.8063, DB= 0.2657, CH= 42963.6026
Training epoch 465, recon_loss:0.782513, zinb_loss:0.644900, cluster_loss:0.156089
Clustering   465: ASW= 0.8062, DB= 0.2656, CH= 42832.2117
Training epoch 466, recon_loss:0.783129, zinb_loss:0.644843, cluster_loss:0.156380
Clustering   466: ASW= 0.8064, DB= 0.2656, CH= 42975.8083
Training epoch 467, recon_loss:0.782888, zinb_loss:0.645055, cluster_loss:0.156330
Clustering   467: ASW= 0.8062, DB= 0.2656, CH= 42820.7894
Training epoch 468, recon_loss:0.783332, zinb_loss:0.644984, cluster_loss:0.156721
Clustering   468: ASW= 0.8065, DB= 0.2657, CH= 42953.0430
Training epoch 469, recon_loss:0.782964, zinb_loss:0.645104, cluster_loss:0.156572
Clustering   469: ASW= 0.8060, DB= 0.2657, CH= 42802.0896
Training epoch 470, recon_loss:0.783184, zinb_loss:0.645021, cluster_loss:0.157003
Clustering   470: ASW= 0.8065, DB= 0.2661, CH= 42880.7125
Training epoch 471, recon_loss:0.782867, zinb_loss:0.645058, cluster_loss:0.156684
Clustering   471: ASW= 0.8059, DB= 0.2660, CH= 42818.4602
Training epoch 472, recon_loss:0.782944, zinb_loss:0.644980, cluster_loss:0.157168
Clustering   472: ASW= 0.8064, DB= 0.2656, CH= 42774.3863
Training epoch 473, recon_loss:0.782769, zinb_loss:0.645017, cluster_loss:0.156714
Clustering   473: ASW= 0.8058, DB= 0.2670, CH= 42854.1509
Training epoch 474, recon_loss:0.782834, zinb_loss:0.644981, cluster_loss:0.157267
Clustering   474: ASW= 0.8062, DB= 0.2654, CH= 42676.7876
Training epoch 475, recon_loss:0.782649, zinb_loss:0.645059, cluster_loss:0.156579
Clustering   475: ASW= 0.8058, DB= 0.2667, CH= 42905.8273
Training epoch 476, recon_loss:0.782543, zinb_loss:0.645011, cluster_loss:0.157114
Clustering   476: ASW= 0.8062, DB= 0.2645, CH= 42656.7664
Training epoch 477, recon_loss:0.782328, zinb_loss:0.645115, cluster_loss:0.156375
Clustering   477: ASW= 0.8059, DB= 0.2669, CH= 42958.6983
Training epoch 478, recon_loss:0.782134, zinb_loss:0.645056, cluster_loss:0.156864
Clustering   478: ASW= 0.8065, DB= 0.2643, CH= 42694.5783
Training epoch 479, recon_loss:0.781886, zinb_loss:0.645164, cluster_loss:0.156161
Clustering   479: ASW= 0.8060, DB= 0.2670, CH= 43047.9461
Training epoch 480, recon_loss:0.781694, zinb_loss:0.645106, cluster_loss:0.156595
Clustering   480: ASW= 0.8067, DB= 0.2641, CH= 42773.1816
Training epoch 481, recon_loss:0.781385, zinb_loss:0.645189, cluster_loss:0.155970
Clustering   481: ASW= 0.8063, DB= 0.2663, CH= 43161.7936
Training epoch 482, recon_loss:0.781314, zinb_loss:0.645156, cluster_loss:0.156376
Clustering   482: ASW= 0.8069, DB= 0.2636, CH= 42849.7210
Training epoch 483, recon_loss:0.780963, zinb_loss:0.645234, cluster_loss:0.155834
Clustering   483: ASW= 0.8066, DB= 0.2658, CH= 43280.6560
Training epoch 484, recon_loss:0.781117, zinb_loss:0.645257, cluster_loss:0.156239
Clustering   484: ASW= 0.8071, DB= 0.2635, CH= 42892.1872
Training epoch 485, recon_loss:0.780792, zinb_loss:0.645387, cluster_loss:0.155761
Clustering   485: ASW= 0.8069, DB= 0.2653, CH= 43410.5354
Training epoch 486, recon_loss:0.781168, zinb_loss:0.645461, cluster_loss:0.156198
Clustering   486: ASW= 0.8071, DB= 0.2635, CH= 42908.3689
Training epoch 487, recon_loss:0.780824, zinb_loss:0.645700, cluster_loss:0.155735
Clustering   487: ASW= 0.8072, DB= 0.2649, CH= 43553.9411
Training epoch 488, recon_loss:0.781349, zinb_loss:0.645780, cluster_loss:0.156197
Clustering   488: ASW= 0.8070, DB= 0.2637, CH= 42891.1891
Training epoch 489, recon_loss:0.781043, zinb_loss:0.646115, cluster_loss:0.155759
Clustering   489: ASW= 0.8076, DB= 0.2643, CH= 43661.8192
Training epoch 490, recon_loss:0.781533, zinb_loss:0.646003, cluster_loss:0.156187
Clustering   490: ASW= 0.8071, DB= 0.2643, CH= 42930.4356
Training epoch 491, recon_loss:0.781008, zinb_loss:0.646146, cluster_loss:0.155823
Clustering   491: ASW= 0.8077, DB= 0.2639, CH= 43670.5296
Training epoch 492, recon_loss:0.781421, zinb_loss:0.645903, cluster_loss:0.156165
Clustering   492: ASW= 0.8071, DB= 0.2643, CH= 42999.8136
Training epoch 493, recon_loss:0.780909, zinb_loss:0.646012, cluster_loss:0.155929
Clustering   493: ASW= 0.8078, DB= 0.2637, CH= 43674.0917
Training epoch 494, recon_loss:0.781362, zinb_loss:0.645672, cluster_loss:0.156194
Clustering   494: ASW= 0.8072, DB= 0.2647, CH= 43064.4736
Training epoch 495, recon_loss:0.780889, zinb_loss:0.645789, cluster_loss:0.156084
Clustering   495: ASW= 0.8078, DB= 0.2635, CH= 43654.7972
Training epoch 496, recon_loss:0.781393, zinb_loss:0.645433, cluster_loss:0.156236
Clustering   496: ASW= 0.8074, DB= 0.2647, CH= 43135.9342
Training epoch 497, recon_loss:0.780949, zinb_loss:0.645567, cluster_loss:0.156249
Clustering   497: ASW= 0.8077, DB= 0.2633, CH= 43636.3722
Training epoch 498, recon_loss:0.781443, zinb_loss:0.645212, cluster_loss:0.156266
Clustering   498: ASW= 0.8077, DB= 0.2647, CH= 43218.7986
Training epoch 499, recon_loss:0.780995, zinb_loss:0.645362, cluster_loss:0.156389
Clustering   499: ASW= 0.8075, DB= 0.2627, CH= 43614.6982
Training epoch 500, recon_loss:0.781478, zinb_loss:0.645033, cluster_loss:0.156240
Clustering   500: ASW= 0.8079, DB= 0.2645, CH= 43295.4937
Training epoch 501, recon_loss:0.781003, zinb_loss:0.645158, cluster_loss:0.156424
Clustering   501: ASW= 0.8075, DB= 0.2620, CH= 43604.4781
Training epoch 502, recon_loss:0.781499, zinb_loss:0.644866, cluster_loss:0.156133
Clustering   502: ASW= 0.8080, DB= 0.2645, CH= 43366.2404
Training epoch 503, recon_loss:0.780951, zinb_loss:0.644941, cluster_loss:0.156316
Clustering   503: ASW= 0.8076, DB= 0.2619, CH= 43646.0121
Training epoch 504, recon_loss:0.781585, zinb_loss:0.644680, cluster_loss:0.156014
Clustering   504: ASW= 0.8082, DB= 0.2643, CH= 43432.1042
Training epoch 505, recon_loss:0.781119, zinb_loss:0.644731, cluster_loss:0.156250
Clustering   505: ASW= 0.8077, DB= 0.2618, CH= 43690.5528
Training epoch 506, recon_loss:0.781912, zinb_loss:0.644498, cluster_loss:0.155966
Clustering   506: ASW= 0.8083, DB= 0.2642, CH= 43462.9658
Training epoch 507, recon_loss:0.781417, zinb_loss:0.644560, cluster_loss:0.156240
Clustering   507: ASW= 0.8077, DB= 0.2620, CH= 43714.3784
Training epoch 508, recon_loss:0.781772, zinb_loss:0.644329, cluster_loss:0.155905
Clustering   508: ASW= 0.8084, DB= 0.2639, CH= 43493.2263
Training epoch 509, recon_loss:0.781109, zinb_loss:0.644385, cluster_loss:0.156155
Clustering   509: ASW= 0.8077, DB= 0.2619, CH= 43725.5124
Training epoch 510, recon_loss:0.781332, zinb_loss:0.644181, cluster_loss:0.155804
Clustering   510: ASW= 0.8087, DB= 0.2638, CH= 43564.7812
Training epoch 511, recon_loss:0.780725, zinb_loss:0.644224, cluster_loss:0.156108
Clustering   511: ASW= 0.8076, DB= 0.2620, CH= 43714.6881
Training epoch 512, recon_loss:0.781039, zinb_loss:0.644077, cluster_loss:0.155776
Clustering   512: ASW= 0.8088, DB= 0.2638, CH= 43618.2890
Training epoch 513, recon_loss:0.780609, zinb_loss:0.644134, cluster_loss:0.156076
Clustering   513: ASW= 0.8075, DB= 0.2618, CH= 43715.4106
Training epoch 514, recon_loss:0.780862, zinb_loss:0.644052, cluster_loss:0.155765
Clustering   514: ASW= 0.8090, DB= 0.2631, CH= 43722.3490
Training epoch 515, recon_loss:0.780496, zinb_loss:0.644112, cluster_loss:0.156101
Clustering   515: ASW= 0.8074, DB= 0.2621, CH= 43716.2648
Training epoch 516, recon_loss:0.780753, zinb_loss:0.644062, cluster_loss:0.155805
Clustering   516: ASW= 0.8090, DB= 0.2631, CH= 43748.7848
Training epoch 517, recon_loss:0.780328, zinb_loss:0.644140, cluster_loss:0.156029
Clustering   517: ASW= 0.8074, DB= 0.2615, CH= 43733.7683
Training epoch 518, recon_loss:0.780543, zinb_loss:0.644125, cluster_loss:0.155714
Clustering   518: ASW= 0.8092, DB= 0.2628, CH= 43848.0465
Training epoch 519, recon_loss:0.780233, zinb_loss:0.644224, cluster_loss:0.155912
Clustering   519: ASW= 0.8076, DB= 0.2615, CH= 43790.9650
Training epoch 520, recon_loss:0.780553, zinb_loss:0.644206, cluster_loss:0.155683
Clustering   520: ASW= 0.8092, DB= 0.2626, CH= 43908.3510
Training epoch 521, recon_loss:0.780473, zinb_loss:0.644381, cluster_loss:0.155870
Clustering   521: ASW= 0.8078, DB= 0.2617, CH= 43872.0880
Training epoch 522, recon_loss:0.780958, zinb_loss:0.644316, cluster_loss:0.155730
Clustering   522: ASW= 0.8091, DB= 0.2622, CH= 43907.3297
Training epoch 523, recon_loss:0.780957, zinb_loss:0.644573, cluster_loss:0.155873
Clustering   523: ASW= 0.8082, DB= 0.2612, CH= 43958.4974
Training epoch 524, recon_loss:0.781487, zinb_loss:0.644431, cluster_loss:0.155802
Clustering   524: ASW= 0.8089, DB= 0.2622, CH= 43921.3709
Training epoch 525, recon_loss:0.781397, zinb_loss:0.644716, cluster_loss:0.155900
Clustering   525: ASW= 0.8086, DB= 0.2605, CH= 44028.3166
Training epoch 526, recon_loss:0.781711, zinb_loss:0.644469, cluster_loss:0.155880
Clustering   526: ASW= 0.8086, DB= 0.2627, CH= 43887.2726
Training epoch 527, recon_loss:0.781568, zinb_loss:0.644754, cluster_loss:0.155896
Clustering   527: ASW= 0.8091, DB= 0.2604, CH= 44131.1273
Training epoch 528, recon_loss:0.781582, zinb_loss:0.644455, cluster_loss:0.155926
Clustering   528: ASW= 0.8082, DB= 0.2629, CH= 43867.1461
Training epoch 529, recon_loss:0.781701, zinb_loss:0.644750, cluster_loss:0.155894
Clustering   529: ASW= 0.8096, DB= 0.2601, CH= 44193.9407
Training epoch 530, recon_loss:0.781560, zinb_loss:0.644439, cluster_loss:0.156010
Clustering   530: ASW= 0.8079, DB= 0.2637, CH= 43846.5786
Training epoch 531, recon_loss:0.782124, zinb_loss:0.644764, cluster_loss:0.155918
Clustering   531: ASW= 0.8099, DB= 0.2598, CH= 44233.6913
Training epoch 532, recon_loss:0.781639, zinb_loss:0.644465, cluster_loss:0.156129
Clustering   532: ASW= 0.8074, DB= 0.2639, CH= 43786.8876
Training epoch 533, recon_loss:0.782126, zinb_loss:0.644795, cluster_loss:0.155941
Clustering   533: ASW= 0.8102, DB= 0.2606, CH= 44258.9145
Training epoch 534, recon_loss:0.781268, zinb_loss:0.644469, cluster_loss:0.156163
Clustering   534: ASW= 0.8072, DB= 0.2644, CH= 43786.2120
Training epoch 535, recon_loss:0.781620, zinb_loss:0.644782, cluster_loss:0.155873
Clustering   535: ASW= 0.8103, DB= 0.2605, CH= 44253.5166
Training epoch 536, recon_loss:0.780965, zinb_loss:0.644442, cluster_loss:0.156071
Clustering   536: ASW= 0.8072, DB= 0.2641, CH= 43828.0405
Training epoch 537, recon_loss:0.781209, zinb_loss:0.644735, cluster_loss:0.155799
Clustering   537: ASW= 0.8102, DB= 0.2605, CH= 44236.6775
Training epoch 538, recon_loss:0.780710, zinb_loss:0.644404, cluster_loss:0.155909
Clustering   538: ASW= 0.8074, DB= 0.2638, CH= 43926.4304
Training epoch 539, recon_loss:0.780764, zinb_loss:0.644591, cluster_loss:0.155703
Clustering   539: ASW= 0.8102, DB= 0.2610, CH= 44236.4976
Training epoch 540, recon_loss:0.780322, zinb_loss:0.644306, cluster_loss:0.155708
Clustering   540: ASW= 0.8078, DB= 0.2633, CH= 44051.4582
Training epoch 541, recon_loss:0.780304, zinb_loss:0.644400, cluster_loss:0.155580
Clustering   541: ASW= 0.8101, DB= 0.2608, CH= 44259.5912
Training epoch 542, recon_loss:0.779960, zinb_loss:0.644208, cluster_loss:0.155538
Clustering   542: ASW= 0.8081, DB= 0.2628, CH= 44157.6921
Training epoch 543, recon_loss:0.779965, zinb_loss:0.644250, cluster_loss:0.155475
Clustering   543: ASW= 0.8101, DB= 0.2604, CH= 44293.5226
Training epoch 544, recon_loss:0.779716, zinb_loss:0.644152, cluster_loss:0.155395
Clustering   544: ASW= 0.8085, DB= 0.2622, CH= 44268.6185
Training epoch 545, recon_loss:0.779738, zinb_loss:0.644150, cluster_loss:0.155389
Clustering   545: ASW= 0.8101, DB= 0.2603, CH= 44337.2439
Training epoch 546, recon_loss:0.779611, zinb_loss:0.644139, cluster_loss:0.155293
Clustering   546: ASW= 0.8088, DB= 0.2618, CH= 44360.3563
Training epoch 547, recon_loss:0.779602, zinb_loss:0.644111, cluster_loss:0.155321
Clustering   547: ASW= 0.8102, DB= 0.2604, CH= 44387.6416
Training epoch 548, recon_loss:0.779616, zinb_loss:0.644168, cluster_loss:0.155215
Clustering   548: ASW= 0.8091, DB= 0.2615, CH= 44444.3837
Training epoch 549, recon_loss:0.779568, zinb_loss:0.644131, cluster_loss:0.155278
Clustering   549: ASW= 0.8102, DB= 0.2603, CH= 44442.0928
Training epoch 550, recon_loss:0.779770, zinb_loss:0.644243, cluster_loss:0.155183
Clustering   550: ASW= 0.8094, DB= 0.2612, CH= 44510.0034
Training epoch 551, recon_loss:0.779762, zinb_loss:0.644250, cluster_loss:0.155291
Clustering   551: ASW= 0.8103, DB= 0.2599, CH= 44493.5821
Training epoch 552, recon_loss:0.780256, zinb_loss:0.644387, cluster_loss:0.155213
Clustering   552: ASW= 0.8096, DB= 0.2604, CH= 44546.4168
Training epoch 553, recon_loss:0.780334, zinb_loss:0.644457, cluster_loss:0.155398
Clustering   553: ASW= 0.8104, DB= 0.2601, CH= 44542.7050
Training epoch 554, recon_loss:0.781065, zinb_loss:0.644579, cluster_loss:0.155348
Clustering   554: ASW= 0.8097, DB= 0.2603, CH= 44572.9343
Training epoch 555, recon_loss:0.780900, zinb_loss:0.644676, cluster_loss:0.155614
Clustering   555: ASW= 0.8104, DB= 0.2606, CH= 44570.2040
Training epoch 556, recon_loss:0.781378, zinb_loss:0.644686, cluster_loss:0.155497
Clustering   556: ASW= 0.8098, DB= 0.2602, CH= 44588.7587
Training epoch 557, recon_loss:0.781050, zinb_loss:0.644688, cluster_loss:0.155802
Clustering   557: ASW= 0.8105, DB= 0.2606, CH= 44575.7605
Training epoch 558, recon_loss:0.781319, zinb_loss:0.644619, cluster_loss:0.155588
Clustering   558: ASW= 0.8097, DB= 0.2601, CH= 44599.4676
Training epoch 559, recon_loss:0.780849, zinb_loss:0.644492, cluster_loss:0.155919
Clustering   559: ASW= 0.8105, DB= 0.2605, CH= 44566.4428
Training epoch 560, recon_loss:0.781081, zinb_loss:0.644398, cluster_loss:0.155652
Clustering   560: ASW= 0.8096, DB= 0.2597, CH= 44555.8493
Training epoch 561, recon_loss:0.780511, zinb_loss:0.644249, cluster_loss:0.155969
Clustering   561: ASW= 0.8105, DB= 0.2603, CH= 44574.0596
Training epoch 562, recon_loss:0.780675, zinb_loss:0.644134, cluster_loss:0.155664
Clustering   562: ASW= 0.8095, DB= 0.2596, CH= 44530.2719
Training epoch 563, recon_loss:0.780114, zinb_loss:0.644012, cluster_loss:0.155955
Clustering   563: ASW= 0.8106, DB= 0.2596, CH= 44570.6584
Training epoch 564, recon_loss:0.780267, zinb_loss:0.643910, cluster_loss:0.155615
Clustering   564: ASW= 0.8096, DB= 0.2596, CH= 44578.2046
Training epoch 565, recon_loss:0.779836, zinb_loss:0.643820, cluster_loss:0.155943
Clustering   565: ASW= 0.8106, DB= 0.2600, CH= 44535.6738
Training epoch 566, recon_loss:0.780137, zinb_loss:0.643812, cluster_loss:0.155584
Clustering   566: ASW= 0.8099, DB= 0.2589, CH= 44644.5828
Training epoch 567, recon_loss:0.779757, zinb_loss:0.643773, cluster_loss:0.155926
Clustering   567: ASW= 0.8106, DB= 0.2600, CH= 44492.0582
Training epoch 568, recon_loss:0.779920, zinb_loss:0.643830, cluster_loss:0.155548
Clustering   568: ASW= 0.8101, DB= 0.2587, CH= 44747.4730
Training epoch 569, recon_loss:0.779741, zinb_loss:0.643841, cluster_loss:0.155910
Clustering   569: ASW= 0.8104, DB= 0.2604, CH= 44434.5430
Training epoch 570, recon_loss:0.779863, zinb_loss:0.643956, cluster_loss:0.155537
Clustering   570: ASW= 0.8105, DB= 0.2588, CH= 44861.7968
Training epoch 571, recon_loss:0.779666, zinb_loss:0.643933, cluster_loss:0.155828
Clustering   571: ASW= 0.8103, DB= 0.2604, CH= 44412.1202
Training epoch 572, recon_loss:0.779611, zinb_loss:0.644006, cluster_loss:0.155444
Clustering   572: ASW= 0.8107, DB= 0.2586, CH= 44960.0115
Training epoch 573, recon_loss:0.779459, zinb_loss:0.643924, cluster_loss:0.155664
Clustering   573: ASW= 0.8104, DB= 0.2605, CH= 44457.4602
Training epoch 574, recon_loss:0.779400, zinb_loss:0.643964, cluster_loss:0.155354
Clustering   574: ASW= 0.8110, DB= 0.2583, CH= 45074.2866
Training epoch 575, recon_loss:0.779589, zinb_loss:0.643899, cluster_loss:0.155644
Clustering   575: ASW= 0.8104, DB= 0.2602, CH= 44477.7655
Training epoch 576, recon_loss:0.779616, zinb_loss:0.643937, cluster_loss:0.155405
Clustering   576: ASW= 0.8111, DB= 0.2584, CH= 45163.3471
Training epoch 577, recon_loss:0.779986, zinb_loss:0.643890, cluster_loss:0.155754
Clustering   577: ASW= 0.8104, DB= 0.2599, CH= 44473.0167
Training epoch 578, recon_loss:0.779858, zinb_loss:0.643922, cluster_loss:0.155492
Clustering   578: ASW= 0.8112, DB= 0.2583, CH= 45208.1166
Training epoch 579, recon_loss:0.780190, zinb_loss:0.643871, cluster_loss:0.155848
Clustering   579: ASW= 0.8104, DB= 0.2598, CH= 44460.5708
Training epoch 580, recon_loss:0.779888, zinb_loss:0.643903, cluster_loss:0.155502
Clustering   580: ASW= 0.8113, DB= 0.2581, CH= 45227.9453
Training epoch 581, recon_loss:0.780053, zinb_loss:0.643794, cluster_loss:0.155811
Clustering   581: ASW= 0.8104, DB= 0.2594, CH= 44473.9500
Training epoch 582, recon_loss:0.779590, zinb_loss:0.643846, cluster_loss:0.155399
Clustering   582: ASW= 0.8114, DB= 0.2583, CH= 45254.8656
Training epoch 583, recon_loss:0.779654, zinb_loss:0.643672, cluster_loss:0.155681
Clustering   583: ASW= 0.8104, DB= 0.2593, CH= 44516.5553
Training epoch 584, recon_loss:0.779198, zinb_loss:0.643770, cluster_loss:0.155252
Clustering   584: ASW= 0.8116, DB= 0.2580, CH= 45286.3452
Training epoch 585, recon_loss:0.779274, zinb_loss:0.643570, cluster_loss:0.155553
Clustering   585: ASW= 0.8104, DB= 0.2592, CH= 44573.8160
Training epoch 586, recon_loss:0.779026, zinb_loss:0.643756, cluster_loss:0.155140
Clustering   586: ASW= 0.8118, DB= 0.2579, CH= 45337.5574
Training epoch 587, recon_loss:0.779299, zinb_loss:0.643565, cluster_loss:0.155518
Clustering   587: ASW= 0.8103, DB= 0.2592, CH= 44617.2740
Training epoch 588, recon_loss:0.779417, zinb_loss:0.643859, cluster_loss:0.155128
Clustering   588: ASW= 0.8122, DB= 0.2576, CH= 45384.2594
Training epoch 589, recon_loss:0.779754, zinb_loss:0.643700, cluster_loss:0.155634
Clustering   589: ASW= 0.8101, DB= 0.2595, CH= 44638.3082
Training epoch 590, recon_loss:0.780169, zinb_loss:0.644096, cluster_loss:0.155266
Clustering   590: ASW= 0.8126, DB= 0.2574, CH= 45404.3221
Training epoch 591, recon_loss:0.780172, zinb_loss:0.643955, cluster_loss:0.155839
Clustering   591: ASW= 0.8099, DB= 0.2585, CH= 44691.1306
Training epoch 592, recon_loss:0.780529, zinb_loss:0.644264, cluster_loss:0.155436
Clustering   592: ASW= 0.8127, DB= 0.2574, CH= 45350.0267
Training epoch 593, recon_loss:0.780281, zinb_loss:0.644100, cluster_loss:0.155915
Clustering   593: ASW= 0.8100, DB= 0.2579, CH= 44779.0745
Training epoch 594, recon_loss:0.780412, zinb_loss:0.644187, cluster_loss:0.155406
Clustering   594: ASW= 0.8124, DB= 0.2575, CH= 45275.9918
Training epoch 595, recon_loss:0.780148, zinb_loss:0.644089, cluster_loss:0.155744
Clustering   595: ASW= 0.8102, DB= 0.2576, CH= 44839.5361
Training epoch 596, recon_loss:0.780226, zinb_loss:0.644087, cluster_loss:0.155358
Clustering   596: ASW= 0.8122, DB= 0.2582, CH= 45228.0594
Training epoch 597, recon_loss:0.780186, zinb_loss:0.644096, cluster_loss:0.155618
Clustering   597: ASW= 0.8105, DB= 0.2573, CH= 44903.7156
Training epoch 598, recon_loss:0.780114, zinb_loss:0.644071, cluster_loss:0.155342
Clustering   598: ASW= 0.8120, DB= 0.2583, CH= 45227.3790
Training epoch 599, recon_loss:0.780177, zinb_loss:0.644115, cluster_loss:0.155575
Clustering   599: ASW= 0.8106, DB= 0.2574, CH= 44917.6847
Training epoch 600, recon_loss:0.779871, zinb_loss:0.644093, cluster_loss:0.155316
Clustering   600: ASW= 0.8120, DB= 0.2582, CH= 45278.4881
Training epoch 601, recon_loss:0.780074, zinb_loss:0.644150, cluster_loss:0.155532
Clustering   601: ASW= 0.8109, DB= 0.2570, CH= 44968.4103
Training epoch 602, recon_loss:0.779644, zinb_loss:0.644147, cluster_loss:0.155275
Clustering   602: ASW= 0.8119, DB= 0.2580, CH= 45325.4166
Training epoch 603, recon_loss:0.779885, zinb_loss:0.644182, cluster_loss:0.155513
Clustering   603: ASW= 0.8109, DB= 0.2569, CH= 44963.3408
Training epoch 604, recon_loss:0.779539, zinb_loss:0.644206, cluster_loss:0.155252
Clustering   604: ASW= 0.8120, DB= 0.2578, CH= 45389.3617
Training epoch 605, recon_loss:0.779861, zinb_loss:0.644250, cluster_loss:0.155534
Clustering   605: ASW= 0.8110, DB= 0.2570, CH= 44987.3507
Training epoch 606, recon_loss:0.779782, zinb_loss:0.644377, cluster_loss:0.155290
Clustering   606: ASW= 0.8120, DB= 0.2578, CH= 45449.1004
Training epoch 607, recon_loss:0.780254, zinb_loss:0.644470, cluster_loss:0.155681
Clustering   607: ASW= 0.8110, DB= 0.2569, CH= 44970.5108
Training epoch 608, recon_loss:0.780501, zinb_loss:0.644767, cluster_loss:0.155456
Clustering   608: ASW= 0.8121, DB= 0.2576, CH= 45496.2287
Training epoch 609, recon_loss:0.781070, zinb_loss:0.644817, cluster_loss:0.155961
Clustering   609: ASW= 0.8109, DB= 0.2572, CH= 44881.7386
Training epoch 610, recon_loss:0.781091, zinb_loss:0.645018, cluster_loss:0.155601
Clustering   610: ASW= 0.8121, DB= 0.2577, CH= 45534.6271
Training epoch 611, recon_loss:0.781349, zinb_loss:0.644752, cluster_loss:0.156029
Clustering   611: ASW= 0.8110, DB= 0.2574, CH= 44885.5987
Training epoch 612, recon_loss:0.780716, zinb_loss:0.644738, cluster_loss:0.155497
Clustering   612: ASW= 0.8120, DB= 0.2577, CH= 45539.3884
Training epoch 613, recon_loss:0.780712, zinb_loss:0.644317, cluster_loss:0.155810
Clustering   613: ASW= 0.8113, DB= 0.2571, CH= 44953.3667
Training epoch 614, recon_loss:0.779934, zinb_loss:0.644289, cluster_loss:0.155257
Clustering   614: ASW= 0.8120, DB= 0.2577, CH= 45555.5730
Training epoch 615, recon_loss:0.779892, zinb_loss:0.643909, cluster_loss:0.155541
Clustering   615: ASW= 0.8115, DB= 0.2570, CH= 45032.9228
Training epoch 616, recon_loss:0.779302, zinb_loss:0.643939, cluster_loss:0.155064
Clustering   616: ASW= 0.8122, DB= 0.2573, CH= 45593.9422
Training epoch 617, recon_loss:0.779354, zinb_loss:0.643635, cluster_loss:0.155360
Clustering   617: ASW= 0.8117, DB= 0.2571, CH= 45118.8111
Training epoch 618, recon_loss:0.778943, zinb_loss:0.643714, cluster_loss:0.154949
Clustering   618: ASW= 0.8123, DB= 0.2572, CH= 45658.5656
Training epoch 619, recon_loss:0.779048, zinb_loss:0.643465, cluster_loss:0.155241
Clustering   619: ASW= 0.8119, DB= 0.2569, CH= 45192.1463
Training epoch 620, recon_loss:0.778766, zinb_loss:0.643574, cluster_loss:0.154897
Clustering   620: ASW= 0.8124, DB= 0.2574, CH= 45727.7503
Training epoch 621, recon_loss:0.778904, zinb_loss:0.643371, cluster_loss:0.155152
Clustering   621: ASW= 0.8121, DB= 0.2567, CH= 45275.0496
Training epoch 622, recon_loss:0.778715, zinb_loss:0.643481, cluster_loss:0.154887
Clustering   622: ASW= 0.8125, DB= 0.2575, CH= 45781.0486
Training epoch 623, recon_loss:0.778906, zinb_loss:0.643325, cluster_loss:0.155087
Clustering   623: ASW= 0.8123, DB= 0.2564, CH= 45345.1516
Training epoch 624, recon_loss:0.778799, zinb_loss:0.643415, cluster_loss:0.154909
Clustering   624: ASW= 0.8125, DB= 0.2574, CH= 45828.8004
Training epoch 625, recon_loss:0.778948, zinb_loss:0.643295, cluster_loss:0.155038
Clustering   625: ASW= 0.8125, DB= 0.2566, CH= 45414.2683
Training epoch 626, recon_loss:0.778839, zinb_loss:0.643373, cluster_loss:0.154931
Clustering   626: ASW= 0.8126, DB= 0.2577, CH= 45889.1364
Training epoch 627, recon_loss:0.778906, zinb_loss:0.643268, cluster_loss:0.155004
Clustering   627: ASW= 0.8127, DB= 0.2567, CH= 45448.2311
Training epoch 628, recon_loss:0.778695, zinb_loss:0.643359, cluster_loss:0.154924
Clustering   628: ASW= 0.8127, DB= 0.2576, CH= 45969.5222
Training epoch 629, recon_loss:0.778753, zinb_loss:0.643264, cluster_loss:0.154970
Clustering   629: ASW= 0.8128, DB= 0.2570, CH= 45486.5367
Training epoch 630, recon_loss:0.778469, zinb_loss:0.643391, cluster_loss:0.154932
Clustering   630: ASW= 0.8128, DB= 0.2577, CH= 46042.2409
Training epoch 631, recon_loss:0.778628, zinb_loss:0.643313, cluster_loss:0.154984
Clustering   631: ASW= 0.8129, DB= 0.2571, CH= 45490.5853
Training epoch 632, recon_loss:0.778464, zinb_loss:0.643528, cluster_loss:0.155019
Clustering   632: ASW= 0.8128, DB= 0.2575, CH= 46073.0330
Training epoch 633, recon_loss:0.778854, zinb_loss:0.643483, cluster_loss:0.155110
Clustering   633: ASW= 0.8130, DB= 0.2569, CH= 45466.2708
Training epoch 634, recon_loss:0.778808, zinb_loss:0.643761, cluster_loss:0.155187
Clustering   634: ASW= 0.8128, DB= 0.2576, CH= 46074.6084
Training epoch 635, recon_loss:0.779661, zinb_loss:0.643759, cluster_loss:0.155224
Clustering   635: ASW= 0.8129, DB= 0.2573, CH= 45420.8440
Training epoch 636, recon_loss:0.779147, zinb_loss:0.643916, cluster_loss:0.155295
Clustering   636: ASW= 0.8126, DB= 0.2576, CH= 46045.3832
Training epoch 637, recon_loss:0.780143, zinb_loss:0.643879, cluster_loss:0.155275
Clustering   637: ASW= 0.8132, DB= 0.2572, CH= 45468.4731
Training epoch 638, recon_loss:0.779234, zinb_loss:0.643869, cluster_loss:0.155395
Clustering   638: ASW= 0.8124, DB= 0.2579, CH= 45930.5185
Training epoch 639, recon_loss:0.780603, zinb_loss:0.643804, cluster_loss:0.155244
Clustering   639: ASW= 0.8135, DB= 0.2562, CH= 45527.8077
Training epoch 640, recon_loss:0.779197, zinb_loss:0.643699, cluster_loss:0.155385
Clustering   640: ASW= 0.8123, DB= 0.2572, CH= 45925.8813
Training epoch 641, recon_loss:0.780247, zinb_loss:0.643587, cluster_loss:0.155176
Clustering   641: ASW= 0.8140, DB= 0.2559, CH= 45687.7344
Training epoch 642, recon_loss:0.778833, zinb_loss:0.643461, cluster_loss:0.155491
Clustering   642: ASW= 0.8119, DB= 0.2569, CH= 45827.4094
Training epoch 643, recon_loss:0.779603, zinb_loss:0.643329, cluster_loss:0.155149
Clustering   643: ASW= 0.8140, DB= 0.2562, CH= 45735.2778
Training epoch 644, recon_loss:0.778496, zinb_loss:0.643321, cluster_loss:0.155468
Clustering   644: ASW= 0.8119, DB= 0.2560, CH= 45823.4928
Training epoch 645, recon_loss:0.779218, zinb_loss:0.643208, cluster_loss:0.155015
Clustering   645: ASW= 0.8140, DB= 0.2558, CH= 45819.4702
Training epoch 646, recon_loss:0.778248, zinb_loss:0.643196, cluster_loss:0.155308
Clustering   646: ASW= 0.8120, DB= 0.2559, CH= 45863.8867
Training epoch 647, recon_loss:0.778884, zinb_loss:0.643091, cluster_loss:0.154901
Clustering   647: ASW= 0.8140, DB= 0.2558, CH= 45884.1937
Training epoch 648, recon_loss:0.778124, zinb_loss:0.643097, cluster_loss:0.155182
Clustering   648: ASW= 0.8122, DB= 0.2557, CH= 45897.9540
Training epoch 649, recon_loss:0.778705, zinb_loss:0.643025, cluster_loss:0.154817
Clustering   649: ASW= 0.8141, DB= 0.2557, CH= 45963.7538
Training epoch 650, recon_loss:0.778107, zinb_loss:0.643033, cluster_loss:0.155092
Clustering   650: ASW= 0.8122, DB= 0.2554, CH= 45924.6186
Training epoch 651, recon_loss:0.778690, zinb_loss:0.643006, cluster_loss:0.154796
Clustering   651: ASW= 0.8142, DB= 0.2552, CH= 46018.5789
Training epoch 652, recon_loss:0.778243, zinb_loss:0.643031, cluster_loss:0.155043
Clustering   652: ASW= 0.8124, DB= 0.2553, CH= 45964.8776
Training epoch 653, recon_loss:0.778872, zinb_loss:0.643057, cluster_loss:0.154833
Clustering   653: ASW= 0.8142, DB= 0.2555, CH= 46079.7586
Training epoch 654, recon_loss:0.778560, zinb_loss:0.643091, cluster_loss:0.155050
Clustering   654: ASW= 0.8125, DB= 0.2552, CH= 45989.8558
Training epoch 655, recon_loss:0.779242, zinb_loss:0.643167, cluster_loss:0.155024
Clustering   655: ASW= 0.8142, DB= 0.2551, CH= 46103.8140
Training epoch 656, recon_loss:0.779103, zinb_loss:0.643213, cluster_loss:0.155182
Clustering   656: ASW= 0.8125, DB= 0.2551, CH= 45961.2954
Training epoch 657, recon_loss:0.779602, zinb_loss:0.643325, cluster_loss:0.155302
Clustering   657: ASW= 0.8141, DB= 0.2560, CH= 46109.7265
Training epoch 658, recon_loss:0.779604, zinb_loss:0.643361, cluster_loss:0.155346
Clustering   658: ASW= 0.8125, DB= 0.2549, CH= 45954.9612
Training epoch 659, recon_loss:0.779723, zinb_loss:0.643470, cluster_loss:0.155545
Clustering   659: ASW= 0.8141, DB= 0.2561, CH= 46158.1466
Training epoch 660, recon_loss:0.779932, zinb_loss:0.643498, cluster_loss:0.155542
Clustering   660: ASW= 0.8124, DB= 0.2548, CH= 45891.4763
Training epoch 661, recon_loss:0.779578, zinb_loss:0.643465, cluster_loss:0.155658
Clustering   661: ASW= 0.8139, DB= 0.2559, CH= 46129.4767
Training epoch 662, recon_loss:0.779792, zinb_loss:0.643494, cluster_loss:0.155491
Clustering   662: ASW= 0.8127, DB= 0.2544, CH= 45972.8724
Training epoch 663, recon_loss:0.779059, zinb_loss:0.643351, cluster_loss:0.155534
Clustering   663: ASW= 0.8140, DB= 0.2559, CH= 46168.9750
Training epoch 664, recon_loss:0.779199, zinb_loss:0.643385, cluster_loss:0.155254
Clustering   664: ASW= 0.8130, DB= 0.2544, CH= 46095.6254
Training epoch 665, recon_loss:0.778309, zinb_loss:0.643074, cluster_loss:0.155305
Clustering   665: ASW= 0.8139, DB= 0.2563, CH= 46148.6770
Training epoch 666, recon_loss:0.778481, zinb_loss:0.643155, cluster_loss:0.154932
Clustering   666: ASW= 0.8134, DB= 0.2545, CH= 46252.4600
Training epoch 667, recon_loss:0.777918, zinb_loss:0.642933, cluster_loss:0.155062
Clustering   667: ASW= 0.8141, DB= 0.2559, CH= 46260.1339
Training epoch 668, recon_loss:0.778191, zinb_loss:0.643055, cluster_loss:0.154723
Clustering   668: ASW= 0.8136, DB= 0.2541, CH= 46334.1467
Training epoch 669, recon_loss:0.777863, zinb_loss:0.642852, cluster_loss:0.154928
Clustering   669: ASW= 0.8141, DB= 0.2559, CH= 46338.1977
Training epoch 670, recon_loss:0.778222, zinb_loss:0.643019, cluster_loss:0.154581
Clustering   670: ASW= 0.8139, DB= 0.2537, CH= 46419.8440
Training epoch 671, recon_loss:0.778079, zinb_loss:0.642846, cluster_loss:0.154857
Clustering   671: ASW= 0.8142, DB= 0.2560, CH= 46407.3440
Training epoch 672, recon_loss:0.778468, zinb_loss:0.643025, cluster_loss:0.154485
Clustering   672: ASW= 0.8141, DB= 0.2542, CH= 46490.7059
Training epoch 673, recon_loss:0.778338, zinb_loss:0.642851, cluster_loss:0.154799
Clustering   673: ASW= 0.8142, DB= 0.2555, CH= 46440.3844
Training epoch 674, recon_loss:0.778714, zinb_loss:0.643021, cluster_loss:0.154398
Clustering   674: ASW= 0.8142, DB= 0.2541, CH= 46530.2675
Training epoch 675, recon_loss:0.778520, zinb_loss:0.642832, cluster_loss:0.154742
Clustering   675: ASW= 0.8141, DB= 0.2556, CH= 46463.8192
Training epoch 676, recon_loss:0.778898, zinb_loss:0.642989, cluster_loss:0.154327
Clustering   676: ASW= 0.8142, DB= 0.2541, CH= 46551.0367
Training epoch 677, recon_loss:0.778592, zinb_loss:0.642767, cluster_loss:0.154707
Clustering   677: ASW= 0.8140, DB= 0.2556, CH= 46449.3458
Training epoch 678, recon_loss:0.778952, zinb_loss:0.642918, cluster_loss:0.154287
Clustering   678: ASW= 0.8142, DB= 0.2539, CH= 46559.4259
Training epoch 679, recon_loss:0.778521, zinb_loss:0.642660, cluster_loss:0.154701
Clustering   679: ASW= 0.8138, DB= 0.2559, CH= 46413.8801
Training epoch 680, recon_loss:0.778830, zinb_loss:0.642816, cluster_loss:0.154281
Clustering   680: ASW= 0.8142, DB= 0.2539, CH= 46582.0812
Training epoch 681, recon_loss:0.778301, zinb_loss:0.642551, cluster_loss:0.154719
Clustering   681: ASW= 0.8135, DB= 0.2561, CH= 46363.5061
Training epoch 682, recon_loss:0.778553, zinb_loss:0.642714, cluster_loss:0.154291
Clustering   682: ASW= 0.8144, DB= 0.2539, CH= 46621.6832
Training epoch 683, recon_loss:0.778053, zinb_loss:0.642472, cluster_loss:0.154773
Clustering   683: ASW= 0.8132, DB= 0.2560, CH= 46290.9516
Training epoch 684, recon_loss:0.778334, zinb_loss:0.642665, cluster_loss:0.154350
Clustering   684: ASW= 0.8146, DB= 0.2541, CH= 46680.9755
Training epoch 685, recon_loss:0.778035, zinb_loss:0.642466, cluster_loss:0.154950
Clustering   685: ASW= 0.8128, DB= 0.2559, CH= 46159.7453
Training epoch 686, recon_loss:0.778376, zinb_loss:0.642728, cluster_loss:0.154539
Clustering   686: ASW= 0.8147, DB= 0.2542, CH= 46705.1483
Training epoch 687, recon_loss:0.778331, zinb_loss:0.642698, cluster_loss:0.155236
Clustering   687: ASW= 0.8123, DB= 0.2554, CH= 46010.4483
Training epoch 688, recon_loss:0.778654, zinb_loss:0.643076, cluster_loss:0.154769
Clustering   688: ASW= 0.8146, DB= 0.2537, CH= 46667.7891
Training epoch 689, recon_loss:0.778960, zinb_loss:0.643261, cluster_loss:0.155450
Clustering   689: ASW= 0.8121, DB= 0.2550, CH= 45859.9627
Training epoch 690, recon_loss:0.779204, zinb_loss:0.643671, cluster_loss:0.154960
Clustering   690: ASW= 0.8143, DB= 0.2548, CH= 46637.5341
Training epoch 691, recon_loss:0.779466, zinb_loss:0.643745, cluster_loss:0.155420
Clustering   691: ASW= 0.8128, DB= 0.2543, CH= 45939.9380
Training epoch 692, recon_loss:0.779247, zinb_loss:0.643721, cluster_loss:0.154902
Clustering   692: ASW= 0.8145, DB= 0.2547, CH= 46684.2038
Training epoch 693, recon_loss:0.779477, zinb_loss:0.643743, cluster_loss:0.155122
Clustering   693: ASW= 0.8138, DB= 0.2528, CH= 46308.1874
Training epoch 694, recon_loss:0.778943, zinb_loss:0.643501, cluster_loss:0.154745
Clustering   694: ASW= 0.8146, DB= 0.2553, CH= 46758.6592
Training epoch 695, recon_loss:0.779277, zinb_loss:0.643511, cluster_loss:0.155040
Clustering   695: ASW= 0.8141, DB= 0.2531, CH= 46291.7327
Training epoch 696, recon_loss:0.779168, zinb_loss:0.643279, cluster_loss:0.154750
Clustering   696: ASW= 0.8146, DB= 0.2552, CH= 46754.3705
Training epoch 697, recon_loss:0.779291, zinb_loss:0.643358, cluster_loss:0.154886
Clustering   697: ASW= 0.8149, DB= 0.2524, CH= 46554.2697
Training epoch 698, recon_loss:0.778885, zinb_loss:0.643145, cluster_loss:0.154585
Clustering   698: ASW= 0.8149, DB= 0.2550, CH= 46884.2579
Training epoch 699, recon_loss:0.779008, zinb_loss:0.643128, cluster_loss:0.154762
Clustering   699: ASW= 0.8151, DB= 0.2521, CH= 46651.5204
Training epoch 700, recon_loss:0.778591, zinb_loss:0.642866, cluster_loss:0.154573
Clustering   700: ASW= 0.8147, DB= 0.2549, CH= 46854.4308
Training epoch 701, recon_loss:0.778886, zinb_loss:0.642988, cluster_loss:0.154722
Clustering   701: ASW= 0.8155, DB= 0.2524, CH= 46714.4321
Training epoch 702, recon_loss:0.778507, zinb_loss:0.642817, cluster_loss:0.154476
Clustering   702: ASW= 0.8148, DB= 0.2543, CH= 46985.8439
Training epoch 703, recon_loss:0.778516, zinb_loss:0.642859, cluster_loss:0.154665
Clustering   703: ASW= 0.8157, DB= 0.2525, CH= 46747.6141
Training epoch 704, recon_loss:0.778098, zinb_loss:0.642716, cluster_loss:0.154412
Clustering   704: ASW= 0.8148, DB= 0.2542, CH= 47041.9454
Training epoch 705, recon_loss:0.778243, zinb_loss:0.642762, cluster_loss:0.154617
Clustering   705: ASW= 0.8158, DB= 0.2527, CH= 46798.1154
Training epoch 706, recon_loss:0.777888, zinb_loss:0.642665, cluster_loss:0.154378
Clustering   706: ASW= 0.8148, DB= 0.2539, CH= 47120.0528
Training epoch 707, recon_loss:0.778087, zinb_loss:0.642735, cluster_loss:0.154629
Clustering   707: ASW= 0.8159, DB= 0.2528, CH= 46818.5047
Training epoch 708, recon_loss:0.777859, zinb_loss:0.642722, cluster_loss:0.154401
Clustering   708: ASW= 0.8149, DB= 0.2539, CH= 47221.0879
Training epoch 709, recon_loss:0.778074, zinb_loss:0.642790, cluster_loss:0.154725
Clustering   709: ASW= 0.8158, DB= 0.2530, CH= 46777.9486
Training epoch 710, recon_loss:0.777951, zinb_loss:0.642915, cluster_loss:0.154469
Clustering   710: ASW= 0.8150, DB= 0.2536, CH= 47345.5181
Training epoch 711, recon_loss:0.778174, zinb_loss:0.643005, cluster_loss:0.154892
Clustering   711: ASW= 0.8157, DB= 0.2529, CH= 46715.3361
Training epoch 712, recon_loss:0.778256, zinb_loss:0.643272, cluster_loss:0.154632
Clustering   712: ASW= 0.8152, DB= 0.2536, CH= 47443.6459
Training epoch 713, recon_loss:0.778531, zinb_loss:0.643366, cluster_loss:0.155186
Clustering   713: ASW= 0.8154, DB= 0.2533, CH= 46578.3952
Training epoch 714, recon_loss:0.778820, zinb_loss:0.643772, cluster_loss:0.154919
Clustering   714: ASW= 0.8152, DB= 0.2538, CH= 47489.9950
Training epoch 715, recon_loss:0.779109, zinb_loss:0.643819, cluster_loss:0.155592
Clustering   715: ASW= 0.8152, DB= 0.2524, CH= 46404.5132
Training epoch 716, recon_loss:0.779317, zinb_loss:0.644271, cluster_loss:0.155242
Clustering   716: ASW= 0.8152, DB= 0.2538, CH= 47404.3629
Training epoch 717, recon_loss:0.779436, zinb_loss:0.644071, cluster_loss:0.155811
Clustering   717: ASW= 0.8148, DB= 0.2524, CH= 46274.4754
Training epoch 718, recon_loss:0.778766, zinb_loss:0.644258, cluster_loss:0.155210
Clustering   718: ASW= 0.8153, DB= 0.2540, CH= 47273.7566
Training epoch 719, recon_loss:0.778815, zinb_loss:0.643840, cluster_loss:0.155524
Clustering   719: ASW= 0.8145, DB= 0.2524, CH= 46314.4062
Training epoch 720, recon_loss:0.778028, zinb_loss:0.643948, cluster_loss:0.154941
Clustering   720: ASW= 0.8152, DB= 0.2540, CH= 47183.4404
Training epoch 721, recon_loss:0.778078, zinb_loss:0.643497, cluster_loss:0.155191
Clustering   721: ASW= 0.8145, DB= 0.2532, CH= 46429.2643
Training epoch 722, recon_loss:0.777466, zinb_loss:0.643652, cluster_loss:0.154664
Clustering   722: ASW= 0.8154, DB= 0.2537, CH= 47163.5072
Training epoch 723, recon_loss:0.777766, zinb_loss:0.643245, cluster_loss:0.154889
Clustering   723: ASW= 0.8145, DB= 0.2527, CH= 46547.4448
Training epoch 724, recon_loss:0.777325, zinb_loss:0.643434, cluster_loss:0.154423
Clustering   724: ASW= 0.8157, DB= 0.2538, CH= 47274.7167
Training epoch 725, recon_loss:0.777768, zinb_loss:0.643120, cluster_loss:0.154753
Clustering   725: ASW= 0.8146, DB= 0.2530, CH= 46646.5248
Training epoch 726, recon_loss:0.777500, zinb_loss:0.643337, cluster_loss:0.154298
Clustering   726: ASW= 0.8158, DB= 0.2537, CH= 47291.3223
Training epoch 727, recon_loss:0.778230, zinb_loss:0.643104, cluster_loss:0.154717
Clustering   727: ASW= 0.8145, DB= 0.2533, CH= 46688.4826
Training epoch 728, recon_loss:0.777669, zinb_loss:0.643242, cluster_loss:0.154247
Clustering   728: ASW= 0.8158, DB= 0.2538, CH= 47312.7544
Training epoch 729, recon_loss:0.778311, zinb_loss:0.643057, cluster_loss:0.154645
Clustering   729: ASW= 0.8146, DB= 0.2534, CH= 46782.4242
Training epoch 730, recon_loss:0.777685, zinb_loss:0.643163, cluster_loss:0.154194
Clustering   730: ASW= 0.8158, DB= 0.2537, CH= 47302.4639
Training epoch 731, recon_loss:0.778329, zinb_loss:0.643000, cluster_loss:0.154654
Clustering   731: ASW= 0.8145, DB= 0.2534, CH= 46777.8121
Training epoch 732, recon_loss:0.777722, zinb_loss:0.643079, cluster_loss:0.154186
Clustering   732: ASW= 0.8157, DB= 0.2539, CH= 47282.2563
Training epoch 733, recon_loss:0.778195, zinb_loss:0.642983, cluster_loss:0.154594
Clustering   733: ASW= 0.8148, DB= 0.2529, CH= 46894.3607
Training epoch 734, recon_loss:0.777556, zinb_loss:0.643051, cluster_loss:0.154137
Clustering   734: ASW= 0.8158, DB= 0.2528, CH= 47289.6340
Training epoch 735, recon_loss:0.778127, zinb_loss:0.642976, cluster_loss:0.154633
Clustering   735: ASW= 0.8147, DB= 0.2528, CH= 46873.6539
Training epoch 736, recon_loss:0.777626, zinb_loss:0.643013, cluster_loss:0.154179
Clustering   736: ASW= 0.8158, DB= 0.2534, CH= 47272.0766
Training epoch 737, recon_loss:0.778224, zinb_loss:0.643000, cluster_loss:0.154608
Clustering   737: ASW= 0.8149, DB= 0.2525, CH= 46986.4518
Training epoch 738, recon_loss:0.777667, zinb_loss:0.642999, cluster_loss:0.154204
Clustering   738: ASW= 0.8160, DB= 0.2525, CH= 47320.4043
Training epoch 739, recon_loss:0.778128, zinb_loss:0.642991, cluster_loss:0.154619
Clustering   739: ASW= 0.8150, DB= 0.2525, CH= 47063.7451
Training epoch 740, recon_loss:0.777665, zinb_loss:0.642931, cluster_loss:0.154264
Clustering   740: ASW= 0.8162, DB= 0.2524, CH= 47371.2833
Training epoch 741, recon_loss:0.778091, zinb_loss:0.642901, cluster_loss:0.154643
Clustering   741: ASW= 0.8152, DB= 0.2522, CH= 47139.6468
Training epoch 742, recon_loss:0.777611, zinb_loss:0.642796, cluster_loss:0.154310
Clustering   742: ASW= 0.8163, DB= 0.2526, CH= 47401.2335
Training epoch 743, recon_loss:0.778017, zinb_loss:0.642759, cluster_loss:0.154595
Clustering   743: ASW= 0.8156, DB= 0.2522, CH= 47266.1735
Training epoch 744, recon_loss:0.777525, zinb_loss:0.642649, cluster_loss:0.154324
Clustering   744: ASW= 0.8163, DB= 0.2529, CH= 47411.0784
Training epoch 745, recon_loss:0.778003, zinb_loss:0.642626, cluster_loss:0.154541
Clustering   745: ASW= 0.8160, DB= 0.2523, CH= 47403.1263
Training epoch 746, recon_loss:0.777745, zinb_loss:0.642576, cluster_loss:0.154450
Clustering   746: ASW= 0.8160, DB= 0.2527, CH= 47327.2942
Training epoch 747, recon_loss:0.778618, zinb_loss:0.642709, cluster_loss:0.154583
Clustering   747: ASW= 0.8165, DB= 0.2523, CH= 47529.0536
Training epoch 748, recon_loss:0.778444, zinb_loss:0.642643, cluster_loss:0.154656
Clustering   748: ASW= 0.8158, DB= 0.2532, CH= 47145.3374
Training epoch 749, recon_loss:0.778834, zinb_loss:0.642681, cluster_loss:0.154616
Clustering   749: ASW= 0.8166, DB= 0.2518, CH= 47480.6571
Training epoch 750, recon_loss:0.778071, zinb_loss:0.642586, cluster_loss:0.154525
Clustering   750: ASW= 0.8162, DB= 0.2519, CH= 47376.8111
Training epoch 751, recon_loss:0.778302, zinb_loss:0.642574, cluster_loss:0.154495
Clustering   751: ASW= 0.8173, DB= 0.2515, CH= 47628.3939
Training epoch 752, recon_loss:0.777697, zinb_loss:0.642467, cluster_loss:0.154564
Clustering   752: ASW= 0.8159, DB= 0.2515, CH= 47291.5846
Training epoch 753, recon_loss:0.777785, zinb_loss:0.642463, cluster_loss:0.154371
Clustering   753: ASW= 0.8174, DB= 0.2506, CH= 47658.2725
Training epoch 754, recon_loss:0.777374, zinb_loss:0.642398, cluster_loss:0.154467
Clustering   754: ASW= 0.8161, DB= 0.2514, CH= 47404.3883
Training epoch 755, recon_loss:0.777439, zinb_loss:0.642371, cluster_loss:0.154306
Clustering   755: ASW= 0.8175, DB= 0.2505, CH= 47725.8554
Training epoch 756, recon_loss:0.777338, zinb_loss:0.642399, cluster_loss:0.154446
Clustering   756: ASW= 0.8160, DB= 0.2512, CH= 47434.3642
Training epoch 757, recon_loss:0.777346, zinb_loss:0.642335, cluster_loss:0.154306
Clustering   757: ASW= 0.8176, DB= 0.2506, CH= 47756.8651
Training epoch 758, recon_loss:0.777390, zinb_loss:0.642441, cluster_loss:0.154453
Clustering   758: ASW= 0.8160, DB= 0.2512, CH= 47490.4779
Training epoch 759, recon_loss:0.777287, zinb_loss:0.642327, cluster_loss:0.154353
Clustering   759: ASW= 0.8176, DB= 0.2505, CH= 47780.7299
Training epoch 760, recon_loss:0.777355, zinb_loss:0.642479, cluster_loss:0.154476
Clustering   760: ASW= 0.8159, DB= 0.2511, CH= 47512.1207
Training epoch 761, recon_loss:0.777063, zinb_loss:0.642295, cluster_loss:0.154399
Clustering   761: ASW= 0.8177, DB= 0.2504, CH= 47804.9705
Training epoch 762, recon_loss:0.777165, zinb_loss:0.642490, cluster_loss:0.154481
Clustering   762: ASW= 0.8159, DB= 0.2509, CH= 47541.0533
Training epoch 763, recon_loss:0.776744, zinb_loss:0.642252, cluster_loss:0.154441
Clustering   763: ASW= 0.8177, DB= 0.2505, CH= 47860.1241
Training epoch 764, recon_loss:0.776937, zinb_loss:0.642473, cluster_loss:0.154499
Clustering   764: ASW= 0.8159, DB= 0.2506, CH= 47546.3944
Training epoch 765, recon_loss:0.776554, zinb_loss:0.642238, cluster_loss:0.154515
Clustering   765: ASW= 0.8177, DB= 0.2508, CH= 47919.2878
Training epoch 766, recon_loss:0.776914, zinb_loss:0.642466, cluster_loss:0.154557
Clustering   766: ASW= 0.8159, DB= 0.2506, CH= 47535.5444
Training epoch 767, recon_loss:0.776619, zinb_loss:0.642280, cluster_loss:0.154659
Clustering   767: ASW= 0.8177, DB= 0.2513, CH= 47962.3543
Training epoch 768, recon_loss:0.777070, zinb_loss:0.642494, cluster_loss:0.154678
Clustering   768: ASW= 0.8160, DB= 0.2504, CH= 47496.6849
Training epoch 769, recon_loss:0.776925, zinb_loss:0.642351, cluster_loss:0.154852
Clustering   769: ASW= 0.8175, DB= 0.2519, CH= 47951.3571
Training epoch 770, recon_loss:0.777375, zinb_loss:0.642543, cluster_loss:0.154771
Clustering   770: ASW= 0.8162, DB= 0.2503, CH= 47494.7784
Training epoch 771, recon_loss:0.777223, zinb_loss:0.642378, cluster_loss:0.154939
Clustering   771: ASW= 0.8175, DB= 0.2517, CH= 47902.5939
Training epoch 772, recon_loss:0.777657, zinb_loss:0.642523, cluster_loss:0.154726
Clustering   772: ASW= 0.8163, DB= 0.2498, CH= 47455.9876
Training epoch 773, recon_loss:0.777357, zinb_loss:0.642314, cluster_loss:0.154855
Clustering   773: ASW= 0.8174, DB= 0.2517, CH= 47929.0949
Training epoch 774, recon_loss:0.777748, zinb_loss:0.642456, cluster_loss:0.154608
Clustering   774: ASW= 0.8167, DB= 0.2500, CH= 47466.7829
Training epoch 775, recon_loss:0.777261, zinb_loss:0.642362, cluster_loss:0.154642
Clustering   775: ASW= 0.8175, DB= 0.2517, CH= 48040.5220
Training epoch 776, recon_loss:0.777675, zinb_loss:0.642417, cluster_loss:0.154412
Clustering   776: ASW= 0.8167, DB= 0.2502, CH= 47520.0338
Training epoch 777, recon_loss:0.777097, zinb_loss:0.642360, cluster_loss:0.154397
Clustering   777: ASW= 0.8177, DB= 0.2512, CH= 48195.8718
Training epoch 778, recon_loss:0.777402, zinb_loss:0.642360, cluster_loss:0.154232
Clustering   778: ASW= 0.8170, DB= 0.2500, CH= 47569.5095
Training epoch 779, recon_loss:0.777089, zinb_loss:0.642446, cluster_loss:0.154225
Clustering   779: ASW= 0.8177, DB= 0.2509, CH= 48318.4659
Training epoch 780, recon_loss:0.777348, zinb_loss:0.642391, cluster_loss:0.154156
Clustering   780: ASW= 0.8171, DB= 0.2500, CH= 47600.6326
Training epoch 781, recon_loss:0.777106, zinb_loss:0.642578, cluster_loss:0.154125
Clustering   781: ASW= 0.8178, DB= 0.2504, CH= 48402.8916
Training epoch 782, recon_loss:0.777366, zinb_loss:0.642482, cluster_loss:0.154117
Clustering   782: ASW= 0.8172, DB= 0.2501, CH= 47661.2916
Training epoch 783, recon_loss:0.777195, zinb_loss:0.642721, cluster_loss:0.154126
Clustering   783: ASW= 0.8177, DB= 0.2500, CH= 48385.4478
Training epoch 784, recon_loss:0.777570, zinb_loss:0.642617, cluster_loss:0.154152
Clustering   784: ASW= 0.8173, DB= 0.2500, CH= 47741.7082
Training epoch 785, recon_loss:0.777457, zinb_loss:0.642872, cluster_loss:0.154243
Clustering   785: ASW= 0.8176, DB= 0.2498, CH= 48351.9413
Training epoch 786, recon_loss:0.777874, zinb_loss:0.642687, cluster_loss:0.154366
Clustering   786: ASW= 0.8172, DB= 0.2504, CH= 47727.0965
Training epoch 787, recon_loss:0.777787, zinb_loss:0.643018, cluster_loss:0.154381
Clustering   787: ASW= 0.8178, DB= 0.2493, CH= 48381.5106
Training epoch 788, recon_loss:0.778060, zinb_loss:0.642752, cluster_loss:0.154558
Clustering   788: ASW= 0.8170, DB= 0.2506, CH= 47712.5417
Training epoch 789, recon_loss:0.777937, zinb_loss:0.643020, cluster_loss:0.154499
Clustering   789: ASW= 0.8178, DB= 0.2491, CH= 48367.9728
Training epoch 790, recon_loss:0.777849, zinb_loss:0.642692, cluster_loss:0.154598
Clustering   790: ASW= 0.8170, DB= 0.2508, CH= 47727.6427
Training epoch 791, recon_loss:0.777770, zinb_loss:0.642872, cluster_loss:0.154431
Clustering   791: ASW= 0.8181, DB= 0.2493, CH= 48373.9331
Training epoch 792, recon_loss:0.777454, zinb_loss:0.642546, cluster_loss:0.154465
Clustering   792: ASW= 0.8172, DB= 0.2506, CH= 47795.4850
Training epoch 793, recon_loss:0.777261, zinb_loss:0.642619, cluster_loss:0.154237
Clustering   793: ASW= 0.8181, DB= 0.2492, CH= 48399.6225
Training epoch 794, recon_loss:0.777027, zinb_loss:0.642347, cluster_loss:0.154358
Clustering   794: ASW= 0.8172, DB= 0.2508, CH= 47901.9421
Training epoch 795, recon_loss:0.776922, zinb_loss:0.642503, cluster_loss:0.154068
Clustering   795: ASW= 0.8186, DB= 0.2489, CH= 48454.2996
Training epoch 796, recon_loss:0.776757, zinb_loss:0.642251, cluster_loss:0.154356
Clustering   796: ASW= 0.8169, DB= 0.2507, CH= 47818.2988
Training epoch 797, recon_loss:0.776722, zinb_loss:0.642344, cluster_loss:0.154045
Clustering   797: ASW= 0.8187, DB= 0.2486, CH= 48441.2521
Training epoch 798, recon_loss:0.776676, zinb_loss:0.642167, cluster_loss:0.154342
Clustering   798: ASW= 0.8170, DB= 0.2504, CH= 47976.0835
Training epoch 799, recon_loss:0.776579, zinb_loss:0.642202, cluster_loss:0.154067
Clustering   799: ASW= 0.8190, DB= 0.2488, CH= 48440.0572
Training epoch 800, recon_loss:0.776459, zinb_loss:0.642036, cluster_loss:0.154354
Clustering   800: ASW= 0.8169, DB= 0.2502, CH= 48030.9443
Training epoch 801, recon_loss:0.776354, zinb_loss:0.642006, cluster_loss:0.154069
Clustering   801: ASW= 0.8190, DB= 0.2491, CH= 48375.9419
Training epoch 802, recon_loss:0.776317, zinb_loss:0.641914, cluster_loss:0.154342
Clustering   802: ASW= 0.8168, DB= 0.2502, CH= 48102.7502
Training epoch 803, recon_loss:0.776293, zinb_loss:0.641914, cluster_loss:0.154051
Clustering   803: ASW= 0.8191, DB= 0.2494, CH= 48320.9716
Training epoch 804, recon_loss:0.776182, zinb_loss:0.641863, cluster_loss:0.154286
Clustering   804: ASW= 0.8166, DB= 0.2503, CH= 48104.1027
Training epoch 805, recon_loss:0.776241, zinb_loss:0.641802, cluster_loss:0.153981
Clustering   805: ASW= 0.8187, DB= 0.2487, CH= 48238.8003
Training epoch 806, recon_loss:0.776287, zinb_loss:0.641803, cluster_loss:0.154259
Clustering   806: ASW= 0.8162, DB= 0.2501, CH= 48069.5493
Training epoch 807, recon_loss:0.776543, zinb_loss:0.641743, cluster_loss:0.154024
Clustering   807: ASW= 0.8186, DB= 0.2488, CH= 48205.3504
Training epoch 808, recon_loss:0.776842, zinb_loss:0.641853, cluster_loss:0.154445
Clustering   808: ASW= 0.8159, DB= 0.2499, CH= 47990.6884
Training epoch 809, recon_loss:0.777597, zinb_loss:0.641726, cluster_loss:0.154176
Clustering   809: ASW= 0.8180, DB= 0.2495, CH= 48075.4070
Training epoch 810, recon_loss:0.778103, zinb_loss:0.641896, cluster_loss:0.154592
Clustering   810: ASW= 0.8158, DB= 0.2492, CH= 47977.0058
Training epoch 811, recon_loss:0.778300, zinb_loss:0.641769, cluster_loss:0.154309
Clustering   811: ASW= 0.8181, DB= 0.2492, CH= 48138.0054
Training epoch 812, recon_loss:0.778090, zinb_loss:0.641837, cluster_loss:0.154685
Clustering   812: ASW= 0.8160, DB= 0.2492, CH= 47929.4855
Training epoch 813, recon_loss:0.778098, zinb_loss:0.641629, cluster_loss:0.154289
Clustering   813: ASW= 0.8177, DB= 0.2498, CH= 48024.8445
Training epoch 814, recon_loss:0.777516, zinb_loss:0.641690, cluster_loss:0.154535
Clustering   814: ASW= 0.8165, DB= 0.2485, CH= 48183.1802
Training epoch 815, recon_loss:0.777463, zinb_loss:0.641537, cluster_loss:0.154098
Clustering   815: ASW= 0.8182, DB= 0.2489, CH= 48281.9729
Training epoch 816, recon_loss:0.776912, zinb_loss:0.641548, cluster_loss:0.154250
Clustering   816: ASW= 0.8172, DB= 0.2483, CH= 48368.4019
Training epoch 817, recon_loss:0.776816, zinb_loss:0.641339, cluster_loss:0.154047
Clustering   817: ASW= 0.8183, DB= 0.2493, CH= 48405.7639
Training epoch 818, recon_loss:0.776597, zinb_loss:0.641512, cluster_loss:0.154149
Clustering   818: ASW= 0.8179, DB= 0.2478, CH= 48606.5199
Training epoch 819, recon_loss:0.776546, zinb_loss:0.641218, cluster_loss:0.154173
Clustering   819: ASW= 0.8182, DB= 0.2495, CH= 48396.1961
Training epoch 820, recon_loss:0.776774, zinb_loss:0.641644, cluster_loss:0.154259
Clustering   820: ASW= 0.8182, DB= 0.2475, CH= 48763.4320
Training epoch 821, recon_loss:0.776839, zinb_loss:0.641285, cluster_loss:0.154583
Clustering   821: ASW= 0.8178, DB= 0.2503, CH= 48176.7142
Training epoch 822, recon_loss:0.777665, zinb_loss:0.642235, cluster_loss:0.154503
Clustering   822: ASW= 0.8187, DB= 0.2472, CH= 48936.6512
Training epoch 823, recon_loss:0.777820, zinb_loss:0.641901, cluster_loss:0.154954
Clustering   823: ASW= 0.8176, DB= 0.2507, CH= 47989.3517
Training epoch 824, recon_loss:0.778772, zinb_loss:0.642889, cluster_loss:0.154606
Clustering   824: ASW= 0.8190, DB= 0.2472, CH= 49019.9698
Training epoch 825, recon_loss:0.778876, zinb_loss:0.642552, cluster_loss:0.155118
Clustering   825: ASW= 0.8175, DB= 0.2504, CH= 47861.7666
Training epoch 826, recon_loss:0.778771, zinb_loss:0.643058, cluster_loss:0.154575
Clustering   826: ASW= 0.8189, DB= 0.2470, CH= 48913.4511
Training epoch 827, recon_loss:0.777959, zinb_loss:0.642427, cluster_loss:0.154883
Clustering   827: ASW= 0.8177, DB= 0.2507, CH= 47915.0480
Training epoch 828, recon_loss:0.777856, zinb_loss:0.642755, cluster_loss:0.154371
Clustering   828: ASW= 0.8188, DB= 0.2477, CH= 48821.8021
Training epoch 829, recon_loss:0.777135, zinb_loss:0.642103, cluster_loss:0.154636
Clustering   829: ASW= 0.8178, DB= 0.2504, CH= 48037.2285
Training epoch 830, recon_loss:0.777458, zinb_loss:0.642535, cluster_loss:0.154187
Clustering   830: ASW= 0.8189, DB= 0.2474, CH= 48886.5609
Training epoch 831, recon_loss:0.776849, zinb_loss:0.641941, cluster_loss:0.154521
Clustering   831: ASW= 0.8181, DB= 0.2506, CH= 48239.6799
Training epoch 832, recon_loss:0.777565, zinb_loss:0.642464, cluster_loss:0.154255
Clustering   832: ASW= 0.8187, DB= 0.2479, CH= 48836.7624
Training epoch 833, recon_loss:0.776898, zinb_loss:0.641913, cluster_loss:0.154519
Clustering   833: ASW= 0.8183, DB= 0.2507, CH= 48351.9679
Training epoch 834, recon_loss:0.777486, zinb_loss:0.642343, cluster_loss:0.154225
Clustering   834: ASW= 0.8189, DB= 0.2474, CH= 48877.4241
Training epoch 835, recon_loss:0.776627, zinb_loss:0.641858, cluster_loss:0.154377
Clustering   835: ASW= 0.8186, DB= 0.2503, CH= 48513.1028
Training epoch 836, recon_loss:0.777136, zinb_loss:0.642107, cluster_loss:0.154150
Clustering   836: ASW= 0.8187, DB= 0.2477, CH= 48818.0219
Training epoch 837, recon_loss:0.776188, zinb_loss:0.641703, cluster_loss:0.154169
Clustering   837: ASW= 0.8188, DB= 0.2500, CH= 48629.4057
Training epoch 838, recon_loss:0.776659, zinb_loss:0.641880, cluster_loss:0.153944
Clustering   838: ASW= 0.8188, DB= 0.2479, CH= 48890.2256
Training epoch 839, recon_loss:0.775945, zinb_loss:0.641649, cluster_loss:0.153953
Clustering   839: ASW= 0.8192, DB= 0.2493, CH= 48838.2534
Training epoch 840, recon_loss:0.776527, zinb_loss:0.641753, cluster_loss:0.153930
Clustering   840: ASW= 0.8186, DB= 0.2479, CH= 48808.6493
Training epoch 841, recon_loss:0.776093, zinb_loss:0.641703, cluster_loss:0.153929
Clustering   841: ASW= 0.8193, DB= 0.2488, CH= 48952.4310
Training epoch 842, recon_loss:0.776862, zinb_loss:0.641785, cluster_loss:0.154051
Clustering   842: ASW= 0.8184, DB= 0.2480, CH= 48691.5546
Training epoch 843, recon_loss:0.776577, zinb_loss:0.641929, cluster_loss:0.153992
Clustering   843: ASW= 0.8194, DB= 0.2483, CH= 49078.8101
Training epoch 844, recon_loss:0.777104, zinb_loss:0.641928, cluster_loss:0.154271
Clustering   844: ASW= 0.8179, DB= 0.2485, CH= 48428.4199
Training epoch 845, recon_loss:0.776686, zinb_loss:0.642224, cluster_loss:0.153975
Clustering   845: ASW= 0.8194, DB= 0.2481, CH= 49182.5850
Training epoch 846, recon_loss:0.776856, zinb_loss:0.642071, cluster_loss:0.154360
Clustering   846: ASW= 0.8174, DB= 0.2488, CH= 48188.5857
Training epoch 847, recon_loss:0.776391, zinb_loss:0.642389, cluster_loss:0.153843
Clustering   847: ASW= 0.8193, DB= 0.2476, CH= 49199.4540
Training epoch 848, recon_loss:0.776544, zinb_loss:0.642187, cluster_loss:0.154341
Clustering   848: ASW= 0.8172, DB= 0.2497, CH= 48098.5152
Training epoch 849, recon_loss:0.776126, zinb_loss:0.642438, cluster_loss:0.153665
Clustering   849: ASW= 0.8194, DB= 0.2473, CH= 49257.7995
Training epoch 850, recon_loss:0.776290, zinb_loss:0.642164, cluster_loss:0.154293
Clustering   850: ASW= 0.8172, DB= 0.2500, CH= 48094.6433
Training epoch 851, recon_loss:0.776050, zinb_loss:0.642405, cluster_loss:0.153577
Clustering   851: ASW= 0.8195, DB= 0.2470, CH= 49271.4837
Training epoch 852, recon_loss:0.776298, zinb_loss:0.642146, cluster_loss:0.154313
Clustering   852: ASW= 0.8173, DB= 0.2500, CH= 48112.5844
Training epoch 853, recon_loss:0.776291, zinb_loss:0.642317, cluster_loss:0.153604
Clustering   853: ASW= 0.8195, DB= 0.2470, CH= 49225.9738
Training epoch 854, recon_loss:0.776489, zinb_loss:0.642110, cluster_loss:0.154367
Clustering   854: ASW= 0.8176, DB= 0.2497, CH= 48214.9162
Training epoch 855, recon_loss:0.776680, zinb_loss:0.642224, cluster_loss:0.153711
Clustering   855: ASW= 0.8194, DB= 0.2468, CH= 49177.6360
Training epoch 856, recon_loss:0.776897, zinb_loss:0.642057, cluster_loss:0.154503
Clustering   856: ASW= 0.8178, DB= 0.2490, CH= 48223.4335
Training epoch 857, recon_loss:0.777168, zinb_loss:0.642093, cluster_loss:0.153857
Clustering   857: ASW= 0.8193, DB= 0.2470, CH= 49111.9809
Training epoch 858, recon_loss:0.777337, zinb_loss:0.641986, cluster_loss:0.154566
Clustering   858: ASW= 0.8183, DB= 0.2485, CH= 48402.0899
Training epoch 859, recon_loss:0.777555, zinb_loss:0.641897, cluster_loss:0.153988
Clustering   859: ASW= 0.8191, DB= 0.2473, CH= 49053.1113
Training epoch 860, recon_loss:0.777549, zinb_loss:0.641824, cluster_loss:0.154606
Clustering   860: ASW= 0.8186, DB= 0.2482, CH= 48452.2812
Training epoch 861, recon_loss:0.777591, zinb_loss:0.641687, cluster_loss:0.154002
Clustering   861: ASW= 0.8190, DB= 0.2476, CH= 49075.9767
Training epoch 862, recon_loss:0.777537, zinb_loss:0.641681, cluster_loss:0.154504
Clustering   862: ASW= 0.8192, DB= 0.2474, CH= 48710.5364
Training epoch 863, recon_loss:0.777382, zinb_loss:0.641459, cluster_loss:0.153977
Clustering   863: ASW= 0.8190, DB= 0.2476, CH= 49083.5528
Training epoch 864, recon_loss:0.777363, zinb_loss:0.641582, cluster_loss:0.154385
Clustering   864: ASW= 0.8195, DB= 0.2470, CH= 48804.1760
Training epoch 865, recon_loss:0.777330, zinb_loss:0.641377, cluster_loss:0.153967
Clustering   865: ASW= 0.8189, DB= 0.2481, CH= 49119.5843
Training epoch 866, recon_loss:0.777327, zinb_loss:0.641616, cluster_loss:0.154273
Clustering   866: ASW= 0.8198, DB= 0.2466, CH= 48910.9381
Training epoch 867, recon_loss:0.777462, zinb_loss:0.641447, cluster_loss:0.154025
Clustering   867: ASW= 0.8189, DB= 0.2484, CH= 49139.2860
Training epoch 868, recon_loss:0.777375, zinb_loss:0.641889, cluster_loss:0.154189
Clustering   868: ASW= 0.8201, DB= 0.2462, CH= 49053.0416
Training epoch 869, recon_loss:0.777481, zinb_loss:0.641662, cluster_loss:0.154128
Clustering   869: ASW= 0.8186, DB= 0.2485, CH= 49001.0625
Training epoch 870, recon_loss:0.777012, zinb_loss:0.642208, cluster_loss:0.154050
Clustering   870: ASW= 0.8204, DB= 0.2454, CH= 49177.6975
Training epoch 871, recon_loss:0.776890, zinb_loss:0.641845, cluster_loss:0.154109
Clustering   871: ASW= 0.8187, DB= 0.2491, CH= 48911.9288
Training epoch 872, recon_loss:0.776434, zinb_loss:0.642285, cluster_loss:0.153890
Clustering   872: ASW= 0.8204, DB= 0.2458, CH= 49266.3066
Training epoch 873, recon_loss:0.776381, zinb_loss:0.641928, cluster_loss:0.153984
Clustering   873: ASW= 0.8187, DB= 0.2490, CH= 48958.6766
Training epoch 874, recon_loss:0.776054, zinb_loss:0.642358, cluster_loss:0.153766
Clustering   874: ASW= 0.8204, DB= 0.2453, CH= 49322.4070
Training epoch 875, recon_loss:0.776039, zinb_loss:0.641927, cluster_loss:0.153966
Clustering   875: ASW= 0.8188, DB= 0.2494, CH= 48940.5879
Training epoch 876, recon_loss:0.775909, zinb_loss:0.642292, cluster_loss:0.153727
Clustering   876: ASW= 0.8203, DB= 0.2457, CH= 49378.6881
Training epoch 877, recon_loss:0.775911, zinb_loss:0.641876, cluster_loss:0.153920
Clustering   877: ASW= 0.8189, DB= 0.2492, CH= 49021.6875
Training epoch 878, recon_loss:0.775879, zinb_loss:0.642224, cluster_loss:0.153697
Clustering   878: ASW= 0.8204, DB= 0.2455, CH= 49424.6005
Training epoch 879, recon_loss:0.775882, zinb_loss:0.641790, cluster_loss:0.153885
Clustering   879: ASW= 0.8192, DB= 0.2491, CH= 49060.6757
Training epoch 880, recon_loss:0.775906, zinb_loss:0.642080, cluster_loss:0.153682
Clustering   880: ASW= 0.8203, DB= 0.2462, CH= 49474.9811
Training epoch 881, recon_loss:0.775888, zinb_loss:0.641684, cluster_loss:0.153857
Clustering   881: ASW= 0.8194, DB= 0.2490, CH= 49091.7465
Training epoch 882, recon_loss:0.776044, zinb_loss:0.641960, cluster_loss:0.153683
Clustering   882: ASW= 0.8202, DB= 0.2460, CH= 49515.3348
Training epoch 883, recon_loss:0.776074, zinb_loss:0.641578, cluster_loss:0.153841
Clustering   883: ASW= 0.8195, DB= 0.2490, CH= 49137.5406
Training epoch 884, recon_loss:0.776212, zinb_loss:0.641790, cluster_loss:0.153684
Clustering   884: ASW= 0.8201, DB= 0.2460, CH= 49532.8735
Training epoch 885, recon_loss:0.776194, zinb_loss:0.641456, cluster_loss:0.153851
Clustering   885: ASW= 0.8194, DB= 0.2487, CH= 49141.0682
Training epoch 886, recon_loss:0.776248, zinb_loss:0.641718, cluster_loss:0.153637
Clustering   886: ASW= 0.8203, DB= 0.2461, CH= 49586.6471
Training epoch 887, recon_loss:0.776062, zinb_loss:0.641394, cluster_loss:0.153757
Clustering   887: ASW= 0.8197, DB= 0.2482, CH= 49189.4583
Training epoch 888, recon_loss:0.776075, zinb_loss:0.641554, cluster_loss:0.153617
Clustering   888: ASW= 0.8201, DB= 0.2461, CH= 49618.5872
Training epoch 889, recon_loss:0.775857, zinb_loss:0.641287, cluster_loss:0.153741
Clustering   889: ASW= 0.8197, DB= 0.2483, CH= 49236.0970
Training epoch 890, recon_loss:0.775937, zinb_loss:0.641456, cluster_loss:0.153599
Clustering   890: ASW= 0.8202, DB= 0.2461, CH= 49685.8725
Training epoch 891, recon_loss:0.775771, zinb_loss:0.641211, cluster_loss:0.153749
Clustering   891: ASW= 0.8198, DB= 0.2477, CH= 49256.8575
Training epoch 892, recon_loss:0.776006, zinb_loss:0.641408, cluster_loss:0.153616
Clustering   892: ASW= 0.8203, DB= 0.2460, CH= 49729.4514
Training epoch 893, recon_loss:0.776000, zinb_loss:0.641221, cluster_loss:0.153811
Clustering   893: ASW= 0.8198, DB= 0.2476, CH= 49261.4920
Training epoch 894, recon_loss:0.776626, zinb_loss:0.641509, cluster_loss:0.153740
Clustering   894: ASW= 0.8205, DB= 0.2456, CH= 49730.7893
Training epoch 895, recon_loss:0.776918, zinb_loss:0.641520, cluster_loss:0.153961
Clustering   895: ASW= 0.8198, DB= 0.2476, CH= 49312.8215
Training epoch 896, recon_loss:0.777924, zinb_loss:0.641974, cluster_loss:0.154006
Clustering   896: ASW= 0.8206, DB= 0.2454, CH= 49635.2764
Training epoch 897, recon_loss:0.778024, zinb_loss:0.642160, cluster_loss:0.154118
Clustering   897: ASW= 0.8199, DB= 0.2477, CH= 49419.9058
Training epoch 898, recon_loss:0.778888, zinb_loss:0.642606, cluster_loss:0.154226
Clustering   898: ASW= 0.8208, DB= 0.2453, CH= 49470.1499
Training epoch 899, recon_loss:0.777643, zinb_loss:0.642440, cluster_loss:0.154074
Clustering   899: ASW= 0.8201, DB= 0.2476, CH= 49560.5846
Training epoch 900, recon_loss:0.778005, zinb_loss:0.642648, cluster_loss:0.154119
Clustering   900: ASW= 0.8209, DB= 0.2450, CH= 49384.7983
Training epoch 901, recon_loss:0.776661, zinb_loss:0.642404, cluster_loss:0.153874
Clustering   901: ASW= 0.8200, DB= 0.2474, CH= 49649.3758
Training epoch 902, recon_loss:0.777056, zinb_loss:0.642510, cluster_loss:0.154074
Clustering   902: ASW= 0.8208, DB= 0.2450, CH= 49246.1665
Training epoch 903, recon_loss:0.776133, zinb_loss:0.642395, cluster_loss:0.153687
Clustering   903: ASW= 0.8202, DB= 0.2473, CH= 49827.8885
Training epoch 904, recon_loss:0.776688, zinb_loss:0.642479, cluster_loss:0.154041
Clustering   904: ASW= 0.8209, DB= 0.2449, CH= 49214.7281
Training epoch 905, recon_loss:0.776016, zinb_loss:0.642453, cluster_loss:0.153575
Clustering   905: ASW= 0.8202, DB= 0.2473, CH= 49962.7548
Training epoch 906, recon_loss:0.776620, zinb_loss:0.642479, cluster_loss:0.154053
Clustering   906: ASW= 0.8208, DB= 0.2448, CH= 49136.2638
Training epoch 907, recon_loss:0.775994, zinb_loss:0.642473, cluster_loss:0.153460
Clustering   907: ASW= 0.8203, DB= 0.2471, CH= 50121.1496
Training epoch 908, recon_loss:0.776681, zinb_loss:0.642443, cluster_loss:0.154127
Clustering   908: ASW= 0.8206, DB= 0.2447, CH= 48995.7732
Training epoch 909, recon_loss:0.776141, zinb_loss:0.642524, cluster_loss:0.153410
Clustering   909: ASW= 0.8204, DB= 0.2471, CH= 50248.5051
Training epoch 910, recon_loss:0.776631, zinb_loss:0.642364, cluster_loss:0.154162
Clustering   910: ASW= 0.8208, DB= 0.2447, CH= 49014.4653
Training epoch 911, recon_loss:0.775948, zinb_loss:0.642436, cluster_loss:0.153302
Clustering   911: ASW= 0.8204, DB= 0.2470, CH= 50340.6364
Training epoch 912, recon_loss:0.776161, zinb_loss:0.642151, cluster_loss:0.154118
Clustering   912: ASW= 0.8210, DB= 0.2447, CH= 49106.5318
Training epoch 913, recon_loss:0.775764, zinb_loss:0.642362, cluster_loss:0.153293
Clustering   913: ASW= 0.8203, DB= 0.2465, CH= 50341.7872
Training epoch 914, recon_loss:0.776203, zinb_loss:0.641954, cluster_loss:0.154253
Clustering   914: ASW= 0.8210, DB= 0.2453, CH= 49148.2019
Training epoch 915, recon_loss:0.776044, zinb_loss:0.642134, cluster_loss:0.153481
Clustering   915: ASW= 0.8202, DB= 0.2461, CH= 50242.1804
Training epoch 916, recon_loss:0.776715, zinb_loss:0.641684, cluster_loss:0.154564
Clustering   916: ASW= 0.8207, DB= 0.2460, CH= 49102.8026
Training epoch 917, recon_loss:0.776289, zinb_loss:0.641765, cluster_loss:0.153764
Clustering   917: ASW= 0.8199, DB= 0.2461, CH= 50081.1733
Training epoch 918, recon_loss:0.776485, zinb_loss:0.641361, cluster_loss:0.154756
Clustering   918: ASW= 0.8206, DB= 0.2460, CH= 49043.0344
Training epoch 919, recon_loss:0.776031, zinb_loss:0.641425, cluster_loss:0.153844
Clustering   919: ASW= 0.8200, DB= 0.2456, CH= 49940.2353
Training epoch 920, recon_loss:0.776033, zinb_loss:0.641055, cluster_loss:0.154786
Clustering   920: ASW= 0.8205, DB= 0.2466, CH= 49015.7086
Training epoch 921, recon_loss:0.776022, zinb_loss:0.641189, cluster_loss:0.153862
Clustering   921: ASW= 0.8202, DB= 0.2454, CH= 49871.7022
Training epoch 922, recon_loss:0.775995, zinb_loss:0.640775, cluster_loss:0.154793
Clustering   922: ASW= 0.8204, DB= 0.2470, CH= 49013.4202
Training epoch 923, recon_loss:0.776050, zinb_loss:0.640999, cluster_loss:0.153827
Clustering   923: ASW= 0.8203, DB= 0.2452, CH= 49775.1593
Training epoch 924, recon_loss:0.775631, zinb_loss:0.640561, cluster_loss:0.154574
Clustering   924: ASW= 0.8206, DB= 0.2469, CH= 49208.0691
Training epoch 925, recon_loss:0.775892, zinb_loss:0.640883, cluster_loss:0.153674
Clustering   925: ASW= 0.8206, DB= 0.2445, CH= 49792.9730
Training epoch 926, recon_loss:0.775377, zinb_loss:0.640449, cluster_loss:0.154408
Clustering   926: ASW= 0.8206, DB= 0.2471, CH= 49378.4618
Training epoch 927, recon_loss:0.775965, zinb_loss:0.640841, cluster_loss:0.153659
Clustering   927: ASW= 0.8206, DB= 0.2441, CH= 49754.3804
Training epoch 928, recon_loss:0.775498, zinb_loss:0.640606, cluster_loss:0.154298
Clustering   928: ASW= 0.8210, DB= 0.2469, CH= 49661.6168
Training epoch 929, recon_loss:0.776103, zinb_loss:0.640991, cluster_loss:0.153740
Clustering   929: ASW= 0.8206, DB= 0.2443, CH= 49637.9140
Training epoch 930, recon_loss:0.775426, zinb_loss:0.640912, cluster_loss:0.154189
Clustering   930: ASW= 0.8212, DB= 0.2463, CH= 49907.6346
Training epoch 931, recon_loss:0.775953, zinb_loss:0.641246, cluster_loss:0.153845
Clustering   931: ASW= 0.8204, DB= 0.2444, CH= 49528.2611
Training epoch 932, recon_loss:0.775294, zinb_loss:0.641312, cluster_loss:0.154089
Clustering   932: ASW= 0.8214, DB= 0.2455, CH= 50078.0948
Training epoch 933, recon_loss:0.775774, zinb_loss:0.641584, cluster_loss:0.153893
Clustering   933: ASW= 0.8204, DB= 0.2447, CH= 49575.5879
Training epoch 934, recon_loss:0.775276, zinb_loss:0.641691, cluster_loss:0.154007
Clustering   934: ASW= 0.8217, DB= 0.2447, CH= 50171.4320
Training epoch 935, recon_loss:0.775643, zinb_loss:0.641841, cluster_loss:0.153967
Clustering   935: ASW= 0.8203, DB= 0.2449, CH= 49606.7985
Training epoch 936, recon_loss:0.775418, zinb_loss:0.641946, cluster_loss:0.153999
Clustering   936: ASW= 0.8219, DB= 0.2448, CH= 50261.8751
Training epoch 937, recon_loss:0.775770, zinb_loss:0.641974, cluster_loss:0.154115
Clustering   937: ASW= 0.8203, DB= 0.2453, CH= 49602.3933
Training epoch 938, recon_loss:0.775727, zinb_loss:0.642072, cluster_loss:0.154040
Clustering   938: ASW= 0.8219, DB= 0.2440, CH= 50241.8509
Training epoch 939, recon_loss:0.776015, zinb_loss:0.641972, cluster_loss:0.154267
Clustering   939: ASW= 0.8202, DB= 0.2454, CH= 49552.2925
Training epoch 940, recon_loss:0.776008, zinb_loss:0.642108, cluster_loss:0.154051
Clustering   940: ASW= 0.8220, DB= 0.2439, CH= 50264.3502
Training epoch 941, recon_loss:0.776126, zinb_loss:0.641864, cluster_loss:0.154313
Clustering   941: ASW= 0.8202, DB= 0.2459, CH= 49507.5603
Training epoch 942, recon_loss:0.776039, zinb_loss:0.642041, cluster_loss:0.153949
Clustering   942: ASW= 0.8221, DB= 0.2437, CH= 50320.6255
Training epoch 943, recon_loss:0.775981, zinb_loss:0.641658, cluster_loss:0.154253
Clustering   943: ASW= 0.8203, DB= 0.2459, CH= 49477.8211
Training epoch 944, recon_loss:0.775839, zinb_loss:0.641838, cluster_loss:0.153782
Clustering   944: ASW= 0.8222, DB= 0.2435, CH= 50390.3066
Training epoch 945, recon_loss:0.775697, zinb_loss:0.641373, cluster_loss:0.154116
Clustering   945: ASW= 0.8204, DB= 0.2462, CH= 49517.5703
Training epoch 946, recon_loss:0.775706, zinb_loss:0.641617, cluster_loss:0.153643
Clustering   946: ASW= 0.8223, DB= 0.2434, CH= 50452.5558
Training epoch 947, recon_loss:0.775548, zinb_loss:0.641124, cluster_loss:0.153979
Clustering   947: ASW= 0.8206, DB= 0.2460, CH= 49581.5547
Training epoch 948, recon_loss:0.775715, zinb_loss:0.641411, cluster_loss:0.153572
Clustering   948: ASW= 0.8223, DB= 0.2436, CH= 50440.3620
Training epoch 949, recon_loss:0.775554, zinb_loss:0.640954, cluster_loss:0.153866
Clustering   949: ASW= 0.8208, DB= 0.2456, CH= 49667.0371
Training epoch 950, recon_loss:0.775860, zinb_loss:0.641265, cluster_loss:0.153520
Clustering   950: ASW= 0.8222, DB= 0.2437, CH= 50460.8942
Training epoch 951, recon_loss:0.775514, zinb_loss:0.640827, cluster_loss:0.153793
Clustering   951: ASW= 0.8209, DB= 0.2460, CH= 49678.3158
Training epoch 952, recon_loss:0.776003, zinb_loss:0.641251, cluster_loss:0.153448
Clustering   952: ASW= 0.8223, DB= 0.2439, CH= 50473.1184
Training epoch 953, recon_loss:0.775709, zinb_loss:0.640835, cluster_loss:0.153730
Clustering   953: ASW= 0.8212, DB= 0.2455, CH= 49782.0559
Training epoch 954, recon_loss:0.776081, zinb_loss:0.641191, cluster_loss:0.153390
Clustering   954: ASW= 0.8223, DB= 0.2437, CH= 50508.5557
Training epoch 955, recon_loss:0.775705, zinb_loss:0.640885, cluster_loss:0.153591
Clustering   955: ASW= 0.8216, DB= 0.2455, CH= 49942.8353
Training epoch 956, recon_loss:0.775884, zinb_loss:0.641126, cluster_loss:0.153374
Clustering   956: ASW= 0.8220, DB= 0.2438, CH= 50456.2604
Training epoch 957, recon_loss:0.775367, zinb_loss:0.640870, cluster_loss:0.153429
Clustering   957: ASW= 0.8218, DB= 0.2453, CH= 50021.5257
Training epoch 958, recon_loss:0.775568, zinb_loss:0.641136, cluster_loss:0.153301
Clustering   958: ASW= 0.8220, DB= 0.2435, CH= 50543.7448
Training epoch 959, recon_loss:0.775313, zinb_loss:0.641017, cluster_loss:0.153332
Clustering   959: ASW= 0.8220, DB= 0.2445, CH= 50103.0253
Training epoch 960, recon_loss:0.775505, zinb_loss:0.641212, cluster_loss:0.153419
Clustering   960: ASW= 0.8216, DB= 0.2441, CH= 50358.6860
Training epoch 961, recon_loss:0.775427, zinb_loss:0.641155, cluster_loss:0.153333
Clustering   961: ASW= 0.8218, DB= 0.2440, CH= 50036.3343
Training epoch 962, recon_loss:0.775604, zinb_loss:0.641232, cluster_loss:0.153506
Clustering   962: ASW= 0.8214, DB= 0.2443, CH= 50348.6532
Training epoch 963, recon_loss:0.776001, zinb_loss:0.641393, cluster_loss:0.153394
Clustering   963: ASW= 0.8218, DB= 0.2436, CH= 50133.4659
Training epoch 964, recon_loss:0.775528, zinb_loss:0.641249, cluster_loss:0.153777
Clustering   964: ASW= 0.8203, DB= 0.2454, CH= 49707.4270
Training epoch 965, recon_loss:0.775644, zinb_loss:0.641277, cluster_loss:0.153624
Clustering   965: ASW= 0.8206, DB= 0.2450, CH= 49505.6651
Training epoch 966, recon_loss:0.775920, zinb_loss:0.641359, cluster_loss:0.154351
Clustering   966: ASW= 0.8197, DB= 0.2457, CH= 49611.9980
Training epoch 967, recon_loss:0.775865, zinb_loss:0.641455, cluster_loss:0.153637
Clustering   967: ASW= 0.8209, DB= 0.2441, CH= 49806.9834
Training epoch 968, recon_loss:0.775242, zinb_loss:0.641323, cluster_loss:0.154025
Clustering   968: ASW= 0.8200, DB= 0.2452, CH= 49682.6118
Training epoch 969, recon_loss:0.775132, zinb_loss:0.641191, cluster_loss:0.153353
Clustering   969: ASW= 0.8210, DB= 0.2440, CH= 49892.1741
Training epoch 970, recon_loss:0.774995, zinb_loss:0.641213, cluster_loss:0.153712
Clustering   970: ASW= 0.8202, DB= 0.2448, CH= 49904.3556
Training epoch 971, recon_loss:0.774953, zinb_loss:0.640983, cluster_loss:0.153206
Clustering   971: ASW= 0.8211, DB= 0.2442, CH= 49945.0347
Training epoch 972, recon_loss:0.775123, zinb_loss:0.641131, cluster_loss:0.153545
Clustering   972: ASW= 0.8204, DB= 0.2439, CH= 50083.6425
Training epoch 973, recon_loss:0.775388, zinb_loss:0.640825, cluster_loss:0.153212
Clustering   973: ASW= 0.8211, DB= 0.2446, CH= 50003.1611
Training epoch 974, recon_loss:0.775489, zinb_loss:0.641091, cluster_loss:0.153475
Clustering   974: ASW= 0.8207, DB= 0.2439, CH= 50221.4849
Training epoch 975, recon_loss:0.775899, zinb_loss:0.640686, cluster_loss:0.153341
Clustering   975: ASW= 0.8210, DB= 0.2448, CH= 49975.2323
Training epoch 976, recon_loss:0.775533, zinb_loss:0.641061, cluster_loss:0.153438
Clustering   976: ASW= 0.8210, DB= 0.2435, CH= 50348.5970
Training epoch 977, recon_loss:0.775812, zinb_loss:0.640572, cluster_loss:0.153414
Clustering   977: ASW= 0.8210, DB= 0.2450, CH= 50029.6433
Training epoch 978, recon_loss:0.775255, zinb_loss:0.641029, cluster_loss:0.153381
Clustering   978: ASW= 0.8215, DB= 0.2435, CH= 50457.8365
Training epoch 979, recon_loss:0.775421, zinb_loss:0.640511, cluster_loss:0.153397
Clustering   979: ASW= 0.8214, DB= 0.2450, CH= 50177.2513
Training epoch 980, recon_loss:0.774964, zinb_loss:0.641081, cluster_loss:0.153307
Clustering   980: ASW= 0.8220, DB= 0.2429, CH= 50649.4802
Training epoch 981, recon_loss:0.775087, zinb_loss:0.640552, cluster_loss:0.153419
Clustering   981: ASW= 0.8215, DB= 0.2454, CH= 50247.2643
Training epoch 982, recon_loss:0.774816, zinb_loss:0.641254, cluster_loss:0.153259
Clustering   982: ASW= 0.8225, DB= 0.2425, CH= 50773.6733
Training epoch 983, recon_loss:0.774959, zinb_loss:0.640777, cluster_loss:0.153436
Clustering   983: ASW= 0.8216, DB= 0.2455, CH= 50279.7720
Training epoch 984, recon_loss:0.774858, zinb_loss:0.641565, cluster_loss:0.153215
Clustering   984: ASW= 0.8228, DB= 0.2420, CH= 50878.0192
Training epoch 985, recon_loss:0.774992, zinb_loss:0.641189, cluster_loss:0.153491
Clustering   985: ASW= 0.8216, DB= 0.2453, CH= 50272.7620
Training epoch 986, recon_loss:0.775061, zinb_loss:0.641959, cluster_loss:0.153230
Clustering   986: ASW= 0.8231, DB= 0.2419, CH= 50939.6393
Training epoch 987, recon_loss:0.774991, zinb_loss:0.641593, cluster_loss:0.153502
Clustering   987: ASW= 0.8216, DB= 0.2457, CH= 50311.2786
Training epoch 988, recon_loss:0.774966, zinb_loss:0.642084, cluster_loss:0.153216
Clustering   988: ASW= 0.8232, DB= 0.2416, CH= 50958.2240
Training epoch 989, recon_loss:0.774881, zinb_loss:0.641655, cluster_loss:0.153486
Clustering   989: ASW= 0.8214, DB= 0.2454, CH= 50347.6130
Training epoch 990, recon_loss:0.774816, zinb_loss:0.641966, cluster_loss:0.153200
Clustering   990: ASW= 0.8233, DB= 0.2416, CH= 50920.7321
Training epoch 991, recon_loss:0.774580, zinb_loss:0.641527, cluster_loss:0.153281
Clustering   991: ASW= 0.8217, DB= 0.2451, CH= 50522.3623
Training epoch 992, recon_loss:0.774458, zinb_loss:0.641629, cluster_loss:0.153183
Clustering   992: ASW= 0.8231, DB= 0.2417, CH= 50901.0535
Training epoch 993, recon_loss:0.774289, zinb_loss:0.641304, cluster_loss:0.153184
Clustering   993: ASW= 0.8218, DB= 0.2446, CH= 50638.3711
Training epoch 994, recon_loss:0.774186, zinb_loss:0.641344, cluster_loss:0.153230
Clustering   994: ASW= 0.8231, DB= 0.2416, CH= 50873.8986
Training epoch 995, recon_loss:0.774071, zinb_loss:0.641112, cluster_loss:0.153066
Clustering   995: ASW= 0.8220, DB= 0.2438, CH= 50775.4149
Training epoch 996, recon_loss:0.773959, zinb_loss:0.641106, cluster_loss:0.153265
Clustering   996: ASW= 0.8232, DB= 0.2424, CH= 50900.3564
Training epoch 997, recon_loss:0.774089, zinb_loss:0.641002, cluster_loss:0.153042
Clustering   997: ASW= 0.8221, DB= 0.2431, CH= 50854.4477
Training epoch 998, recon_loss:0.774073, zinb_loss:0.640900, cluster_loss:0.153453
Clustering   998: ASW= 0.8231, DB= 0.2430, CH= 50836.5761
Training epoch 999, recon_loss:0.774590, zinb_loss:0.640967, cluster_loss:0.153166
Clustering   999: ASW= 0.8222, DB= 0.2429, CH= 50888.1350
Training epoch 1000, recon_loss:0.774464, zinb_loss:0.640694, cluster_loss:0.153752
Clustering   1000: ASW= 0.8229, DB= 0.2437, CH= 50672.6236
Training epoch 1001, recon_loss:0.775363, zinb_loss:0.640935, cluster_loss:0.153360
Clustering   1001: ASW= 0.8221, DB= 0.2433, CH= 50857.1890
Training epoch 1002, recon_loss:0.774808, zinb_loss:0.640473, cluster_loss:0.153986
Clustering   1002: ASW= 0.8227, DB= 0.2444, CH= 50474.1399
Training epoch 1003, recon_loss:0.775801, zinb_loss:0.640854, cluster_loss:0.153354
Clustering   1003: ASW= 0.8223, DB= 0.2428, CH= 50842.6361
Training epoch 1004, recon_loss:0.774872, zinb_loss:0.640223, cluster_loss:0.154007
Clustering   1004: ASW= 0.8225, DB= 0.2448, CH= 50373.5489
Training epoch 1005, recon_loss:0.775838, zinb_loss:0.640723, cluster_loss:0.153199
Clustering   1005: ASW= 0.8225, DB= 0.2425, CH= 50910.2397
Training epoch 1006, recon_loss:0.774710, zinb_loss:0.640018, cluster_loss:0.153908
Clustering   1006: ASW= 0.8223, DB= 0.2450, CH= 50386.1029
Training epoch 1007, recon_loss:0.775670, zinb_loss:0.640588, cluster_loss:0.153072
Clustering   1007: ASW= 0.8228, DB= 0.2423, CH= 50950.2659
Training epoch 1008, recon_loss:0.774410, zinb_loss:0.639877, cluster_loss:0.153721
Clustering   1008: ASW= 0.8224, DB= 0.2454, CH= 50523.0174
Training epoch 1009, recon_loss:0.775360, zinb_loss:0.640477, cluster_loss:0.152959
Clustering   1009: ASW= 0.8232, DB= 0.2420, CH= 51011.8464
Training epoch 1010, recon_loss:0.774118, zinb_loss:0.639831, cluster_loss:0.153528
Clustering   1010: ASW= 0.8224, DB= 0.2451, CH= 50669.9318
Training epoch 1011, recon_loss:0.775077, zinb_loss:0.640449, cluster_loss:0.152924
Clustering   1011: ASW= 0.8235, DB= 0.2414, CH= 51081.0035
Training epoch 1012, recon_loss:0.774010, zinb_loss:0.639937, cluster_loss:0.153440
Clustering   1012: ASW= 0.8224, DB= 0.2452, CH= 50823.8857
Training epoch 1013, recon_loss:0.775031, zinb_loss:0.640563, cluster_loss:0.153040
Clustering   1013: ASW= 0.8238, DB= 0.2414, CH= 51139.0150
Training epoch 1014, recon_loss:0.774251, zinb_loss:0.640280, cluster_loss:0.153439
Clustering   1014: ASW= 0.8225, DB= 0.2444, CH= 50925.8907
Training epoch 1015, recon_loss:0.775307, zinb_loss:0.640821, cluster_loss:0.153284
Clustering   1015: ASW= 0.8238, DB= 0.2414, CH= 51105.4937
Training epoch 1016, recon_loss:0.774991, zinb_loss:0.640868, cluster_loss:0.153498
Clustering   1016: ASW= 0.8227, DB= 0.2437, CH= 51133.6367
Training epoch 1017, recon_loss:0.775943, zinb_loss:0.641317, cluster_loss:0.153719
Clustering   1017: ASW= 0.8238, DB= 0.2419, CH= 51000.1370
Training epoch 1018, recon_loss:0.775815, zinb_loss:0.641657, cluster_loss:0.153689
Clustering   1018: ASW= 0.8227, DB= 0.2434, CH= 51217.3950
Training epoch 1019, recon_loss:0.776512, zinb_loss:0.641917, cluster_loss:0.154245
Clustering   1019: ASW= 0.8235, DB= 0.2427, CH= 50728.5421
Training epoch 1020, recon_loss:0.776355, zinb_loss:0.642495, cluster_loss:0.153775
Clustering   1020: ASW= 0.8229, DB= 0.2428, CH= 51365.9575
Training epoch 1021, recon_loss:0.776758, zinb_loss:0.642362, cluster_loss:0.154420
Clustering   1021: ASW= 0.8233, DB= 0.2429, CH= 50529.7505
Training epoch 1022, recon_loss:0.776063, zinb_loss:0.642713, cluster_loss:0.153677
Clustering   1022: ASW= 0.8229, DB= 0.2427, CH= 51345.4629
Training epoch 1023, recon_loss:0.776250, zinb_loss:0.642265, cluster_loss:0.154222
Clustering   1023: ASW= 0.8232, DB= 0.2432, CH= 50448.4959
Training epoch 1024, recon_loss:0.775208, zinb_loss:0.642434, cluster_loss:0.153395
Clustering   1024: ASW= 0.8230, DB= 0.2426, CH= 51360.8792
Training epoch 1025, recon_loss:0.775333, zinb_loss:0.641856, cluster_loss:0.153865
Clustering   1025: ASW= 0.8232, DB= 0.2433, CH= 50535.0558
Training epoch 1026, recon_loss:0.774392, zinb_loss:0.642016, cluster_loss:0.153109
Clustering   1026: ASW= 0.8231, DB= 0.2425, CH= 51379.5732
Training epoch 1027, recon_loss:0.774608, zinb_loss:0.641495, cluster_loss:0.153566
Clustering   1027: ASW= 0.8232, DB= 0.2432, CH= 50645.3112
Training epoch 1028, recon_loss:0.773931, zinb_loss:0.641739, cluster_loss:0.152941
Clustering   1028: ASW= 0.8231, DB= 0.2424, CH= 51406.4381
Training epoch 1029, recon_loss:0.774152, zinb_loss:0.641274, cluster_loss:0.153398
Clustering   1029: ASW= 0.8231, DB= 0.2435, CH= 50729.9048
Training epoch 1030, recon_loss:0.773753, zinb_loss:0.641649, cluster_loss:0.152848
Clustering   1030: ASW= 0.8234, DB= 0.2420, CH= 51450.8016
Training epoch 1031, recon_loss:0.774161, zinb_loss:0.641222, cluster_loss:0.153375
Clustering   1031: ASW= 0.8226, DB= 0.2429, CH= 50657.3865
Training epoch 1032, recon_loss:0.773908, zinb_loss:0.641620, cluster_loss:0.152852
Clustering   1032: ASW= 0.8233, DB= 0.2422, CH= 51445.9065
Training epoch 1033, recon_loss:0.774363, zinb_loss:0.641182, cluster_loss:0.153409
Clustering   1033: ASW= 0.8226, DB= 0.2441, CH= 50726.6793
Training epoch 1034, recon_loss:0.774273, zinb_loss:0.641693, cluster_loss:0.152939
Clustering   1034: ASW= 0.8237, DB= 0.2420, CH= 51445.7000
Training epoch 1035, recon_loss:0.774909, zinb_loss:0.641179, cluster_loss:0.153614
Clustering   1035: ASW= 0.8221, DB= 0.2441, CH= 50640.6332
Training epoch 1036, recon_loss:0.774827, zinb_loss:0.641639, cluster_loss:0.153193
Clustering   1036: ASW= 0.8237, DB= 0.2410, CH= 51328.6195
Training epoch 1037, recon_loss:0.775599, zinb_loss:0.641076, cluster_loss:0.153754
Clustering   1037: ASW= 0.8220, DB= 0.2447, CH= 50645.0992
Training epoch 1038, recon_loss:0.775457, zinb_loss:0.641503, cluster_loss:0.153392
Clustering   1038: ASW= 0.8238, DB= 0.2412, CH= 51317.1885
Training epoch 1039, recon_loss:0.776150, zinb_loss:0.640891, cluster_loss:0.153924
Clustering   1039: ASW= 0.8215, DB= 0.2444, CH= 50439.6038
Training epoch 1040, recon_loss:0.775409, zinb_loss:0.641043, cluster_loss:0.153610
Clustering   1040: ASW= 0.8236, DB= 0.2414, CH= 51142.4569
Training epoch 1041, recon_loss:0.776085, zinb_loss:0.640597, cluster_loss:0.153765
Clustering   1041: ASW= 0.8218, DB= 0.2442, CH= 50534.2116
Training epoch 1042, recon_loss:0.775227, zinb_loss:0.640506, cluster_loss:0.153550
Clustering   1042: ASW= 0.8234, DB= 0.2420, CH= 50946.9501
Training epoch 1043, recon_loss:0.775270, zinb_loss:0.640090, cluster_loss:0.153450
Clustering   1043: ASW= 0.8220, DB= 0.2449, CH= 50615.6787
Training epoch 1044, recon_loss:0.775073, zinb_loss:0.640136, cluster_loss:0.153444
Clustering   1044: ASW= 0.8236, DB= 0.2422, CH= 51139.0971
Training epoch 1045, recon_loss:0.775178, zinb_loss:0.640066, cluster_loss:0.153327
Clustering   1045: ASW= 0.8226, DB= 0.2437, CH= 50918.9657
Training epoch 1046, recon_loss:0.775118, zinb_loss:0.639966, cluster_loss:0.153562
Clustering   1046: ASW= 0.8234, DB= 0.2426, CH= 50914.6717
Training epoch 1047, recon_loss:0.775040, zinb_loss:0.640179, cluster_loss:0.153307
Clustering   1047: ASW= 0.8231, DB= 0.2437, CH= 50909.4443
Training epoch 1048, recon_loss:0.774894, zinb_loss:0.640003, cluster_loss:0.153475
Clustering   1048: ASW= 0.8235, DB= 0.2427, CH= 50978.8432
Training epoch 1049, recon_loss:0.775082, zinb_loss:0.640514, cluster_loss:0.153313
Clustering   1049: ASW= 0.8236, DB= 0.2428, CH= 50998.7662
Training epoch 1050, recon_loss:0.774542, zinb_loss:0.640175, cluster_loss:0.153407
Clustering   1050: ASW= 0.8226, DB= 0.2441, CH= 50527.4209
Training epoch 1051, recon_loss:0.774207, zinb_loss:0.640311, cluster_loss:0.153117
Clustering   1051: ASW= 0.8230, DB= 0.2427, CH= 50615.8578
Training epoch 1052, recon_loss:0.774763, zinb_loss:0.640424, cluster_loss:0.153562
Clustering   1052: ASW= 0.8227, DB= 0.2430, CH= 50726.0921
Training epoch 1053, recon_loss:0.774962, zinb_loss:0.640882, cluster_loss:0.153375
Clustering   1053: ASW= 0.8237, DB= 0.2428, CH= 50846.7273
Training epoch 1054, recon_loss:0.774569, zinb_loss:0.640683, cluster_loss:0.153771
Clustering   1054: ASW= 0.8223, DB= 0.2427, CH= 50592.4757
Training epoch 1055, recon_loss:0.774593, zinb_loss:0.640904, cluster_loss:0.153288
Clustering   1055: ASW= 0.8244, DB= 0.2420, CH= 51085.2438
Training epoch 1056, recon_loss:0.774126, zinb_loss:0.640694, cluster_loss:0.153757
Clustering   1056: ASW= 0.8219, DB= 0.2428, CH= 50617.1630
Training epoch 1057, recon_loss:0.774238, zinb_loss:0.640874, cluster_loss:0.153069
Clustering   1057: ASW= 0.8246, DB= 0.2416, CH= 51191.7610
Training epoch 1058, recon_loss:0.773749, zinb_loss:0.640563, cluster_loss:0.153385
Clustering   1058: ASW= 0.8220, DB= 0.2427, CH= 50809.5882
Training epoch 1059, recon_loss:0.773707, zinb_loss:0.640579, cluster_loss:0.152936
Clustering   1059: ASW= 0.8247, DB= 0.2408, CH= 51349.3776
Training epoch 1060, recon_loss:0.773702, zinb_loss:0.640581, cluster_loss:0.153265
Clustering   1060: ASW= 0.8221, DB= 0.2424, CH= 51002.1613
Training epoch 1061, recon_loss:0.773891, zinb_loss:0.640587, cluster_loss:0.152985
Clustering   1061: ASW= 0.8246, DB= 0.2414, CH= 51511.6095
Training epoch 1062, recon_loss:0.774019, zinb_loss:0.640683, cluster_loss:0.153377
Clustering   1062: ASW= 0.8220, DB= 0.2417, CH= 50940.9325
Training epoch 1063, recon_loss:0.774221, zinb_loss:0.640612, cluster_loss:0.153107
Clustering   1063: ASW= 0.8240, DB= 0.2429, CH= 51431.4129
Training epoch 1064, recon_loss:0.774509, zinb_loss:0.640865, cluster_loss:0.153341
Clustering   1064: ASW= 0.8223, DB= 0.2406, CH= 51057.2812
Training epoch 1065, recon_loss:0.774559, zinb_loss:0.640687, cluster_loss:0.153104
Clustering   1065: ASW= 0.8239, DB= 0.2429, CH= 51534.6099
Training epoch 1066, recon_loss:0.774634, zinb_loss:0.640854, cluster_loss:0.153398
Clustering   1066: ASW= 0.8225, DB= 0.2410, CH= 50923.8774
Training epoch 1067, recon_loss:0.774593, zinb_loss:0.640601, cluster_loss:0.153095
Clustering   1067: ASW= 0.8235, DB= 0.2435, CH= 51388.3023
Training epoch 1068, recon_loss:0.774729, zinb_loss:0.640764, cluster_loss:0.153330
Clustering   1068: ASW= 0.8230, DB= 0.2399, CH= 51054.2692
Training epoch 1069, recon_loss:0.774364, zinb_loss:0.640619, cluster_loss:0.152938
Clustering   1069: ASW= 0.8239, DB= 0.2430, CH= 51659.7362
Training epoch 1070, recon_loss:0.774401, zinb_loss:0.640605, cluster_loss:0.153222
Clustering   1070: ASW= 0.8232, DB= 0.2402, CH= 51050.6337
Training epoch 1071, recon_loss:0.774138, zinb_loss:0.640660, cluster_loss:0.152782
Clustering   1071: ASW= 0.8243, DB= 0.2429, CH= 51846.1960
Training epoch 1072, recon_loss:0.774420, zinb_loss:0.640596, cluster_loss:0.153217
Clustering   1072: ASW= 0.8234, DB= 0.2400, CH= 51082.2987
Training epoch 1073, recon_loss:0.774229, zinb_loss:0.640792, cluster_loss:0.152731
Clustering   1073: ASW= 0.8245, DB= 0.2424, CH= 51937.3765
Training epoch 1074, recon_loss:0.774712, zinb_loss:0.640671, cluster_loss:0.153346
Clustering   1074: ASW= 0.8235, DB= 0.2402, CH= 51088.7055
Training epoch 1075, recon_loss:0.774490, zinb_loss:0.640942, cluster_loss:0.152768
Clustering   1075: ASW= 0.8243, DB= 0.2417, CH= 51883.9524
Training epoch 1076, recon_loss:0.774980, zinb_loss:0.640764, cluster_loss:0.153382
Clustering   1076: ASW= 0.8239, DB= 0.2400, CH= 51142.7324
Training epoch 1077, recon_loss:0.774598, zinb_loss:0.640989, cluster_loss:0.152789
Clustering   1077: ASW= 0.8243, DB= 0.2418, CH= 51869.1058
Training epoch 1078, recon_loss:0.774833, zinb_loss:0.640711, cluster_loss:0.153492
Clustering   1078: ASW= 0.8238, DB= 0.2404, CH= 51108.9723
Training epoch 1079, recon_loss:0.774583, zinb_loss:0.640901, cluster_loss:0.152872
Clustering   1079: ASW= 0.8239, DB= 0.2421, CH= 51719.8050
Training epoch 1080, recon_loss:0.774981, zinb_loss:0.640761, cluster_loss:0.153492
Clustering   1080: ASW= 0.8243, DB= 0.2398, CH= 51259.6815
Training epoch 1081, recon_loss:0.774704, zinb_loss:0.640871, cluster_loss:0.152948
Clustering   1081: ASW= 0.8236, DB= 0.2422, CH= 51605.4614
Training epoch 1082, recon_loss:0.774981, zinb_loss:0.640852, cluster_loss:0.153420
Clustering   1082: ASW= 0.8250, DB= 0.2394, CH= 51509.9498
Training epoch 1083, recon_loss:0.774794, zinb_loss:0.640819, cluster_loss:0.153038
Clustering   1083: ASW= 0.8233, DB= 0.2424, CH= 51507.7788
Training epoch 1084, recon_loss:0.775162, zinb_loss:0.640915, cluster_loss:0.153370
Clustering   1084: ASW= 0.8253, DB= 0.2391, CH= 51659.6416
Training epoch 1085, recon_loss:0.775069, zinb_loss:0.640713, cluster_loss:0.153158
Clustering   1085: ASW= 0.8231, DB= 0.2425, CH= 51503.0449
Training epoch 1086, recon_loss:0.775363, zinb_loss:0.640967, cluster_loss:0.153366
Clustering   1086: ASW= 0.8256, DB= 0.2386, CH= 51760.6702
Training epoch 1087, recon_loss:0.775365, zinb_loss:0.640588, cluster_loss:0.153284
Clustering   1087: ASW= 0.8228, DB= 0.2431, CH= 51419.6931
Training epoch 1088, recon_loss:0.775667, zinb_loss:0.640988, cluster_loss:0.153335
Clustering   1088: ASW= 0.8257, DB= 0.2390, CH= 51803.2571
Training epoch 1089, recon_loss:0.775316, zinb_loss:0.640372, cluster_loss:0.153329
Clustering   1089: ASW= 0.8227, DB= 0.2437, CH= 51351.8570
Training epoch 1090, recon_loss:0.775607, zinb_loss:0.640937, cluster_loss:0.153221
Clustering   1090: ASW= 0.8259, DB= 0.2383, CH= 51901.4069
Training epoch 1091, recon_loss:0.774640, zinb_loss:0.640090, cluster_loss:0.153346
Clustering   1091: ASW= 0.8224, DB= 0.2442, CH= 51165.4304
Training epoch 1092, recon_loss:0.775006, zinb_loss:0.640767, cluster_loss:0.153085
Clustering   1092: ASW= 0.8257, DB= 0.2388, CH= 51866.0391
Training epoch 1093, recon_loss:0.774432, zinb_loss:0.639868, cluster_loss:0.153382
Clustering   1093: ASW= 0.8223, DB= 0.2446, CH= 51167.3338
Training epoch 1094, recon_loss:0.774701, zinb_loss:0.640543, cluster_loss:0.152940
Clustering   1094: ASW= 0.8260, DB= 0.2385, CH= 52017.7733
Training epoch 1095, recon_loss:0.773701, zinb_loss:0.639661, cluster_loss:0.153250
Clustering   1095: ASW= 0.8223, DB= 0.2442, CH= 51244.8684
Training epoch 1096, recon_loss:0.774248, zinb_loss:0.640361, cluster_loss:0.152779
Clustering   1096: ASW= 0.8262, DB= 0.2385, CH= 52104.3727
Training epoch 1097, recon_loss:0.773344, zinb_loss:0.639556, cluster_loss:0.153161
Clustering   1097: ASW= 0.8227, DB= 0.2436, CH= 51361.3292
Training epoch 1098, recon_loss:0.774044, zinb_loss:0.640206, cluster_loss:0.152743
Clustering   1098: ASW= 0.8262, DB= 0.2386, CH= 52137.9762
Training epoch 1099, recon_loss:0.773376, zinb_loss:0.639533, cluster_loss:0.153263
Clustering   1099: ASW= 0.8227, DB= 0.2437, CH= 51428.4399
Training epoch 1100, recon_loss:0.774526, zinb_loss:0.640167, cluster_loss:0.152879
Clustering   1100: ASW= 0.8261, DB= 0.2388, CH= 52086.6075
Training epoch 1101, recon_loss:0.773812, zinb_loss:0.639569, cluster_loss:0.153430
Clustering   1101: ASW= 0.8227, DB= 0.2439, CH= 51406.2934
Training epoch 1102, recon_loss:0.775028, zinb_loss:0.640084, cluster_loss:0.152991
Clustering   1102: ASW= 0.8259, DB= 0.2381, CH= 51996.2657
Training epoch 1103, recon_loss:0.774034, zinb_loss:0.639585, cluster_loss:0.153513
Clustering   1103: ASW= 0.8227, DB= 0.2436, CH= 51429.1156
Training epoch 1104, recon_loss:0.775141, zinb_loss:0.640104, cluster_loss:0.152937
Clustering   1104: ASW= 0.8260, DB= 0.2381, CH= 52029.6968
Training epoch 1105, recon_loss:0.774218, zinb_loss:0.639716, cluster_loss:0.153393
Clustering   1105: ASW= 0.8231, DB= 0.2427, CH= 51449.5722
Training epoch 1106, recon_loss:0.775279, zinb_loss:0.640196, cluster_loss:0.152881
Clustering   1106: ASW= 0.8257, DB= 0.2385, CH= 52018.8848
Training epoch 1107, recon_loss:0.774670, zinb_loss:0.639990, cluster_loss:0.153325
Clustering   1107: ASW= 0.8236, DB= 0.2425, CH= 51643.5129
Training epoch 1108, recon_loss:0.775963, zinb_loss:0.640750, cluster_loss:0.152927
Clustering   1108: ASW= 0.8258, DB= 0.2386, CH= 52141.6058
Training epoch 1109, recon_loss:0.775591, zinb_loss:0.640705, cluster_loss:0.153502
Clustering   1109: ASW= 0.8236, DB= 0.2421, CH= 51470.9866
Training epoch 1110, recon_loss:0.776680, zinb_loss:0.641447, cluster_loss:0.153176
Clustering   1110: ASW= 0.8255, DB= 0.2391, CH= 52054.1761
Training epoch 1111, recon_loss:0.776127, zinb_loss:0.641302, cluster_loss:0.153557
Clustering   1111: ASW= 0.8240, DB= 0.2415, CH= 51653.9585
Training epoch 1112, recon_loss:0.776176, zinb_loss:0.641567, cluster_loss:0.153269
Clustering   1112: ASW= 0.8253, DB= 0.2394, CH= 52059.3186
Training epoch 1113, recon_loss:0.775525, zinb_loss:0.641375, cluster_loss:0.153512
Clustering   1113: ASW= 0.8240, DB= 0.2417, CH= 51611.5281
Training epoch 1114, recon_loss:0.775458, zinb_loss:0.641543, cluster_loss:0.153236
Clustering   1114: ASW= 0.8256, DB= 0.2394, CH= 52091.8983
Training epoch 1115, recon_loss:0.775129, zinb_loss:0.641331, cluster_loss:0.153353
Clustering   1115: ASW= 0.8242, DB= 0.2406, CH= 51698.4322
Training epoch 1116, recon_loss:0.774855, zinb_loss:0.641166, cluster_loss:0.153240
Clustering   1116: ASW= 0.8254, DB= 0.2398, CH= 52120.3927
Training epoch 1117, recon_loss:0.775041, zinb_loss:0.641037, cluster_loss:0.153251
Clustering   1117: ASW= 0.8242, DB= 0.2403, CH= 51823.8278
Training epoch 1118, recon_loss:0.774369, zinb_loss:0.640735, cluster_loss:0.153305
Clustering   1118: ASW= 0.8253, DB= 0.2402, CH= 52125.7374
Training epoch 1119, recon_loss:0.774744, zinb_loss:0.640754, cluster_loss:0.153174
Clustering   1119: ASW= 0.8242, DB= 0.2394, CH= 51918.3676
Training epoch 1120, recon_loss:0.773992, zinb_loss:0.640414, cluster_loss:0.153438
Clustering   1120: ASW= 0.8254, DB= 0.2406, CH= 52084.5068
Training epoch 1121, recon_loss:0.774311, zinb_loss:0.640638, cluster_loss:0.153123
Clustering   1121: ASW= 0.8244, DB= 0.2392, CH= 51884.4798
Training epoch 1122, recon_loss:0.773832, zinb_loss:0.640374, cluster_loss:0.153533
Clustering   1122: ASW= 0.8250, DB= 0.2414, CH= 52085.3913
Training epoch 1123, recon_loss:0.774137, zinb_loss:0.640543, cluster_loss:0.153118
Clustering   1123: ASW= 0.8242, DB= 0.2389, CH= 51808.9576
Training epoch 1124, recon_loss:0.773502, zinb_loss:0.640161, cluster_loss:0.153528
Clustering   1124: ASW= 0.8249, DB= 0.2416, CH= 52095.1682
Training epoch 1125, recon_loss:0.773787, zinb_loss:0.640369, cluster_loss:0.153102
Clustering   1125: ASW= 0.8240, DB= 0.2388, CH= 51683.2277
Training epoch 1126, recon_loss:0.773275, zinb_loss:0.639947, cluster_loss:0.153599
Clustering   1126: ASW= 0.8247, DB= 0.2421, CH= 52004.1862
Training epoch 1127, recon_loss:0.773484, zinb_loss:0.640274, cluster_loss:0.153079
Clustering   1127: ASW= 0.8242, DB= 0.2387, CH= 51574.9759
Training epoch 1128, recon_loss:0.773219, zinb_loss:0.639899, cluster_loss:0.153571
Clustering   1128: ASW= 0.8243, DB= 0.2425, CH= 52028.4084
Training epoch 1129, recon_loss:0.773344, zinb_loss:0.640147, cluster_loss:0.153046
Clustering   1129: ASW= 0.8242, DB= 0.2386, CH= 51502.4272
Training epoch 1130, recon_loss:0.773360, zinb_loss:0.639836, cluster_loss:0.153498
Clustering   1130: ASW= 0.8244, DB= 0.2426, CH= 52084.3247
Training epoch 1131, recon_loss:0.773414, zinb_loss:0.640045, cluster_loss:0.153024
Clustering   1131: ASW= 0.8243, DB= 0.2387, CH= 51423.7873
Training epoch 1132, recon_loss:0.773593, zinb_loss:0.639898, cluster_loss:0.153372
Clustering   1132: ASW= 0.8245, DB= 0.2423, CH= 52180.8246
Training epoch 1133, recon_loss:0.773553, zinb_loss:0.640044, cluster_loss:0.153000
Clustering   1133: ASW= 0.8244, DB= 0.2390, CH= 51377.4795
Training epoch 1134, recon_loss:0.773899, zinb_loss:0.640093, cluster_loss:0.153252
Clustering   1134: ASW= 0.8246, DB= 0.2419, CH= 52253.0278
Training epoch 1135, recon_loss:0.773864, zinb_loss:0.640183, cluster_loss:0.152996
Clustering   1135: ASW= 0.8245, DB= 0.2399, CH= 51392.7580
Training epoch 1136, recon_loss:0.774363, zinb_loss:0.640392, cluster_loss:0.153210
Clustering   1136: ASW= 0.8245, DB= 0.2411, CH= 52216.9799
Training epoch 1137, recon_loss:0.774300, zinb_loss:0.640426, cluster_loss:0.153007
Clustering   1137: ASW= 0.8246, DB= 0.2404, CH= 51458.0421
Training epoch 1138, recon_loss:0.774738, zinb_loss:0.640647, cluster_loss:0.153197
Clustering   1138: ASW= 0.8244, DB= 0.2407, CH= 52109.0542
Training epoch 1139, recon_loss:0.774380, zinb_loss:0.640560, cluster_loss:0.152934
Clustering   1139: ASW= 0.8247, DB= 0.2405, CH= 51568.8514
Training epoch 1140, recon_loss:0.774525, zinb_loss:0.640571, cluster_loss:0.153064
Clustering   1140: ASW= 0.8242, DB= 0.2401, CH= 52082.4063
Training epoch 1141, recon_loss:0.774184, zinb_loss:0.640517, cluster_loss:0.152812
Clustering   1141: ASW= 0.8249, DB= 0.2405, CH= 51760.1324
Training epoch 1142, recon_loss:0.774208, zinb_loss:0.640438, cluster_loss:0.152979
Clustering   1142: ASW= 0.8241, DB= 0.2401, CH= 51950.2610
Training epoch 1143, recon_loss:0.773986, zinb_loss:0.640333, cluster_loss:0.152676
Clustering   1143: ASW= 0.8250, DB= 0.2396, CH= 51850.7547
Training epoch 1144, recon_loss:0.774106, zinb_loss:0.640246, cluster_loss:0.152929
Clustering   1144: ASW= 0.8241, DB= 0.2397, CH= 52004.6299
Training epoch 1145, recon_loss:0.773952, zinb_loss:0.640201, cluster_loss:0.152657
Clustering   1145: ASW= 0.8252, DB= 0.2389, CH= 52035.3136
Training epoch 1146, recon_loss:0.774066, zinb_loss:0.640100, cluster_loss:0.152965
Clustering   1146: ASW= 0.8240, DB= 0.2400, CH= 51909.4906
Training epoch 1147, recon_loss:0.774043, zinb_loss:0.640134, cluster_loss:0.152655
Clustering   1147: ASW= 0.8255, DB= 0.2389, CH= 52294.2629
Training epoch 1148, recon_loss:0.774168, zinb_loss:0.640008, cluster_loss:0.153148
Clustering   1148: ASW= 0.8239, DB= 0.2396, CH= 51718.4139
Training epoch 1149, recon_loss:0.773959, zinb_loss:0.640101, cluster_loss:0.152732
Clustering   1149: ASW= 0.8256, DB= 0.2392, CH= 52487.7063
Training epoch 1150, recon_loss:0.774141, zinb_loss:0.639915, cluster_loss:0.153341
Clustering   1150: ASW= 0.8238, DB= 0.2397, CH= 51595.1088
Training epoch 1151, recon_loss:0.773750, zinb_loss:0.640059, cluster_loss:0.152834
Clustering   1151: ASW= 0.8257, DB= 0.2399, CH= 52606.6785
Training epoch 1152, recon_loss:0.773956, zinb_loss:0.639880, cluster_loss:0.153417
Clustering   1152: ASW= 0.8241, DB= 0.2394, CH= 51578.1339
Training epoch 1153, recon_loss:0.773477, zinb_loss:0.640064, cluster_loss:0.152847
Clustering   1153: ASW= 0.8259, DB= 0.2403, CH= 52772.0409
Training epoch 1154, recon_loss:0.773696, zinb_loss:0.639894, cluster_loss:0.153479
Clustering   1154: ASW= 0.8243, DB= 0.2390, CH= 51520.3428
Training epoch 1155, recon_loss:0.773269, zinb_loss:0.640124, cluster_loss:0.152838
Clustering   1155: ASW= 0.8260, DB= 0.2404, CH= 52870.6729
Training epoch 1156, recon_loss:0.773541, zinb_loss:0.639966, cluster_loss:0.153552
Clustering   1156: ASW= 0.8244, DB= 0.2389, CH= 51449.2789
Training epoch 1157, recon_loss:0.773215, zinb_loss:0.640260, cluster_loss:0.152786
Clustering   1157: ASW= 0.8261, DB= 0.2405, CH= 53005.3532
Training epoch 1158, recon_loss:0.773522, zinb_loss:0.640055, cluster_loss:0.153602
Clustering   1158: ASW= 0.8245, DB= 0.2390, CH= 51399.6881
Training epoch 1159, recon_loss:0.773254, zinb_loss:0.640402, cluster_loss:0.152654
Clustering   1159: ASW= 0.8263, DB= 0.2401, CH= 53121.8767
Training epoch 1160, recon_loss:0.773560, zinb_loss:0.640101, cluster_loss:0.153592
Clustering   1160: ASW= 0.8247, DB= 0.2388, CH= 51385.4219
Training epoch 1161, recon_loss:0.773378, zinb_loss:0.640503, cluster_loss:0.152484
Clustering   1161: ASW= 0.8264, DB= 0.2401, CH= 53180.5796
Training epoch 1162, recon_loss:0.773661, zinb_loss:0.640116, cluster_loss:0.153474
Clustering   1162: ASW= 0.8250, DB= 0.2387, CH= 51484.4627
Training epoch 1163, recon_loss:0.773558, zinb_loss:0.640579, cluster_loss:0.152345
Clustering   1163: ASW= 0.8263, DB= 0.2398, CH= 53178.2999
Training epoch 1164, recon_loss:0.774011, zinb_loss:0.640125, cluster_loss:0.153435
Clustering   1164: ASW= 0.8251, DB= 0.2390, CH= 51575.4033
Training epoch 1165, recon_loss:0.773865, zinb_loss:0.640670, cluster_loss:0.152360
Clustering   1165: ASW= 0.8261, DB= 0.2396, CH= 53002.7730
Training epoch 1166, recon_loss:0.774536, zinb_loss:0.640079, cluster_loss:0.153543
Clustering   1166: ASW= 0.8251, DB= 0.2389, CH= 51588.9712
Training epoch 1167, recon_loss:0.774139, zinb_loss:0.640731, cluster_loss:0.152510
Clustering   1167: ASW= 0.8259, DB= 0.2391, CH= 52780.4065
Training epoch 1168, recon_loss:0.774274, zinb_loss:0.639958, cluster_loss:0.153537
Clustering   1168: ASW= 0.8251, DB= 0.2396, CH= 51602.0208
Training epoch 1169, recon_loss:0.773977, zinb_loss:0.640550, cluster_loss:0.152580
Clustering   1169: ASW= 0.8257, DB= 0.2396, CH= 52601.1868
Training epoch 1170, recon_loss:0.773890, zinb_loss:0.639770, cluster_loss:0.153393
Clustering   1170: ASW= 0.8251, DB= 0.2396, CH= 51761.1263
Training epoch 1171, recon_loss:0.773642, zinb_loss:0.640298, cluster_loss:0.152523
Clustering   1171: ASW= 0.8256, DB= 0.2389, CH= 52577.2820
Training epoch 1172, recon_loss:0.773540, zinb_loss:0.639665, cluster_loss:0.153175
Clustering   1172: ASW= 0.8254, DB= 0.2397, CH= 51933.4751
Training epoch 1173, recon_loss:0.773283, zinb_loss:0.640143, cluster_loss:0.152420
Clustering   1173: ASW= 0.8257, DB= 0.2384, CH= 52632.3763
Training epoch 1174, recon_loss:0.773275, zinb_loss:0.639574, cluster_loss:0.153075
Clustering   1174: ASW= 0.8253, DB= 0.2399, CH= 51936.4637
Training epoch 1175, recon_loss:0.773104, zinb_loss:0.640052, cluster_loss:0.152398
Clustering   1175: ASW= 0.8256, DB= 0.2382, CH= 52619.7743
Training epoch 1176, recon_loss:0.773389, zinb_loss:0.639558, cluster_loss:0.152984
Clustering   1176: ASW= 0.8253, DB= 0.2403, CH= 52035.9552
Training epoch 1177, recon_loss:0.773411, zinb_loss:0.640104, cluster_loss:0.152410
Clustering   1177: ASW= 0.8256, DB= 0.2379, CH= 52658.8310
Training epoch 1178, recon_loss:0.773879, zinb_loss:0.639723, cluster_loss:0.153041
Clustering   1178: ASW= 0.8250, DB= 0.2410, CH= 51940.5408
Training epoch 1179, recon_loss:0.773628, zinb_loss:0.640301, cluster_loss:0.152513
Clustering   1179: ASW= 0.8255, DB= 0.2384, CH= 52565.1082
Training epoch 1180, recon_loss:0.773520, zinb_loss:0.639959, cluster_loss:0.152949
Clustering   1180: ASW= 0.8254, DB= 0.2406, CH= 52130.1792
Training epoch 1181, recon_loss:0.773253, zinb_loss:0.640443, cluster_loss:0.152514
Clustering   1181: ASW= 0.8257, DB= 0.2374, CH= 52714.9296
Training epoch 1182, recon_loss:0.773152, zinb_loss:0.640021, cluster_loss:0.152951
Clustering   1182: ASW= 0.8251, DB= 0.2408, CH= 52030.9084
Training epoch 1183, recon_loss:0.772849, zinb_loss:0.640276, cluster_loss:0.152601
Clustering   1183: ASW= 0.8253, DB= 0.2377, CH= 52599.8909
Training epoch 1184, recon_loss:0.772800, zinb_loss:0.640041, cluster_loss:0.152884
Clustering   1184: ASW= 0.8254, DB= 0.2405, CH= 52247.6021
Training epoch 1185, recon_loss:0.772670, zinb_loss:0.640430, cluster_loss:0.152589
Clustering   1185: ASW= 0.8257, DB= 0.2379, CH= 52674.3102
Training epoch 1186, recon_loss:0.772657, zinb_loss:0.640146, cluster_loss:0.152762
Clustering   1186: ASW= 0.8258, DB= 0.2407, CH= 52360.1836
Training epoch 1187, recon_loss:0.772596, zinb_loss:0.640497, cluster_loss:0.152742
Clustering   1187: ASW= 0.8256, DB= 0.2375, CH= 52806.4751
Training epoch 1188, recon_loss:0.772822, zinb_loss:0.640424, cluster_loss:0.152858
Clustering   1188: ASW= 0.8260, DB= 0.2405, CH= 52340.2728
Training epoch 1189, recon_loss:0.773038, zinb_loss:0.640818, cluster_loss:0.153066
Clustering   1189: ASW= 0.8253, DB= 0.2378, CH= 52832.2911
Training epoch 1190, recon_loss:0.773270, zinb_loss:0.640767, cluster_loss:0.153074
Clustering   1190: ASW= 0.8260, DB= 0.2395, CH= 52142.9966
Training epoch 1191, recon_loss:0.773345, zinb_loss:0.641056, cluster_loss:0.153225
Clustering   1191: ASW= 0.8252, DB= 0.2380, CH= 52942.3564
Training epoch 1192, recon_loss:0.773540, zinb_loss:0.640889, cluster_loss:0.153168
Clustering   1192: ASW= 0.8259, DB= 0.2391, CH= 51871.2018
Training epoch 1193, recon_loss:0.773318, zinb_loss:0.641006, cluster_loss:0.153224
Clustering   1193: ASW= 0.8251, DB= 0.2385, CH= 52875.4583
Training epoch 1194, recon_loss:0.773589, zinb_loss:0.640727, cluster_loss:0.153052
Clustering   1194: ASW= 0.8258, DB= 0.2389, CH= 51822.6577
Training epoch 1195, recon_loss:0.772884, zinb_loss:0.640557, cluster_loss:0.152927
Clustering   1195: ASW= 0.8252, DB= 0.2387, CH= 52918.3441
Training epoch 1196, recon_loss:0.773222, zinb_loss:0.640231, cluster_loss:0.152723
Clustering   1196: ASW= 0.8258, DB= 0.2387, CH= 51940.3220
Training epoch 1197, recon_loss:0.772581, zinb_loss:0.640128, cluster_loss:0.152647
Clustering   1197: ASW= 0.8255, DB= 0.2387, CH= 53020.6417
Training epoch 1198, recon_loss:0.772796, zinb_loss:0.639813, cluster_loss:0.152464
Clustering   1198: ASW= 0.8260, DB= 0.2387, CH= 52148.0125
Training epoch 1199, recon_loss:0.772579, zinb_loss:0.639864, cluster_loss:0.152505
Clustering   1199: ASW= 0.8257, DB= 0.2385, CH= 53060.7496
Training epoch 1200, recon_loss:0.772887, zinb_loss:0.639630, cluster_loss:0.152383
Clustering   1200: ASW= 0.8261, DB= 0.2386, CH= 52342.0570
Training epoch 1201, recon_loss:0.772740, zinb_loss:0.639710, cluster_loss:0.152498
Clustering   1201: ASW= 0.8258, DB= 0.2384, CH= 53054.3929
Training epoch 1202, recon_loss:0.773177, zinb_loss:0.639517, cluster_loss:0.152350
Clustering   1202: ASW= 0.8264, DB= 0.2383, CH= 52525.6678
Training epoch 1203, recon_loss:0.773056, zinb_loss:0.639618, cluster_loss:0.152557
Clustering   1203: ASW= 0.8257, DB= 0.2387, CH= 52997.4996
Training epoch 1204, recon_loss:0.773416, zinb_loss:0.639457, cluster_loss:0.152367
Clustering   1204: ASW= 0.8266, DB= 0.2382, CH= 52673.7909
Training epoch 1205, recon_loss:0.773211, zinb_loss:0.639555, cluster_loss:0.152562
Clustering   1205: ASW= 0.8259, DB= 0.2383, CH= 53015.3574
Training epoch 1206, recon_loss:0.773785, zinb_loss:0.639489, cluster_loss:0.152404
Clustering   1206: ASW= 0.8268, DB= 0.2379, CH= 52876.1055
Training epoch 1207, recon_loss:0.773613, zinb_loss:0.639596, cluster_loss:0.152666
Clustering   1207: ASW= 0.8259, DB= 0.2384, CH= 52886.9848
Training epoch 1208, recon_loss:0.774213, zinb_loss:0.639492, cluster_loss:0.152541
Clustering   1208: ASW= 0.8268, DB= 0.2380, CH= 52925.3192
Training epoch 1209, recon_loss:0.773710, zinb_loss:0.639605, cluster_loss:0.152738
Clustering   1209: ASW= 0.8263, DB= 0.2375, CH= 52946.4231
Training epoch 1210, recon_loss:0.774354, zinb_loss:0.639542, cluster_loss:0.152632
Clustering   1210: ASW= 0.8271, DB= 0.2377, CH= 53189.4076
Training epoch 1211, recon_loss:0.773974, zinb_loss:0.639543, cluster_loss:0.152907
Clustering   1211: ASW= 0.8257, DB= 0.2383, CH= 52588.4641
Training epoch 1212, recon_loss:0.774335, zinb_loss:0.639426, cluster_loss:0.152831
Clustering   1212: ASW= 0.8268, DB= 0.2385, CH= 53142.3723
Training epoch 1213, recon_loss:0.773912, zinb_loss:0.639539, cluster_loss:0.153169
Clustering   1213: ASW= 0.8261, DB= 0.2377, CH= 52659.0462
Training epoch 1214, recon_loss:0.773850, zinb_loss:0.639419, cluster_loss:0.152867
Clustering   1214: ASW= 0.8271, DB= 0.2379, CH= 53315.1462
Training epoch 1215, recon_loss:0.773142, zinb_loss:0.639278, cluster_loss:0.153091
Clustering   1215: ASW= 0.8257, DB= 0.2380, CH= 52534.3408
Training epoch 1216, recon_loss:0.773420, zinb_loss:0.639421, cluster_loss:0.152793
Clustering   1216: ASW= 0.8273, DB= 0.2376, CH= 53459.8552
Training epoch 1217, recon_loss:0.773014, zinb_loss:0.639235, cluster_loss:0.153052
Clustering   1217: ASW= 0.8252, DB= 0.2386, CH= 52374.6546
Training epoch 1218, recon_loss:0.773343, zinb_loss:0.639507, cluster_loss:0.152872
Clustering   1218: ASW= 0.8266, DB= 0.2381, CH= 53149.4360
Training epoch 1219, recon_loss:0.773039, zinb_loss:0.639406, cluster_loss:0.153256
Clustering   1219: ASW= 0.8252, DB= 0.2390, CH= 52374.6408
Training epoch 1220, recon_loss:0.773708, zinb_loss:0.639991, cluster_loss:0.152914
Clustering   1220: ASW= 0.8268, DB= 0.2375, CH= 53144.2294
Training epoch 1221, recon_loss:0.773598, zinb_loss:0.639668, cluster_loss:0.153368
Clustering   1221: ASW= 0.8246, DB= 0.2400, CH= 52233.1000
Training epoch 1222, recon_loss:0.774698, zinb_loss:0.640606, cluster_loss:0.153103
Clustering   1222: ASW= 0.8270, DB= 0.2374, CH= 53012.3100
Training epoch 1223, recon_loss:0.774425, zinb_loss:0.639995, cluster_loss:0.153472
Clustering   1223: ASW= 0.8243, DB= 0.2407, CH= 52064.4050
Training epoch 1224, recon_loss:0.774816, zinb_loss:0.640711, cluster_loss:0.153293
Clustering   1224: ASW= 0.8261, DB= 0.2378, CH= 52477.4685
Training epoch 1225, recon_loss:0.774592, zinb_loss:0.639950, cluster_loss:0.153763
Clustering   1225: ASW= 0.8242, DB= 0.2409, CH= 51952.6897
Training epoch 1226, recon_loss:0.774813, zinb_loss:0.640743, cluster_loss:0.153189
Clustering   1226: ASW= 0.8271, DB= 0.2374, CH= 52623.0317
Training epoch 1227, recon_loss:0.773425, zinb_loss:0.639822, cluster_loss:0.153026
Clustering   1227: ASW= 0.8253, DB= 0.2399, CH= 52455.9489
Training epoch 1228, recon_loss:0.773228, zinb_loss:0.640115, cluster_loss:0.152722
Clustering   1228: ASW= 0.8274, DB= 0.2365, CH= 52887.0687
Training epoch 1229, recon_loss:0.772639, zinb_loss:0.639721, cluster_loss:0.152655
Clustering   1229: ASW= 0.8258, DB= 0.2395, CH= 52896.5378
Training epoch 1230, recon_loss:0.772949, zinb_loss:0.639846, cluster_loss:0.152633
Clustering   1230: ASW= 0.8274, DB= 0.2373, CH= 52772.0216
Training epoch 1231, recon_loss:0.772962, zinb_loss:0.639751, cluster_loss:0.152544
Clustering   1231: ASW= 0.8263, DB= 0.2389, CH= 53189.2710
Training epoch 1232, recon_loss:0.773304, zinb_loss:0.639794, cluster_loss:0.152812
Clustering   1232: ASW= 0.8274, DB= 0.2367, CH= 52749.8823
Training epoch 1233, recon_loss:0.773529, zinb_loss:0.639899, cluster_loss:0.152616
Clustering   1233: ASW= 0.8262, DB= 0.2391, CH= 53288.3904
Training epoch 1234, recon_loss:0.773822, zinb_loss:0.639714, cluster_loss:0.153080
Clustering   1234: ASW= 0.8273, DB= 0.2370, CH= 52651.1027
Training epoch 1235, recon_loss:0.773946, zinb_loss:0.640035, cluster_loss:0.152630
Clustering   1235: ASW= 0.8263, DB= 0.2388, CH= 53336.6790
Training epoch 1236, recon_loss:0.773905, zinb_loss:0.639551, cluster_loss:0.153211
Clustering   1236: ASW= 0.8267, DB= 0.2373, CH= 52404.9179
Training epoch 1237, recon_loss:0.773953, zinb_loss:0.639922, cluster_loss:0.152549
Clustering   1237: ASW= 0.8265, DB= 0.2382, CH= 53397.7540
Training epoch 1238, recon_loss:0.773323, zinb_loss:0.639355, cluster_loss:0.152972
Clustering   1238: ASW= 0.8270, DB= 0.2371, CH= 52532.7435
Training epoch 1239, recon_loss:0.774101, zinb_loss:0.639987, cluster_loss:0.152722
Clustering   1239: ASW= 0.8255, DB= 0.2386, CH= 53064.5111
Training epoch 1240, recon_loss:0.774628, zinb_loss:0.640008, cluster_loss:0.153295
Clustering   1240: ASW= 0.8260, DB= 0.2395, CH= 51811.1712
Training epoch 1241, recon_loss:0.773324, zinb_loss:0.639445, cluster_loss:0.152822
Clustering   1241: ASW= 0.8242, DB= 0.2426, CH= 52168.5521
Training epoch 1242, recon_loss:0.772676, zinb_loss:0.638777, cluster_loss:0.153262
Clustering   1242: ASW= 0.8255, DB= 0.2388, CH= 51957.5249
Training epoch 1243, recon_loss:0.772486, zinb_loss:0.639272, cluster_loss:0.152500
Clustering   1243: ASW= 0.8257, DB= 0.2394, CH= 52653.6044
Training epoch 1244, recon_loss:0.773146, zinb_loss:0.638788, cluster_loss:0.153501
Clustering   1244: ASW= 0.8249, DB= 0.2392, CH= 52034.6760
Training epoch 1245, recon_loss:0.773426, zinb_loss:0.639563, cluster_loss:0.152544
Clustering   1245: ASW= 0.8260, DB= 0.2381, CH= 52526.4345
Training epoch 1246, recon_loss:0.773649, zinb_loss:0.639096, cluster_loss:0.153369
Clustering   1246: ASW= 0.8255, DB= 0.2398, CH= 52351.5216
Training epoch 1247, recon_loss:0.773961, zinb_loss:0.639814, cluster_loss:0.152561
Clustering   1247: ASW= 0.8262, DB= 0.2375, CH= 52407.5617
Training epoch 1248, recon_loss:0.774013, zinb_loss:0.639358, cluster_loss:0.153368
Clustering   1248: ASW= 0.8260, DB= 0.2397, CH= 52689.2571
Training epoch 1249, recon_loss:0.773997, zinb_loss:0.639811, cluster_loss:0.152558
Clustering   1249: ASW= 0.8264, DB= 0.2375, CH= 52461.2553
Training epoch 1250, recon_loss:0.773667, zinb_loss:0.639438, cluster_loss:0.153083
Clustering   1250: ASW= 0.8266, DB= 0.2388, CH= 53076.7576
Training epoch 1251, recon_loss:0.773416, zinb_loss:0.639648, cluster_loss:0.152423
Clustering   1251: ASW= 0.8265, DB= 0.2374, CH= 52582.8023
Training epoch 1252, recon_loss:0.772978, zinb_loss:0.639434, cluster_loss:0.152670
Clustering   1252: ASW= 0.8272, DB= 0.2376, CH= 53417.0460
Training epoch 1253, recon_loss:0.772728, zinb_loss:0.639524, cluster_loss:0.152293
Clustering   1253: ASW= 0.8266, DB= 0.2367, CH= 52727.7179
Training epoch 1254, recon_loss:0.772517, zinb_loss:0.639570, cluster_loss:0.152370
Clustering   1254: ASW= 0.8277, DB= 0.2370, CH= 53702.9134
Training epoch 1255, recon_loss:0.772389, zinb_loss:0.639589, cluster_loss:0.152299
Clustering   1255: ASW= 0.8264, DB= 0.2372, CH= 52805.5919
Training epoch 1256, recon_loss:0.772415, zinb_loss:0.639931, cluster_loss:0.152212
Clustering   1256: ASW= 0.8281, DB= 0.2368, CH= 53937.5637
Training epoch 1257, recon_loss:0.772301, zinb_loss:0.639809, cluster_loss:0.152425
Clustering   1257: ASW= 0.8261, DB= 0.2379, CH= 52791.8541
Training epoch 1258, recon_loss:0.772394, zinb_loss:0.640348, cluster_loss:0.152157
Clustering   1258: ASW= 0.8286, DB= 0.2360, CH= 54090.0269
Training epoch 1259, recon_loss:0.772317, zinb_loss:0.640022, cluster_loss:0.152675
Clustering   1259: ASW= 0.8257, DB= 0.2382, CH= 52719.9984
Training epoch 1260, recon_loss:0.772589, zinb_loss:0.640748, cluster_loss:0.152245
Clustering   1260: ASW= 0.8289, DB= 0.2354, CH= 54110.5618
Training epoch 1261, recon_loss:0.772501, zinb_loss:0.640235, cluster_loss:0.152989
Clustering   1261: ASW= 0.8253, DB= 0.2388, CH= 52503.8430
Training epoch 1262, recon_loss:0.772872, zinb_loss:0.641080, cluster_loss:0.152337
Clustering   1262: ASW= 0.8289, DB= 0.2358, CH= 54088.8497
Training epoch 1263, recon_loss:0.772502, zinb_loss:0.640396, cluster_loss:0.152952
Clustering   1263: ASW= 0.8255, DB= 0.2386, CH= 52562.5212
Training epoch 1264, recon_loss:0.773030, zinb_loss:0.641141, cluster_loss:0.152329
Clustering   1264: ASW= 0.8287, DB= 0.2359, CH= 54056.4323
Training epoch 1265, recon_loss:0.772856, zinb_loss:0.640495, cluster_loss:0.152845
Clustering   1265: ASW= 0.8258, DB= 0.2384, CH= 52725.7372
Training epoch 1266, recon_loss:0.773502, zinb_loss:0.641165, cluster_loss:0.152383
Clustering   1266: ASW= 0.8284, DB= 0.2359, CH= 53995.8184
Training epoch 1267, recon_loss:0.773494, zinb_loss:0.640582, cluster_loss:0.152812
Clustering   1267: ASW= 0.8262, DB= 0.2380, CH= 52915.8851
Training epoch 1268, recon_loss:0.773869, zinb_loss:0.641102, cluster_loss:0.152513
Clustering   1268: ASW= 0.8280, DB= 0.2355, CH= 53882.6223
Training epoch 1269, recon_loss:0.773748, zinb_loss:0.640538, cluster_loss:0.152821
Clustering   1269: ASW= 0.8263, DB= 0.2384, CH= 53082.1690
Training epoch 1270, recon_loss:0.773672, zinb_loss:0.640943, cluster_loss:0.152649
Clustering   1270: ASW= 0.8277, DB= 0.2355, CH= 53744.7216
Training epoch 1271, recon_loss:0.773310, zinb_loss:0.640458, cluster_loss:0.152809
Clustering   1271: ASW= 0.8265, DB= 0.2389, CH= 53222.3117
Training epoch 1272, recon_loss:0.773422, zinb_loss:0.640722, cluster_loss:0.152884
Clustering   1272: ASW= 0.8273, DB= 0.2350, CH= 53528.4201
Training epoch 1273, recon_loss:0.773282, zinb_loss:0.640418, cluster_loss:0.152903
Clustering   1273: ASW= 0.8267, DB= 0.2388, CH= 53301.7142
Training epoch 1274, recon_loss:0.773491, zinb_loss:0.640629, cluster_loss:0.153232
Clustering   1274: ASW= 0.8269, DB= 0.2352, CH= 53184.5450
Training epoch 1275, recon_loss:0.773307, zinb_loss:0.640555, cluster_loss:0.152861
Clustering   1275: ASW= 0.8270, DB= 0.2387, CH= 53387.3448
Training epoch 1276, recon_loss:0.773480, zinb_loss:0.640504, cluster_loss:0.153292
Clustering   1276: ASW= 0.8270, DB= 0.2355, CH= 53058.0262
Training epoch 1277, recon_loss:0.773318, zinb_loss:0.640609, cluster_loss:0.152715
Clustering   1277: ASW= 0.8273, DB= 0.2378, CH= 53474.8746
Training epoch 1278, recon_loss:0.772959, zinb_loss:0.640230, cluster_loss:0.153171
Clustering   1278: ASW= 0.8267, DB= 0.2362, CH= 52878.1257
Training epoch 1279, recon_loss:0.772881, zinb_loss:0.640450, cluster_loss:0.152897
Clustering   1279: ASW= 0.8264, DB= 0.2396, CH= 52774.7447
Training epoch 1280, recon_loss:0.773896, zinb_loss:0.640306, cluster_loss:0.154097
Clustering   1280: ASW= 0.8257, DB= 0.2374, CH= 52421.0435
Training epoch 1281, recon_loss:0.773564, zinb_loss:0.640496, cluster_loss:0.153063
Clustering   1281: ASW= 0.8269, DB= 0.2391, CH= 52717.4841
Training epoch 1282, recon_loss:0.772661, zinb_loss:0.639780, cluster_loss:0.153154
Clustering   1282: ASW= 0.8268, DB= 0.2368, CH= 52809.8158
Training epoch 1283, recon_loss:0.772273, zinb_loss:0.639690, cluster_loss:0.152395
Clustering   1283: ASW= 0.8272, DB= 0.2377, CH= 53055.1454
Training epoch 1284, recon_loss:0.772092, zinb_loss:0.639456, cluster_loss:0.152493
Clustering   1284: ASW= 0.8273, DB= 0.2363, CH= 53371.9518
Training epoch 1285, recon_loss:0.771819, zinb_loss:0.639249, cluster_loss:0.152105
Clustering   1285: ASW= 0.8274, DB= 0.2370, CH= 53229.8145
Training epoch 1286, recon_loss:0.772043, zinb_loss:0.639325, cluster_loss:0.152227
Clustering   1286: ASW= 0.8276, DB= 0.2359, CH= 53696.5370
Training epoch 1287, recon_loss:0.771912, zinb_loss:0.639081, cluster_loss:0.152052
Clustering   1287: ASW= 0.8274, DB= 0.2373, CH= 53339.9386
Training epoch 1288, recon_loss:0.772246, zinb_loss:0.639355, cluster_loss:0.152115
Clustering   1288: ASW= 0.8278, DB= 0.2356, CH= 53926.4121
Training epoch 1289, recon_loss:0.772178, zinb_loss:0.639042, cluster_loss:0.152085
Clustering   1289: ASW= 0.8273, DB= 0.2373, CH= 53364.1451
Training epoch 1290, recon_loss:0.772543, zinb_loss:0.639401, cluster_loss:0.152101
Clustering   1290: ASW= 0.8277, DB= 0.2351, CH= 54006.8839
Training epoch 1291, recon_loss:0.772459, zinb_loss:0.639086, cluster_loss:0.152177
Clustering   1291: ASW= 0.8272, DB= 0.2371, CH= 53350.7648
Training epoch 1292, recon_loss:0.772801, zinb_loss:0.639496, cluster_loss:0.152151
Clustering   1292: ASW= 0.8275, DB= 0.2353, CH= 54019.5404
Training epoch 1293, recon_loss:0.772689, zinb_loss:0.639241, cluster_loss:0.152321
Clustering   1293: ASW= 0.8271, DB= 0.2370, CH= 53315.4273
Training epoch 1294, recon_loss:0.772979, zinb_loss:0.639685, cluster_loss:0.152234
Clustering   1294: ASW= 0.8273, DB= 0.2355, CH= 53972.5431
Training epoch 1295, recon_loss:0.772866, zinb_loss:0.639509, cluster_loss:0.152482
Clustering   1295: ASW= 0.8270, DB= 0.2369, CH= 53299.0114
Training epoch 1296, recon_loss:0.773143, zinb_loss:0.639984, cluster_loss:0.152344
Clustering   1296: ASW= 0.8271, DB= 0.2361, CH= 53848.2824
Training epoch 1297, recon_loss:0.772974, zinb_loss:0.639883, cluster_loss:0.152628
Clustering   1297: ASW= 0.8271, DB= 0.2370, CH= 53315.5827
Training epoch 1298, recon_loss:0.773333, zinb_loss:0.640344, cluster_loss:0.152419
Clustering   1298: ASW= 0.8270, DB= 0.2363, CH= 53787.1338
Training epoch 1299, recon_loss:0.773021, zinb_loss:0.640223, cluster_loss:0.152656
Clustering   1299: ASW= 0.8273, DB= 0.2367, CH= 53401.7473
Training epoch 1300, recon_loss:0.773605, zinb_loss:0.640603, cluster_loss:0.152450
Clustering   1300: ASW= 0.8270, DB= 0.2362, CH= 53769.2998
Training epoch 1301, recon_loss:0.772661, zinb_loss:0.640328, cluster_loss:0.152517
Clustering   1301: ASW= 0.8277, DB= 0.2364, CH= 53576.5167
Training epoch 1302, recon_loss:0.773202, zinb_loss:0.640488, cluster_loss:0.152412
Clustering   1302: ASW= 0.8271, DB= 0.2359, CH= 53795.1628
Training epoch 1303, recon_loss:0.772223, zinb_loss:0.640331, cluster_loss:0.152307
Clustering   1303: ASW= 0.8283, DB= 0.2361, CH= 53832.6853
Training epoch 1304, recon_loss:0.772725, zinb_loss:0.640236, cluster_loss:0.152400
Clustering   1304: ASW= 0.8270, DB= 0.2369, CH= 53773.9855
Training epoch 1305, recon_loss:0.772202, zinb_loss:0.640420, cluster_loss:0.152171
Clustering   1305: ASW= 0.8287, DB= 0.2356, CH= 53990.6917
Training epoch 1306, recon_loss:0.772838, zinb_loss:0.640102, cluster_loss:0.152653
Clustering   1306: ASW= 0.8262, DB= 0.2371, CH= 53502.7436
Training epoch 1307, recon_loss:0.772959, zinb_loss:0.640773, cluster_loss:0.152296
Clustering   1307: ASW= 0.8290, DB= 0.2349, CH= 53907.6272
Training epoch 1308, recon_loss:0.773748, zinb_loss:0.640093, cluster_loss:0.153133
Clustering   1308: ASW= 0.8253, DB= 0.2386, CH= 53067.1000
Training epoch 1309, recon_loss:0.773581, zinb_loss:0.640816, cluster_loss:0.152492
Clustering   1309: ASW= 0.8282, DB= 0.2349, CH= 53563.2506
Training epoch 1310, recon_loss:0.773248, zinb_loss:0.639795, cluster_loss:0.153240
Clustering   1310: ASW= 0.8248, DB= 0.2392, CH= 52722.9944
Training epoch 1311, recon_loss:0.773191, zinb_loss:0.640545, cluster_loss:0.152304
Clustering   1311: ASW= 0.8284, DB= 0.2350, CH= 53737.9445
Training epoch 1312, recon_loss:0.772790, zinb_loss:0.639521, cluster_loss:0.153062
Clustering   1312: ASW= 0.8251, DB= 0.2390, CH= 52739.0572
Training epoch 1313, recon_loss:0.772648, zinb_loss:0.640186, cluster_loss:0.152071
Clustering   1313: ASW= 0.8288, DB= 0.2347, CH= 54016.0657
Training epoch 1314, recon_loss:0.772170, zinb_loss:0.639200, cluster_loss:0.152844
Clustering   1314: ASW= 0.8256, DB= 0.2383, CH= 52916.8695
Training epoch 1315, recon_loss:0.772117, zinb_loss:0.639795, cluster_loss:0.151918
Clustering   1315: ASW= 0.8289, DB= 0.2349, CH= 54147.0361
Training epoch 1316, recon_loss:0.771709, zinb_loss:0.638938, cluster_loss:0.152639
Clustering   1316: ASW= 0.8260, DB= 0.2374, CH= 53151.3073
Training epoch 1317, recon_loss:0.771604, zinb_loss:0.639517, cluster_loss:0.151812
Clustering   1317: ASW= 0.8292, DB= 0.2347, CH= 54357.3798
Training epoch 1318, recon_loss:0.771231, zinb_loss:0.638732, cluster_loss:0.152560
Clustering   1318: ASW= 0.8261, DB= 0.2372, CH= 53226.9599
Training epoch 1319, recon_loss:0.771289, zinb_loss:0.639319, cluster_loss:0.151772
Clustering   1319: ASW= 0.8293, DB= 0.2348, CH= 54439.6854
Training epoch 1320, recon_loss:0.771004, zinb_loss:0.638622, cluster_loss:0.152536
Clustering   1320: ASW= 0.8263, DB= 0.2364, CH= 53291.3935
Training epoch 1321, recon_loss:0.771117, zinb_loss:0.639178, cluster_loss:0.151792
Clustering   1321: ASW= 0.8295, DB= 0.2349, CH= 54602.5150
Training epoch 1322, recon_loss:0.770955, zinb_loss:0.638579, cluster_loss:0.152606
Clustering   1322: ASW= 0.8262, DB= 0.2363, CH= 53163.9338
Training epoch 1323, recon_loss:0.771075, zinb_loss:0.639052, cluster_loss:0.151846
Clustering   1323: ASW= 0.8293, DB= 0.2360, CH= 54509.1654
Training epoch 1324, recon_loss:0.771129, zinb_loss:0.638660, cluster_loss:0.152708
Clustering   1324: ASW= 0.8266, DB= 0.2357, CH= 53344.0206
Training epoch 1325, recon_loss:0.771259, zinb_loss:0.639023, cluster_loss:0.151957
Clustering   1325: ASW= 0.8293, DB= 0.2363, CH= 54741.7416
Training epoch 1326, recon_loss:0.771313, zinb_loss:0.638748, cluster_loss:0.152673
Clustering   1326: ASW= 0.8267, DB= 0.2356, CH= 53140.5080
Training epoch 1327, recon_loss:0.771661, zinb_loss:0.638906, cluster_loss:0.152217
Clustering   1327: ASW= 0.8283, DB= 0.2377, CH= 54396.1820
Training epoch 1328, recon_loss:0.772621, zinb_loss:0.639121, cluster_loss:0.153482
Clustering   1328: ASW= 0.8269, DB= 0.2346, CH= 53108.1177
Training epoch 1329, recon_loss:0.772317, zinb_loss:0.639056, cluster_loss:0.152412
Clustering   1329: ASW= 0.8282, DB= 0.2383, CH= 54493.1348
Training epoch 1330, recon_loss:0.772259, zinb_loss:0.639088, cluster_loss:0.153074
Clustering   1330: ASW= 0.8274, DB= 0.2341, CH= 53189.7430
Training epoch 1331, recon_loss:0.771799, zinb_loss:0.638923, cluster_loss:0.152269
Clustering   1331: ASW= 0.8282, DB= 0.2381, CH= 54563.5728
Training epoch 1332, recon_loss:0.772087, zinb_loss:0.639045, cluster_loss:0.152708
Clustering   1332: ASW= 0.8280, DB= 0.2343, CH= 53228.3962
Training epoch 1333, recon_loss:0.772107, zinb_loss:0.638757, cluster_loss:0.152475
Clustering   1333: ASW= 0.8274, DB= 0.2390, CH= 54335.8374
Training epoch 1334, recon_loss:0.772799, zinb_loss:0.639118, cluster_loss:0.152771
Clustering   1334: ASW= 0.8284, DB= 0.2344, CH= 53235.2281
Training epoch 1335, recon_loss:0.772561, zinb_loss:0.638542, cluster_loss:0.152761
Clustering   1335: ASW= 0.8269, DB= 0.2395, CH= 54019.1946
Training epoch 1336, recon_loss:0.772946, zinb_loss:0.638963, cluster_loss:0.152696
Clustering   1336: ASW= 0.8286, DB= 0.2349, CH= 53253.3780
Training epoch 1337, recon_loss:0.772281, zinb_loss:0.638362, cluster_loss:0.152574
Clustering   1337: ASW= 0.8271, DB= 0.2390, CH= 54024.4060
Training epoch 1338, recon_loss:0.772488, zinb_loss:0.638792, cluster_loss:0.152385
Clustering   1338: ASW= 0.8289, DB= 0.2341, CH= 53407.9346
Training epoch 1339, recon_loss:0.772009, zinb_loss:0.638395, cluster_loss:0.152352
Clustering   1339: ASW= 0.8273, DB= 0.2384, CH= 54087.7310
Training epoch 1340, recon_loss:0.772294, zinb_loss:0.638841, cluster_loss:0.152222
Clustering   1340: ASW= 0.8290, DB= 0.2339, CH= 53503.1926
Training epoch 1341, recon_loss:0.772069, zinb_loss:0.638627, cluster_loss:0.152261
Clustering   1341: ASW= 0.8273, DB= 0.2385, CH= 54165.7747
Training epoch 1342, recon_loss:0.772464, zinb_loss:0.639116, cluster_loss:0.152235
Clustering   1342: ASW= 0.8291, DB= 0.2341, CH= 53496.7086
Training epoch 1343, recon_loss:0.772215, zinb_loss:0.639002, cluster_loss:0.152238
Clustering   1343: ASW= 0.8275, DB= 0.2384, CH= 54259.7082
Training epoch 1344, recon_loss:0.772485, zinb_loss:0.639393, cluster_loss:0.152354
Clustering   1344: ASW= 0.8289, DB= 0.2341, CH= 53534.9030
Training epoch 1345, recon_loss:0.772231, zinb_loss:0.639366, cluster_loss:0.152308
Clustering   1345: ASW= 0.8276, DB= 0.2383, CH= 54283.5878
Training epoch 1346, recon_loss:0.772503, zinb_loss:0.639520, cluster_loss:0.152580
Clustering   1346: ASW= 0.8286, DB= 0.2341, CH= 53443.5884
Training epoch 1347, recon_loss:0.772475, zinb_loss:0.639645, cluster_loss:0.152489
Clustering   1347: ASW= 0.8275, DB= 0.2376, CH= 54256.0822
Training epoch 1348, recon_loss:0.772724, zinb_loss:0.639736, cluster_loss:0.152739
Clustering   1348: ASW= 0.8287, DB= 0.2340, CH= 53414.8077
Training epoch 1349, recon_loss:0.772372, zinb_loss:0.639763, cluster_loss:0.152453
Clustering   1349: ASW= 0.8277, DB= 0.2371, CH= 54233.5372
Training epoch 1350, recon_loss:0.772237, zinb_loss:0.639666, cluster_loss:0.152681
Clustering   1350: ASW= 0.8288, DB= 0.2333, CH= 53678.8647
Training epoch 1351, recon_loss:0.772123, zinb_loss:0.639805, cluster_loss:0.152406
Clustering   1351: ASW= 0.8278, DB= 0.2371, CH= 54191.3282
Training epoch 1352, recon_loss:0.772381, zinb_loss:0.639551, cluster_loss:0.152765
Clustering   1352: ASW= 0.8287, DB= 0.2342, CH= 53831.7886
Training epoch 1353, recon_loss:0.772489, zinb_loss:0.639781, cluster_loss:0.152451
Clustering   1353: ASW= 0.8278, DB= 0.2364, CH= 54028.8505
Training epoch 1354, recon_loss:0.772211, zinb_loss:0.639389, cluster_loss:0.152781
Clustering   1354: ASW= 0.8286, DB= 0.2350, CH= 53883.4986
Training epoch 1355, recon_loss:0.772476, zinb_loss:0.639586, cluster_loss:0.152365
Clustering   1355: ASW= 0.8280, DB= 0.2358, CH= 54031.2378
Training epoch 1356, recon_loss:0.771945, zinb_loss:0.639173, cluster_loss:0.152677
Clustering   1356: ASW= 0.8288, DB= 0.2349, CH= 53970.0474
Training epoch 1357, recon_loss:0.772143, zinb_loss:0.639446, cluster_loss:0.152306
Clustering   1357: ASW= 0.8275, DB= 0.2358, CH= 53898.5450
Training epoch 1358, recon_loss:0.771996, zinb_loss:0.639219, cluster_loss:0.152726
Clustering   1358: ASW= 0.8289, DB= 0.2354, CH= 53885.0351
Training epoch 1359, recon_loss:0.772407, zinb_loss:0.639474, cluster_loss:0.152217
Clustering   1359: ASW= 0.8279, DB= 0.2354, CH= 53920.3606
Training epoch 1360, recon_loss:0.772296, zinb_loss:0.639357, cluster_loss:0.152701
Clustering   1360: ASW= 0.8290, DB= 0.2353, CH= 54077.9333
Training epoch 1361, recon_loss:0.772598, zinb_loss:0.639454, cluster_loss:0.152200
Clustering   1361: ASW= 0.8279, DB= 0.2354, CH= 53861.2428
Training epoch 1362, recon_loss:0.772201, zinb_loss:0.639188, cluster_loss:0.152631
Clustering   1362: ASW= 0.8290, DB= 0.2356, CH= 54163.8676
Training epoch 1363, recon_loss:0.772340, zinb_loss:0.639220, cluster_loss:0.152070
Clustering   1363: ASW= 0.8281, DB= 0.2354, CH= 53934.7163
Training epoch 1364, recon_loss:0.771886, zinb_loss:0.638910, cluster_loss:0.152486
Clustering   1364: ASW= 0.8290, DB= 0.2355, CH= 54186.3529
Training epoch 1365, recon_loss:0.771984, zinb_loss:0.638978, cluster_loss:0.151931
Clustering   1365: ASW= 0.8283, DB= 0.2355, CH= 54102.8711
Training epoch 1366, recon_loss:0.771751, zinb_loss:0.638725, cluster_loss:0.152391
Clustering   1366: ASW= 0.8290, DB= 0.2347, CH= 54151.0044
Training epoch 1367, recon_loss:0.771773, zinb_loss:0.638776, cluster_loss:0.151826
Clustering   1367: ASW= 0.8284, DB= 0.2356, CH= 54209.7089
Training epoch 1368, recon_loss:0.771647, zinb_loss:0.638549, cluster_loss:0.152264
Clustering   1368: ASW= 0.8290, DB= 0.2349, CH= 54267.3439
Training epoch 1369, recon_loss:0.771651, zinb_loss:0.638662, cluster_loss:0.151805
Clustering   1369: ASW= 0.8285, DB= 0.2352, CH= 54291.2511
Training epoch 1370, recon_loss:0.771663, zinb_loss:0.638513, cluster_loss:0.152191
Clustering   1370: ASW= 0.8291, DB= 0.2348, CH= 54306.3594
Training epoch 1371, recon_loss:0.771562, zinb_loss:0.638600, cluster_loss:0.151768
Clustering   1371: ASW= 0.8286, DB= 0.2346, CH= 54370.0542
Training epoch 1372, recon_loss:0.771643, zinb_loss:0.638477, cluster_loss:0.152142
Clustering   1372: ASW= 0.8291, DB= 0.2353, CH= 54415.1828
Training epoch 1373, recon_loss:0.771579, zinb_loss:0.638609, cluster_loss:0.151799
Clustering   1373: ASW= 0.8286, DB= 0.2351, CH= 54454.6469
Training epoch 1374, recon_loss:0.771753, zinb_loss:0.638597, cluster_loss:0.152159
Clustering   1374: ASW= 0.8291, DB= 0.2349, CH= 54347.4044
Training epoch 1375, recon_loss:0.771631, zinb_loss:0.638704, cluster_loss:0.151851
Clustering   1375: ASW= 0.8285, DB= 0.2357, CH= 54514.7884
Training epoch 1376, recon_loss:0.772086, zinb_loss:0.638876, cluster_loss:0.152300
Clustering   1376: ASW= 0.8291, DB= 0.2352, CH= 54379.2300
Training epoch 1377, recon_loss:0.771992, zinb_loss:0.639027, cluster_loss:0.151972
Clustering   1377: ASW= 0.8285, DB= 0.2359, CH= 54619.0368
Training epoch 1378, recon_loss:0.772404, zinb_loss:0.639248, cluster_loss:0.152374
Clustering   1378: ASW= 0.8292, DB= 0.2345, CH= 54299.0085
Training epoch 1379, recon_loss:0.772835, zinb_loss:0.639553, cluster_loss:0.152250
Clustering   1379: ASW= 0.8283, DB= 0.2366, CH= 54669.4939
Training epoch 1380, recon_loss:0.773144, zinb_loss:0.639691, cluster_loss:0.152723
Clustering   1380: ASW= 0.8282, DB= 0.2348, CH= 53425.9921
Training epoch 1381, recon_loss:0.773066, zinb_loss:0.639559, cluster_loss:0.152447
Clustering   1381: ASW= 0.8273, DB= 0.2379, CH= 54511.7982
Training epoch 1382, recon_loss:0.774201, zinb_loss:0.640286, cluster_loss:0.152549
Clustering   1382: ASW= 0.8296, DB= 0.2331, CH= 53949.9548
Training epoch 1383, recon_loss:0.773321, zinb_loss:0.639825, cluster_loss:0.152426
Clustering   1383: ASW= 0.8272, DB= 0.2386, CH= 54586.2291
Training epoch 1384, recon_loss:0.773336, zinb_loss:0.640328, cluster_loss:0.152405
Clustering   1384: ASW= 0.8296, DB= 0.2330, CH= 53904.2068
Training epoch 1385, recon_loss:0.772507, zinb_loss:0.639978, cluster_loss:0.152176
Clustering   1385: ASW= 0.8278, DB= 0.2372, CH= 54733.3690
Training epoch 1386, recon_loss:0.772887, zinb_loss:0.640298, cluster_loss:0.152376
Clustering   1386: ASW= 0.8296, DB= 0.2330, CH= 54114.7877
Training epoch 1387, recon_loss:0.772312, zinb_loss:0.640075, cluster_loss:0.152264
Clustering   1387: ASW= 0.8281, DB= 0.2365, CH= 54779.2037
Training epoch 1388, recon_loss:0.772854, zinb_loss:0.640248, cluster_loss:0.152553
Clustering   1388: ASW= 0.8298, DB= 0.2335, CH= 54215.1935
Training epoch 1389, recon_loss:0.772104, zinb_loss:0.640141, cluster_loss:0.152399
Clustering   1389: ASW= 0.8283, DB= 0.2357, CH= 54736.5597
Training epoch 1390, recon_loss:0.772619, zinb_loss:0.640005, cluster_loss:0.152631
Clustering   1390: ASW= 0.8298, DB= 0.2348, CH= 54384.8279
Training epoch 1391, recon_loss:0.772085, zinb_loss:0.640213, cluster_loss:0.152488
Clustering   1391: ASW= 0.8284, DB= 0.2346, CH= 54721.8953
Training epoch 1392, recon_loss:0.772427, zinb_loss:0.639817, cluster_loss:0.152825
Clustering   1392: ASW= 0.8295, DB= 0.2356, CH= 54297.4635
Training epoch 1393, recon_loss:0.772256, zinb_loss:0.640200, cluster_loss:0.152467
Clustering   1393: ASW= 0.8285, DB= 0.2345, CH= 54644.4699
Training epoch 1394, recon_loss:0.772506, zinb_loss:0.639754, cluster_loss:0.152980
Clustering   1394: ASW= 0.8290, DB= 0.2357, CH= 54064.9132
Training epoch 1395, recon_loss:0.772247, zinb_loss:0.640269, cluster_loss:0.152309
Clustering   1395: ASW= 0.8287, DB= 0.2344, CH= 54614.6933
Training epoch 1396, recon_loss:0.772559, zinb_loss:0.639751, cluster_loss:0.153014
Clustering   1396: ASW= 0.8286, DB= 0.2359, CH= 53910.2489
Training epoch 1397, recon_loss:0.772225, zinb_loss:0.640218, cluster_loss:0.152192
Clustering   1397: ASW= 0.8288, DB= 0.2344, CH= 54555.9312
Training epoch 1398, recon_loss:0.772444, zinb_loss:0.639629, cluster_loss:0.153082
Clustering   1398: ASW= 0.8280, DB= 0.2361, CH= 53665.6823
Training epoch 1399, recon_loss:0.771805, zinb_loss:0.640190, cluster_loss:0.152012
Clustering   1399: ASW= 0.8288, DB= 0.2338, CH= 54472.5884
Training epoch 1400, recon_loss:0.772179, zinb_loss:0.639541, cluster_loss:0.152912
Clustering   1400: ASW= 0.8277, DB= 0.2359, CH= 53660.7053
Training epoch 1401, recon_loss:0.771531, zinb_loss:0.639928, cluster_loss:0.152004
Clustering   1401: ASW= 0.8286, DB= 0.2344, CH= 54253.1947
Training epoch 1402, recon_loss:0.771881, zinb_loss:0.639451, cluster_loss:0.152713
Clustering   1402: ASW= 0.8278, DB= 0.2353, CH= 53763.1419
Training epoch 1403, recon_loss:0.771235, zinb_loss:0.639777, cluster_loss:0.151784
Clustering   1403: ASW= 0.8289, DB= 0.2344, CH= 54454.4181
Training epoch 1404, recon_loss:0.771695, zinb_loss:0.639306, cluster_loss:0.152505
Clustering   1404: ASW= 0.8278, DB= 0.2350, CH= 53912.0201
Training epoch 1405, recon_loss:0.770906, zinb_loss:0.639534, cluster_loss:0.151721
Clustering   1405: ASW= 0.8290, DB= 0.2341, CH= 54464.7775
Training epoch 1406, recon_loss:0.771493, zinb_loss:0.639203, cluster_loss:0.152312
Clustering   1406: ASW= 0.8281, DB= 0.2345, CH= 54193.3249
Training epoch 1407, recon_loss:0.770836, zinb_loss:0.639415, cluster_loss:0.151635
Clustering   1407: ASW= 0.8293, DB= 0.2346, CH= 54666.8438
Training epoch 1408, recon_loss:0.771380, zinb_loss:0.639143, cluster_loss:0.152154
Clustering   1408: ASW= 0.8283, DB= 0.2340, CH= 54451.6608
Training epoch 1409, recon_loss:0.770816, zinb_loss:0.639231, cluster_loss:0.151682
Clustering   1409: ASW= 0.8292, DB= 0.2346, CH= 54646.7350
Training epoch 1410, recon_loss:0.771443, zinb_loss:0.639096, cluster_loss:0.152075
Clustering   1410: ASW= 0.8285, DB= 0.2334, CH= 54604.9031
Training epoch 1411, recon_loss:0.770890, zinb_loss:0.639158, cluster_loss:0.151716
Clustering   1411: ASW= 0.8294, DB= 0.2346, CH= 54706.4227
Training epoch 1412, recon_loss:0.771499, zinb_loss:0.639153, cluster_loss:0.152013
Clustering   1412: ASW= 0.8285, DB= 0.2333, CH= 54792.2556
Training epoch 1413, recon_loss:0.771085, zinb_loss:0.639050, cluster_loss:0.151885
Clustering   1413: ASW= 0.8291, DB= 0.2356, CH= 54561.7477
Training epoch 1414, recon_loss:0.771887, zinb_loss:0.639223, cluster_loss:0.152052
Clustering   1414: ASW= 0.8286, DB= 0.2328, CH= 54874.3752
Training epoch 1415, recon_loss:0.771371, zinb_loss:0.639026, cluster_loss:0.152114
Clustering   1415: ASW= 0.8288, DB= 0.2360, CH= 54453.4938
Training epoch 1416, recon_loss:0.772349, zinb_loss:0.639457, cluster_loss:0.152063
Clustering   1416: ASW= 0.8288, DB= 0.2322, CH= 54898.2272
Training epoch 1417, recon_loss:0.771999, zinb_loss:0.638990, cluster_loss:0.152471
Clustering   1417: ASW= 0.8282, DB= 0.2377, CH= 54144.4925
Training epoch 1418, recon_loss:0.773227, zinb_loss:0.639582, cluster_loss:0.152191
Clustering   1418: ASW= 0.8290, DB= 0.2319, CH= 54865.1442
Training epoch 1419, recon_loss:0.772469, zinb_loss:0.638764, cluster_loss:0.152846
Clustering   1419: ASW= 0.8278, DB= 0.2389, CH= 53818.0596
Training epoch 1420, recon_loss:0.773526, zinb_loss:0.639486, cluster_loss:0.152219
Clustering   1420: ASW= 0.8296, DB= 0.2318, CH= 54813.2543
Training epoch 1421, recon_loss:0.772539, zinb_loss:0.638518, cluster_loss:0.152988
Clustering   1421: ASW= 0.8276, DB= 0.2392, CH= 53676.4965
Training epoch 1422, recon_loss:0.773251, zinb_loss:0.639302, cluster_loss:0.152174
Clustering   1422: ASW= 0.8299, DB= 0.2319, CH= 54764.5636
Training epoch 1423, recon_loss:0.772323, zinb_loss:0.638421, cluster_loss:0.152848
Clustering   1423: ASW= 0.8279, DB= 0.2386, CH= 53819.1749
Training epoch 1424, recon_loss:0.772838, zinb_loss:0.639342, cluster_loss:0.152017
Clustering   1424: ASW= 0.8303, DB= 0.2314, CH= 54877.3062
Training epoch 1425, recon_loss:0.771979, zinb_loss:0.638596, cluster_loss:0.152603
Clustering   1425: ASW= 0.8282, DB= 0.2375, CH= 54016.9811
Training epoch 1426, recon_loss:0.772317, zinb_loss:0.639475, cluster_loss:0.151859
Clustering   1426: ASW= 0.8306, DB= 0.2318, CH= 55070.8122
Training epoch 1427, recon_loss:0.771571, zinb_loss:0.638842, cluster_loss:0.152383
Clustering   1427: ASW= 0.8285, DB= 0.2370, CH= 54245.9790
Training epoch 1428, recon_loss:0.772037, zinb_loss:0.639590, cluster_loss:0.151766
Clustering   1428: ASW= 0.8308, DB= 0.2316, CH= 55225.0998
Training epoch 1429, recon_loss:0.771432, zinb_loss:0.638991, cluster_loss:0.152226
Clustering   1429: ASW= 0.8286, DB= 0.2363, CH= 54339.3585
Training epoch 1430, recon_loss:0.772133, zinb_loss:0.639512, cluster_loss:0.151766
Clustering   1430: ASW= 0.8306, DB= 0.2313, CH= 55301.0874
Training epoch 1431, recon_loss:0.771736, zinb_loss:0.639135, cluster_loss:0.152194
Clustering   1431: ASW= 0.8288, DB= 0.2362, CH= 54585.3976
Training epoch 1432, recon_loss:0.772542, zinb_loss:0.639696, cluster_loss:0.151780
Clustering   1432: ASW= 0.8308, DB= 0.2314, CH= 55356.2969
Training epoch 1433, recon_loss:0.772024, zinb_loss:0.639320, cluster_loss:0.152198
Clustering   1433: ASW= 0.8288, DB= 0.2358, CH= 54625.5232
Training epoch 1434, recon_loss:0.772652, zinb_loss:0.639797, cluster_loss:0.151862
Clustering   1434: ASW= 0.8307, DB= 0.2315, CH= 55378.2017
Training epoch 1435, recon_loss:0.772109, zinb_loss:0.639419, cluster_loss:0.152228
Clustering   1435: ASW= 0.8288, DB= 0.2360, CH= 54634.2800
Training epoch 1436, recon_loss:0.772615, zinb_loss:0.639803, cluster_loss:0.151946
Clustering   1436: ASW= 0.8307, DB= 0.2315, CH= 55364.8789
Training epoch 1437, recon_loss:0.772186, zinb_loss:0.639450, cluster_loss:0.152217
Clustering   1437: ASW= 0.8289, DB= 0.2357, CH= 54667.3469
Training epoch 1438, recon_loss:0.772624, zinb_loss:0.639638, cluster_loss:0.152112
Clustering   1438: ASW= 0.8304, DB= 0.2315, CH= 55245.2957
Training epoch 1439, recon_loss:0.772491, zinb_loss:0.639424, cluster_loss:0.152257
Clustering   1439: ASW= 0.8292, DB= 0.2353, CH= 54706.4187
Training epoch 1440, recon_loss:0.772881, zinb_loss:0.639403, cluster_loss:0.152371
Clustering   1440: ASW= 0.8300, DB= 0.2323, CH= 55020.8940
Training epoch 1441, recon_loss:0.772932, zinb_loss:0.639434, cluster_loss:0.152328
Clustering   1441: ASW= 0.8293, DB= 0.2346, CH= 54581.0326
Training epoch 1442, recon_loss:0.772795, zinb_loss:0.639016, cluster_loss:0.152637
Clustering   1442: ASW= 0.8295, DB= 0.2332, CH= 54678.1546
Training epoch 1443, recon_loss:0.772662, zinb_loss:0.639197, cluster_loss:0.152522
Clustering   1443: ASW= 0.8293, DB= 0.2352, CH= 54346.2627
Training epoch 1444, recon_loss:0.771920, zinb_loss:0.638727, cluster_loss:0.152515
Clustering   1444: ASW= 0.8288, DB= 0.2342, CH= 54147.9193
Training epoch 1445, recon_loss:0.771788, zinb_loss:0.638959, cluster_loss:0.152561
Clustering   1445: ASW= 0.8276, DB= 0.2378, CH= 53844.2491
Training epoch 1446, recon_loss:0.772936, zinb_loss:0.638988, cluster_loss:0.153884
Clustering   1446: ASW= 0.8280, DB= 0.2348, CH= 53354.0016
Training epoch 1447, recon_loss:0.772248, zinb_loss:0.639176, cluster_loss:0.152610
Clustering   1447: ASW= 0.8290, DB= 0.2357, CH= 54002.2283
Training epoch 1448, recon_loss:0.773897, zinb_loss:0.639109, cluster_loss:0.154721
Clustering   1448: ASW= 0.8266, DB= 0.2352, CH= 52883.8802
Training epoch 1449, recon_loss:0.777321, zinb_loss:0.639760, cluster_loss:0.154381
Clustering   1449: ASW= 0.8224, DB= 0.2433, CH= 51861.2071
Training epoch 1450, recon_loss:0.775597, zinb_loss:0.639327, cluster_loss:0.153430
Clustering   1450: ASW= 0.8259, DB= 0.2381, CH= 52838.2194
Training epoch 1451, recon_loss:0.772094, zinb_loss:0.638829, cluster_loss:0.152364
Clustering   1451: ASW= 0.8261, DB= 0.2389, CH= 52607.6735
Training epoch 1452, recon_loss:0.770926, zinb_loss:0.638589, cluster_loss:0.152091
Clustering   1452: ASW= 0.8275, DB= 0.2361, CH= 53903.0808
Training epoch 1453, recon_loss:0.770454, zinb_loss:0.638291, cluster_loss:0.151875
Clustering   1453: ASW= 0.8277, DB= 0.2361, CH= 53563.0658
Training epoch 1454, recon_loss:0.770039, zinb_loss:0.638421, cluster_loss:0.151669
Clustering   1454: ASW= 0.8286, DB= 0.2347, CH= 54531.1569
Training epoch 1455, recon_loss:0.769956, zinb_loss:0.638136, cluster_loss:0.151758
Clustering   1455: ASW= 0.8283, DB= 0.2354, CH= 53942.9018
Training epoch 1456, recon_loss:0.769886, zinb_loss:0.638518, cluster_loss:0.151486
Clustering   1456: ASW= 0.8293, DB= 0.2340, CH= 54921.4944
Training epoch 1457, recon_loss:0.769926, zinb_loss:0.638240, cluster_loss:0.151816
Clustering   1457: ASW= 0.8286, DB= 0.2353, CH= 54131.3247
Training epoch 1458, recon_loss:0.770206, zinb_loss:0.638897, cluster_loss:0.151431
Clustering   1458: ASW= 0.8298, DB= 0.2338, CH= 55220.3378
Training epoch 1459, recon_loss:0.770463, zinb_loss:0.638607, cluster_loss:0.152103
Clustering   1459: ASW= 0.8285, DB= 0.2357, CH= 54110.6906
Training epoch 1460, recon_loss:0.771299, zinb_loss:0.639628, cluster_loss:0.151572
Clustering   1460: ASW= 0.8301, DB= 0.2332, CH= 55251.4032
Training epoch 1461, recon_loss:0.771987, zinb_loss:0.639261, cluster_loss:0.152608
Clustering   1461: ASW= 0.8281, DB= 0.2366, CH= 53877.5904
Training epoch 1462, recon_loss:0.773203, zinb_loss:0.640359, cluster_loss:0.151897
Clustering   1462: ASW= 0.8300, DB= 0.2336, CH= 55016.5840
Training epoch 1463, recon_loss:0.773890, zinb_loss:0.639701, cluster_loss:0.152999
Clustering   1463: ASW= 0.8280, DB= 0.2368, CH= 53717.1440
Training epoch 1464, recon_loss:0.773658, zinb_loss:0.640287, cluster_loss:0.151989
Clustering   1464: ASW= 0.8301, DB= 0.2332, CH= 54827.6680
Training epoch 1465, recon_loss:0.773532, zinb_loss:0.639236, cluster_loss:0.152768
Clustering   1465: ASW= 0.8283, DB= 0.2366, CH= 54007.1876
Training epoch 1466, recon_loss:0.772617, zinb_loss:0.639637, cluster_loss:0.151759
Clustering   1466: ASW= 0.8304, DB= 0.2325, CH= 54978.0967
Training epoch 1467, recon_loss:0.771911, zinb_loss:0.638607, cluster_loss:0.152299
Clustering   1467: ASW= 0.8287, DB= 0.2364, CH= 54348.6262
Training epoch 1468, recon_loss:0.771728, zinb_loss:0.639071, cluster_loss:0.151544
Clustering   1468: ASW= 0.8306, DB= 0.2321, CH= 55166.5309
Training epoch 1469, recon_loss:0.771511, zinb_loss:0.638383, cluster_loss:0.151988
Clustering   1469: ASW= 0.8292, DB= 0.2354, CH= 54741.2045
Training epoch 1470, recon_loss:0.771677, zinb_loss:0.638753, cluster_loss:0.151469
Clustering   1470: ASW= 0.8307, DB= 0.2319, CH= 55269.0282
Training epoch 1471, recon_loss:0.771672, zinb_loss:0.638344, cluster_loss:0.151806
Clustering   1471: ASW= 0.8296, DB= 0.2348, CH= 55068.2689
Training epoch 1472, recon_loss:0.772098, zinb_loss:0.638704, cluster_loss:0.151551
Clustering   1472: ASW= 0.8307, DB= 0.2314, CH= 55320.1890
Training epoch 1473, recon_loss:0.772111, zinb_loss:0.638602, cluster_loss:0.151777
Clustering   1473: ASW= 0.8301, DB= 0.2344, CH= 55326.3990
Training epoch 1474, recon_loss:0.772626, zinb_loss:0.638941, cluster_loss:0.151835
Clustering   1474: ASW= 0.8304, DB= 0.2317, CH= 55192.0030
Training epoch 1475, recon_loss:0.772546, zinb_loss:0.639146, cluster_loss:0.151820
Clustering   1475: ASW= 0.8305, DB= 0.2341, CH= 55600.1142
Training epoch 1476, recon_loss:0.773071, zinb_loss:0.639313, cluster_loss:0.152297
Clustering   1476: ASW= 0.8300, DB= 0.2321, CH= 54886.5920
Training epoch 1477, recon_loss:0.772701, zinb_loss:0.639666, cluster_loss:0.151941
Clustering   1477: ASW= 0.8308, DB= 0.2334, CH= 55710.4009
Training epoch 1478, recon_loss:0.772924, zinb_loss:0.639418, cluster_loss:0.152765
Clustering   1478: ASW= 0.8295, DB= 0.2324, CH= 54477.0440
Training epoch 1479, recon_loss:0.772358, zinb_loss:0.639804, cluster_loss:0.152054
Clustering   1479: ASW= 0.8308, DB= 0.2336, CH= 55654.1050
Training epoch 1480, recon_loss:0.772299, zinb_loss:0.639218, cluster_loss:0.153102
Clustering   1480: ASW= 0.8291, DB= 0.2332, CH= 54068.6999
Training epoch 1481, recon_loss:0.771817, zinb_loss:0.639626, cluster_loss:0.152104
Clustering   1481: ASW= 0.8307, DB= 0.2334, CH= 55480.8532
Training epoch 1482, recon_loss:0.771602, zinb_loss:0.638895, cluster_loss:0.153181
Clustering   1482: ASW= 0.8288, DB= 0.2335, CH= 53833.4347
Training epoch 1483, recon_loss:0.771263, zinb_loss:0.639295, cluster_loss:0.152030
Clustering   1483: ASW= 0.8307, DB= 0.2333, CH= 55396.4697
Training epoch 1484, recon_loss:0.770999, zinb_loss:0.638703, cluster_loss:0.152880
Clustering   1484: ASW= 0.8291, DB= 0.2336, CH= 53980.6921
Training epoch 1485, recon_loss:0.770917, zinb_loss:0.639077, cluster_loss:0.151835
Clustering   1485: ASW= 0.8306, DB= 0.2335, CH= 55424.1083
Training epoch 1486, recon_loss:0.770758, zinb_loss:0.638671, cluster_loss:0.152770
Clustering   1486: ASW= 0.8292, DB= 0.2329, CH= 54166.6173
Training epoch 1487, recon_loss:0.770732, zinb_loss:0.638919, cluster_loss:0.151696
Clustering   1487: ASW= 0.8307, DB= 0.2332, CH= 55538.8257
Training epoch 1488, recon_loss:0.770634, zinb_loss:0.638627, cluster_loss:0.152366
Clustering   1488: ASW= 0.8297, DB= 0.2329, CH= 54531.2592
Training epoch 1489, recon_loss:0.770802, zinb_loss:0.638824, cluster_loss:0.151586
Clustering   1489: ASW= 0.8306, DB= 0.2337, CH= 55663.8326
Training epoch 1490, recon_loss:0.771036, zinb_loss:0.638755, cluster_loss:0.152185
Clustering   1490: ASW= 0.8302, DB= 0.2323, CH= 54790.8168
Training epoch 1491, recon_loss:0.771299, zinb_loss:0.638857, cluster_loss:0.151592
Clustering   1491: ASW= 0.8304, DB= 0.2342, CH= 55736.1367
Training epoch 1492, recon_loss:0.771659, zinb_loss:0.638938, cluster_loss:0.152160
Clustering   1492: ASW= 0.8305, DB= 0.2318, CH= 54915.6403
Training epoch 1493, recon_loss:0.771696, zinb_loss:0.638954, cluster_loss:0.151685
Clustering   1493: ASW= 0.8300, DB= 0.2350, CH= 55766.9713
Training epoch 1494, recon_loss:0.771913, zinb_loss:0.639188, cluster_loss:0.152233
Clustering   1494: ASW= 0.8307, DB= 0.2320, CH= 54907.7332
Training epoch 1495, recon_loss:0.772037, zinb_loss:0.639103, cluster_loss:0.151798
Clustering   1495: ASW= 0.8297, DB= 0.2348, CH= 55745.1994
Training epoch 1496, recon_loss:0.772467, zinb_loss:0.639348, cluster_loss:0.152308
Clustering   1496: ASW= 0.8309, DB= 0.2318, CH= 54890.7813
Training epoch 1497, recon_loss:0.772404, zinb_loss:0.639149, cluster_loss:0.151925
Clustering   1497: ASW= 0.8294, DB= 0.2357, CH= 55740.5966
Training epoch 1498, recon_loss:0.772332, zinb_loss:0.639419, cluster_loss:0.152376
Clustering   1498: ASW= 0.8309, DB= 0.2319, CH= 54660.5209
Training epoch 1499, recon_loss:0.772242, zinb_loss:0.639168, cluster_loss:0.151998
Clustering   1499: ASW= 0.8292, DB= 0.2356, CH= 55597.6126
Training epoch 1500, recon_loss:0.772234, zinb_loss:0.639390, cluster_loss:0.152354
Clustering   1500: ASW= 0.8309, DB= 0.2316, CH= 54614.2404
Training epoch 1501, recon_loss:0.771942, zinb_loss:0.638997, cluster_loss:0.151949
Clustering   1501: ASW= 0.8292, DB= 0.2357, CH= 55507.2467
Training epoch 1502, recon_loss:0.771585, zinb_loss:0.639148, cluster_loss:0.152174
Clustering   1502: ASW= 0.8310, DB= 0.2315, CH= 54688.5617
Training epoch 1503, recon_loss:0.771387, zinb_loss:0.638870, cluster_loss:0.151776
Clustering   1503: ASW= 0.8293, DB= 0.2356, CH= 55558.1030
Training epoch 1504, recon_loss:0.770958, zinb_loss:0.638929, cluster_loss:0.151985
Clustering   1504: ASW= 0.8312, DB= 0.2314, CH= 54845.1961
Training epoch 1505, recon_loss:0.771068, zinb_loss:0.638847, cluster_loss:0.151629
Clustering   1505: ASW= 0.8296, DB= 0.2353, CH= 55650.9120
Training epoch 1506, recon_loss:0.770752, zinb_loss:0.638751, cluster_loss:0.151973
Clustering   1506: ASW= 0.8310, DB= 0.2313, CH= 54954.2454
Training epoch 1507, recon_loss:0.771196, zinb_loss:0.638987, cluster_loss:0.151681
Clustering   1507: ASW= 0.8293, DB= 0.2350, CH= 55501.4372
Training epoch 1508, recon_loss:0.770929, zinb_loss:0.638906, cluster_loss:0.152014
Clustering   1508: ASW= 0.8302, DB= 0.2329, CH= 54448.9850
Training epoch 1509, recon_loss:0.771017, zinb_loss:0.638960, cluster_loss:0.151671
Clustering   1509: ASW= 0.8295, DB= 0.2348, CH= 55558.0561
Training epoch 1510, recon_loss:0.770633, zinb_loss:0.639007, cluster_loss:0.151926
Clustering   1510: ASW= 0.8311, DB= 0.2318, CH= 54925.2463
Training epoch 1511, recon_loss:0.771042, zinb_loss:0.639220, cluster_loss:0.151618
Clustering   1511: ASW= 0.8296, DB= 0.2341, CH= 55531.7540
Training epoch 1512, recon_loss:0.771349, zinb_loss:0.639359, cluster_loss:0.151979
Clustering   1512: ASW= 0.8311, DB= 0.2316, CH= 55208.2002
Training epoch 1513, recon_loss:0.771845, zinb_loss:0.639604, cluster_loss:0.151732
Clustering   1513: ASW= 0.8296, DB= 0.2333, CH= 55276.1432
Training epoch 1514, recon_loss:0.772170, zinb_loss:0.639526, cluster_loss:0.152207
Clustering   1514: ASW= 0.8308, DB= 0.2324, CH= 55316.7699
Training epoch 1515, recon_loss:0.772437, zinb_loss:0.639711, cluster_loss:0.151834
Clustering   1515: ASW= 0.8299, DB= 0.2326, CH= 55083.7788
Training epoch 1516, recon_loss:0.772015, zinb_loss:0.639113, cluster_loss:0.152435
Clustering   1516: ASW= 0.8302, DB= 0.2335, CH= 55234.3056
Training epoch 1517, recon_loss:0.771876, zinb_loss:0.639194, cluster_loss:0.151884
Clustering   1517: ASW= 0.8301, DB= 0.2325, CH= 54809.6581
Training epoch 1518, recon_loss:0.770984, zinb_loss:0.638289, cluster_loss:0.152413
Clustering   1518: ASW= 0.8297, DB= 0.2339, CH= 55064.2249
Training epoch 1519, recon_loss:0.770999, zinb_loss:0.638546, cluster_loss:0.151786
Clustering   1519: ASW= 0.8306, DB= 0.2319, CH= 54903.3539
Training epoch 1520, recon_loss:0.770280, zinb_loss:0.637760, cluster_loss:0.152288
Clustering   1520: ASW= 0.8296, DB= 0.2339, CH= 55031.9780
Training epoch 1521, recon_loss:0.770497, zinb_loss:0.638158, cluster_loss:0.151679
Clustering   1521: ASW= 0.8311, DB= 0.2317, CH= 55114.4178
Training epoch 1522, recon_loss:0.770128, zinb_loss:0.637595, cluster_loss:0.152093
Clustering   1522: ASW= 0.8296, DB= 0.2331, CH= 55167.4511
Training epoch 1523, recon_loss:0.770623, zinb_loss:0.638001, cluster_loss:0.151664
Clustering   1523: ASW= 0.8314, DB= 0.2319, CH= 55304.7215
Training epoch 1524, recon_loss:0.770709, zinb_loss:0.637679, cluster_loss:0.152053
Clustering   1524: ASW= 0.8297, DB= 0.2327, CH= 55308.4663
Training epoch 1525, recon_loss:0.771233, zinb_loss:0.638000, cluster_loss:0.151807
Clustering   1525: ASW= 0.8315, DB= 0.2321, CH= 55393.5116
Training epoch 1526, recon_loss:0.771215, zinb_loss:0.637864, cluster_loss:0.152045
Clustering   1526: ASW= 0.8298, DB= 0.2321, CH= 55411.1288
Training epoch 1527, recon_loss:0.771298, zinb_loss:0.637991, cluster_loss:0.151889
Clustering   1527: ASW= 0.8314, DB= 0.2329, CH= 55413.0791
Training epoch 1528, recon_loss:0.770950, zinb_loss:0.638025, cluster_loss:0.151909
Clustering   1528: ASW= 0.8301, DB= 0.2320, CH= 55562.8749
Training epoch 1529, recon_loss:0.770981, zinb_loss:0.637977, cluster_loss:0.151831
Clustering   1529: ASW= 0.8312, DB= 0.2336, CH= 55465.9097
Training epoch 1530, recon_loss:0.770621, zinb_loss:0.638176, cluster_loss:0.151744
Clustering   1530: ASW= 0.8304, DB= 0.2318, CH= 55688.3857
Training epoch 1531, recon_loss:0.770783, zinb_loss:0.638020, cluster_loss:0.151758
Clustering   1531: ASW= 0.8310, DB= 0.2338, CH= 55535.5689
Training epoch 1532, recon_loss:0.770536, zinb_loss:0.638393, cluster_loss:0.151630
Clustering   1532: ASW= 0.8306, DB= 0.2316, CH= 55773.6534
Training epoch 1533, recon_loss:0.770799, zinb_loss:0.638155, cluster_loss:0.151754
Clustering   1533: ASW= 0.8307, DB= 0.2342, CH= 55589.5773
Training epoch 1534, recon_loss:0.770587, zinb_loss:0.638687, cluster_loss:0.151576
Clustering   1534: ASW= 0.8309, DB= 0.2315, CH= 55829.8543
Training epoch 1535, recon_loss:0.770948, zinb_loss:0.638373, cluster_loss:0.151876
Clustering   1535: ASW= 0.8303, DB= 0.2349, CH= 55582.4980
Training epoch 1536, recon_loss:0.770849, zinb_loss:0.639092, cluster_loss:0.151585
Clustering   1536: ASW= 0.8312, DB= 0.2309, CH= 55791.2720
Training epoch 1537, recon_loss:0.771306, zinb_loss:0.638676, cluster_loss:0.152169
Clustering   1537: ASW= 0.8298, DB= 0.2356, CH= 55403.5113
Training epoch 1538, recon_loss:0.771371, zinb_loss:0.639545, cluster_loss:0.151725
Clustering   1538: ASW= 0.8313, DB= 0.2309, CH= 55528.1209
Training epoch 1539, recon_loss:0.771778, zinb_loss:0.638989, cluster_loss:0.152549
Clustering   1539: ASW= 0.8292, DB= 0.2366, CH= 55036.9383
Training epoch 1540, recon_loss:0.771756, zinb_loss:0.639789, cluster_loss:0.151911
Clustering   1540: ASW= 0.8311, DB= 0.2316, CH= 55153.9741
Training epoch 1541, recon_loss:0.772131, zinb_loss:0.639164, cluster_loss:0.152642
Clustering   1541: ASW= 0.8292, DB= 0.2355, CH= 54937.6862
Training epoch 1542, recon_loss:0.771431, zinb_loss:0.639625, cluster_loss:0.151834
Clustering   1542: ASW= 0.8311, DB= 0.2312, CH= 55145.5394
Training epoch 1543, recon_loss:0.771500, zinb_loss:0.639088, cluster_loss:0.152285
Clustering   1543: ASW= 0.8298, DB= 0.2343, CH= 55241.7947
Training epoch 1544, recon_loss:0.770674, zinb_loss:0.639249, cluster_loss:0.151570
Clustering   1544: ASW= 0.8313, DB= 0.2310, CH= 55408.8152
Training epoch 1545, recon_loss:0.770898, zinb_loss:0.638904, cluster_loss:0.151900
Clustering   1545: ASW= 0.8303, DB= 0.2334, CH= 55626.4227
Training epoch 1546, recon_loss:0.770306, zinb_loss:0.638985, cluster_loss:0.151428
Clustering   1546: ASW= 0.8311, DB= 0.2310, CH= 55601.3726
Training epoch 1547, recon_loss:0.770606, zinb_loss:0.638939, cluster_loss:0.151700
Clustering   1547: ASW= 0.8305, DB= 0.2327, CH= 55851.0166
Training epoch 1548, recon_loss:0.770487, zinb_loss:0.638911, cluster_loss:0.151466
Clustering   1548: ASW= 0.8307, DB= 0.2319, CH= 55570.6681
Training epoch 1549, recon_loss:0.771068, zinb_loss:0.639106, cluster_loss:0.151669
Clustering   1549: ASW= 0.8306, DB= 0.2327, CH= 56040.2589
Training epoch 1550, recon_loss:0.771138, zinb_loss:0.638966, cluster_loss:0.151734
Clustering   1550: ASW= 0.8299, DB= 0.2325, CH= 55352.5163
Training epoch 1551, recon_loss:0.771838, zinb_loss:0.639509, cluster_loss:0.151808
Clustering   1551: ASW= 0.8305, DB= 0.2318, CH= 56002.4530
Training epoch 1552, recon_loss:0.772156, zinb_loss:0.639136, cluster_loss:0.152185
Clustering   1552: ASW= 0.8288, DB= 0.2339, CH= 54941.6100
Training epoch 1553, recon_loss:0.772611, zinb_loss:0.639795, cluster_loss:0.152047
Clustering   1553: ASW= 0.8305, DB= 0.2306, CH= 55729.7692
Training epoch 1554, recon_loss:0.772318, zinb_loss:0.639087, cluster_loss:0.152327
Clustering   1554: ASW= 0.8287, DB= 0.2341, CH= 54800.6317
Training epoch 1555, recon_loss:0.772329, zinb_loss:0.639584, cluster_loss:0.151976
Clustering   1555: ASW= 0.8308, DB= 0.2304, CH= 55793.2278
Training epoch 1556, recon_loss:0.771456, zinb_loss:0.638802, cluster_loss:0.152052
Clustering   1556: ASW= 0.8296, DB= 0.2331, CH= 55100.3608
Training epoch 1557, recon_loss:0.771473, zinb_loss:0.639037, cluster_loss:0.151742
Clustering   1557: ASW= 0.8311, DB= 0.2305, CH= 56000.9700
Training epoch 1558, recon_loss:0.770689, zinb_loss:0.638491, cluster_loss:0.151799
Clustering   1558: ASW= 0.8303, DB= 0.2326, CH= 55408.2188
Training epoch 1559, recon_loss:0.770940, zinb_loss:0.638621, cluster_loss:0.151601
Clustering   1559: ASW= 0.8313, DB= 0.2307, CH= 56192.4526
Training epoch 1560, recon_loss:0.770313, zinb_loss:0.638310, cluster_loss:0.151638
Clustering   1560: ASW= 0.8309, DB= 0.2324, CH= 55675.6703
Training epoch 1561, recon_loss:0.770726, zinb_loss:0.638355, cluster_loss:0.151600
Clustering   1561: ASW= 0.8313, DB= 0.2308, CH= 56252.0157
Training epoch 1562, recon_loss:0.770281, zinb_loss:0.638245, cluster_loss:0.151591
Clustering   1562: ASW= 0.8313, DB= 0.2320, CH= 55857.3025
Training epoch 1563, recon_loss:0.770865, zinb_loss:0.638207, cluster_loss:0.151738
Clustering   1563: ASW= 0.8311, DB= 0.2310, CH= 56204.6150
Training epoch 1564, recon_loss:0.770499, zinb_loss:0.638292, cluster_loss:0.151659
Clustering   1564: ASW= 0.8316, DB= 0.2315, CH= 55950.7342
Training epoch 1565, recon_loss:0.771067, zinb_loss:0.638133, cluster_loss:0.151944
Clustering   1565: ASW= 0.8309, DB= 0.2310, CH= 56090.9688
Training epoch 1566, recon_loss:0.770704, zinb_loss:0.638344, cluster_loss:0.151737
Clustering   1566: ASW= 0.8317, DB= 0.2314, CH= 55990.6069
Training epoch 1567, recon_loss:0.771079, zinb_loss:0.638106, cluster_loss:0.152058
Clustering   1567: ASW= 0.8310, DB= 0.2309, CH= 56021.8463
Training epoch 1568, recon_loss:0.770724, zinb_loss:0.638327, cluster_loss:0.151755
Clustering   1568: ASW= 0.8317, DB= 0.2316, CH= 56030.4685
Training epoch 1569, recon_loss:0.771030, zinb_loss:0.638079, cluster_loss:0.152140
Clustering   1569: ASW= 0.8311, DB= 0.2306, CH= 55931.4126
Training epoch 1570, recon_loss:0.770662, zinb_loss:0.638284, cluster_loss:0.151739
Clustering   1570: ASW= 0.8315, DB= 0.2315, CH= 56019.6934
Training epoch 1571, recon_loss:0.770933, zinb_loss:0.638106, cluster_loss:0.152130
Clustering   1571: ASW= 0.8314, DB= 0.2306, CH= 55953.1675
Training epoch 1572, recon_loss:0.770594, zinb_loss:0.638254, cluster_loss:0.151694
Clustering   1572: ASW= 0.8313, DB= 0.2321, CH= 56049.7122
Training epoch 1573, recon_loss:0.770832, zinb_loss:0.638156, cluster_loss:0.152134
Clustering   1573: ASW= 0.8317, DB= 0.2301, CH= 55888.0989
Training epoch 1574, recon_loss:0.770504, zinb_loss:0.638280, cluster_loss:0.151651
Clustering   1574: ASW= 0.8310, DB= 0.2326, CH= 56044.7681
Training epoch 1575, recon_loss:0.770850, zinb_loss:0.638431, cluster_loss:0.152044
Clustering   1575: ASW= 0.8321, DB= 0.2294, CH= 55944.1099
Training epoch 1576, recon_loss:0.770529, zinb_loss:0.638475, cluster_loss:0.151575
Clustering   1576: ASW= 0.8308, DB= 0.2323, CH= 56118.4888
Training epoch 1577, recon_loss:0.770770, zinb_loss:0.638614, cluster_loss:0.152052
Clustering   1577: ASW= 0.8320, DB= 0.2299, CH= 55852.9902
Training epoch 1578, recon_loss:0.770645, zinb_loss:0.638696, cluster_loss:0.151636
Clustering   1578: ASW= 0.8303, DB= 0.2338, CH= 56111.0675
Training epoch 1579, recon_loss:0.771273, zinb_loss:0.639163, cluster_loss:0.152047
Clustering   1579: ASW= 0.8324, DB= 0.2298, CH= 55731.1507
Training epoch 1580, recon_loss:0.771346, zinb_loss:0.639163, cluster_loss:0.151740
Clustering   1580: ASW= 0.8300, DB= 0.2345, CH= 56011.9364
Training epoch 1581, recon_loss:0.771802, zinb_loss:0.639657, cluster_loss:0.152176
Clustering   1581: ASW= 0.8321, DB= 0.2304, CH= 55540.1757
Training epoch 1582, recon_loss:0.772081, zinb_loss:0.639690, cluster_loss:0.152007
Clustering   1582: ASW= 0.8301, DB= 0.2337, CH= 56093.6077
Training epoch 1583, recon_loss:0.772565, zinb_loss:0.640191, cluster_loss:0.152392
Clustering   1583: ASW= 0.8321, DB= 0.2301, CH= 55300.5527
Training epoch 1584, recon_loss:0.772544, zinb_loss:0.639764, cluster_loss:0.152314
Clustering   1584: ASW= 0.8297, DB= 0.2344, CH= 55777.6551
Training epoch 1585, recon_loss:0.772187, zinb_loss:0.639910, cluster_loss:0.152444
Clustering   1585: ASW= 0.8319, DB= 0.2304, CH= 54962.6357
Training epoch 1586, recon_loss:0.772646, zinb_loss:0.639876, cluster_loss:0.152833
Clustering   1586: ASW= 0.8287, DB= 0.2346, CH= 55096.5719
Training epoch 1587, recon_loss:0.774406, zinb_loss:0.640095, cluster_loss:0.153536
Clustering   1587: ASW= 0.8288, DB= 0.2349, CH= 53272.9338
Training epoch 1588, recon_loss:0.772588, zinb_loss:0.638809, cluster_loss:0.152257
Clustering   1588: ASW= 0.8292, DB= 0.2360, CH= 54339.3411
Training epoch 1589, recon_loss:0.771132, zinb_loss:0.638414, cluster_loss:0.152148
Clustering   1589: ASW= 0.8299, DB= 0.2329, CH= 54761.9965
Training epoch 1590, recon_loss:0.771052, zinb_loss:0.638576, cluster_loss:0.151766
Clustering   1590: ASW= 0.8306, DB= 0.2332, CH= 55340.8002
Training epoch 1591, recon_loss:0.770910, zinb_loss:0.638325, cluster_loss:0.152164
Clustering   1591: ASW= 0.8301, DB= 0.2334, CH= 55193.5861
Training epoch 1592, recon_loss:0.770916, zinb_loss:0.638664, cluster_loss:0.151878
Clustering   1592: ASW= 0.8306, DB= 0.2325, CH= 55291.7209
Training epoch 1593, recon_loss:0.771125, zinb_loss:0.638385, cluster_loss:0.152154
Clustering   1593: ASW= 0.8305, DB= 0.2341, CH= 55634.9919
Training epoch 1594, recon_loss:0.771097, zinb_loss:0.638666, cluster_loss:0.152061
Clustering   1594: ASW= 0.8305, DB= 0.2316, CH= 55174.5046
Training epoch 1595, recon_loss:0.771215, zinb_loss:0.638407, cluster_loss:0.152318
Clustering   1595: ASW= 0.8305, DB= 0.2347, CH= 55799.7640
Training epoch 1596, recon_loss:0.771186, zinb_loss:0.638574, cluster_loss:0.152400
Clustering   1596: ASW= 0.8302, DB= 0.2313, CH= 54857.1873
Training epoch 1597, recon_loss:0.771265, zinb_loss:0.638416, cluster_loss:0.152387
Clustering   1597: ASW= 0.8309, DB= 0.2345, CH= 56151.9025
Training epoch 1598, recon_loss:0.771154, zinb_loss:0.638394, cluster_loss:0.152710
Clustering   1598: ASW= 0.8299, DB= 0.2313, CH= 54637.3756
Training epoch 1599, recon_loss:0.770842, zinb_loss:0.638340, cluster_loss:0.152211
Clustering   1599: ASW= 0.8313, DB= 0.2340, CH= 56393.1242
Training epoch 1600, recon_loss:0.770623, zinb_loss:0.638154, cluster_loss:0.152608
Clustering   1600: ASW= 0.8299, DB= 0.2314, CH= 54650.1162
Training epoch 1601, recon_loss:0.770174, zinb_loss:0.638265, cluster_loss:0.151776
Clustering   1601: ASW= 0.8319, DB= 0.2334, CH= 56620.1042
Training epoch 1602, recon_loss:0.769887, zinb_loss:0.637980, cluster_loss:0.152255
Clustering   1602: ASW= 0.8300, DB= 0.2318, CH= 54877.8790
Training epoch 1603, recon_loss:0.769719, zinb_loss:0.638302, cluster_loss:0.151413
Clustering   1603: ASW= 0.8324, DB= 0.2321, CH= 56808.8364
Training epoch 1604, recon_loss:0.769485, zinb_loss:0.637986, cluster_loss:0.152039
Clustering   1604: ASW= 0.8301, DB= 0.2322, CH= 55059.8098
Training epoch 1605, recon_loss:0.769699, zinb_loss:0.638531, cluster_loss:0.151232
Clustering   1605: ASW= 0.8327, DB= 0.2317, CH= 56951.5883
Training epoch 1606, recon_loss:0.769619, zinb_loss:0.638235, cluster_loss:0.152007
Clustering   1606: ASW= 0.8302, DB= 0.2322, CH= 55120.6269
Training epoch 1607, recon_loss:0.770178, zinb_loss:0.638973, cluster_loss:0.151192
Clustering   1607: ASW= 0.8329, DB= 0.2312, CH= 57040.0228
Training epoch 1608, recon_loss:0.770262, zinb_loss:0.638647, cluster_loss:0.152109
Clustering   1608: ASW= 0.8302, DB= 0.2324, CH= 55126.7691
Training epoch 1609, recon_loss:0.770924, zinb_loss:0.639386, cluster_loss:0.151249
Clustering   1609: ASW= 0.8328, DB= 0.2305, CH= 57006.8973
Training epoch 1610, recon_loss:0.770989, zinb_loss:0.638963, cluster_loss:0.152174
Clustering   1610: ASW= 0.8304, DB= 0.2324, CH= 55132.5569
Training epoch 1611, recon_loss:0.771444, zinb_loss:0.639637, cluster_loss:0.151273
Clustering   1611: ASW= 0.8328, DB= 0.2302, CH= 57061.1098
Training epoch 1612, recon_loss:0.771460, zinb_loss:0.639066, cluster_loss:0.152188
Clustering   1612: ASW= 0.8305, DB= 0.2326, CH= 55184.3293
Training epoch 1613, recon_loss:0.771440, zinb_loss:0.639497, cluster_loss:0.151334
Clustering   1613: ASW= 0.8323, DB= 0.2305, CH= 56865.8570
Training epoch 1614, recon_loss:0.771446, zinb_loss:0.638826, cluster_loss:0.152046
Clustering   1614: ASW= 0.8308, DB= 0.2322, CH= 55368.5911
Training epoch 1615, recon_loss:0.771504, zinb_loss:0.639388, cluster_loss:0.151291
Clustering   1615: ASW= 0.8324, DB= 0.2297, CH= 57013.2568
Training epoch 1616, recon_loss:0.770887, zinb_loss:0.638787, cluster_loss:0.151875
Clustering   1616: ASW= 0.8311, DB= 0.2326, CH= 55512.8815
Training epoch 1617, recon_loss:0.770613, zinb_loss:0.639145, cluster_loss:0.151268
Clustering   1617: ASW= 0.8325, DB= 0.2294, CH= 56900.2553
Training epoch 1618, recon_loss:0.770505, zinb_loss:0.638645, cluster_loss:0.151667
Clustering   1618: ASW= 0.8314, DB= 0.2318, CH= 55813.7164
Training epoch 1619, recon_loss:0.770317, zinb_loss:0.638883, cluster_loss:0.151179
Clustering   1619: ASW= 0.8324, DB= 0.2293, CH= 56919.6323
Training epoch 1620, recon_loss:0.770200, zinb_loss:0.638511, cluster_loss:0.151517
Clustering   1620: ASW= 0.8317, DB= 0.2314, CH= 56069.8930
Training epoch 1621, recon_loss:0.770113, zinb_loss:0.638642, cluster_loss:0.151186
Clustering   1621: ASW= 0.8323, DB= 0.2296, CH= 56930.2633
Training epoch 1622, recon_loss:0.770017, zinb_loss:0.638426, cluster_loss:0.151388
Clustering   1622: ASW= 0.8320, DB= 0.2310, CH= 56232.4816
Training epoch 1623, recon_loss:0.769977, zinb_loss:0.638439, cluster_loss:0.151257
Clustering   1623: ASW= 0.8320, DB= 0.2299, CH= 56857.4420
Training epoch 1624, recon_loss:0.769949, zinb_loss:0.638444, cluster_loss:0.151286
Clustering   1624: ASW= 0.8323, DB= 0.2304, CH= 56353.4079
Training epoch 1625, recon_loss:0.770079, zinb_loss:0.638375, cluster_loss:0.151490
Clustering   1625: ASW= 0.8317, DB= 0.2301, CH= 56680.9751
Training epoch 1626, recon_loss:0.770317, zinb_loss:0.638654, cluster_loss:0.151407
Clustering   1626: ASW= 0.8322, DB= 0.2302, CH= 56172.8841
Training epoch 1627, recon_loss:0.770244, zinb_loss:0.638345, cluster_loss:0.151947
Clustering   1627: ASW= 0.8310, DB= 0.2310, CH= 56174.6695
Training epoch 1628, recon_loss:0.770653, zinb_loss:0.638865, cluster_loss:0.151724
Clustering   1628: ASW= 0.8318, DB= 0.2301, CH= 55706.1215
Training epoch 1629, recon_loss:0.770169, zinb_loss:0.638277, cluster_loss:0.152341
Clustering   1629: ASW= 0.8306, DB= 0.2319, CH= 55708.7751
Training epoch 1630, recon_loss:0.770492, zinb_loss:0.638816, cluster_loss:0.151771
Clustering   1630: ASW= 0.8313, DB= 0.2304, CH= 55515.6856
Training epoch 1631, recon_loss:0.770147, zinb_loss:0.638216, cluster_loss:0.152336
Clustering   1631: ASW= 0.8306, DB= 0.2319, CH= 55574.4789
Training epoch 1632, recon_loss:0.770352, zinb_loss:0.638617, cluster_loss:0.151528
Clustering   1632: ASW= 0.8313, DB= 0.2303, CH= 55658.1852
Training epoch 1633, recon_loss:0.770265, zinb_loss:0.638217, cluster_loss:0.152130
Clustering   1633: ASW= 0.8309, DB= 0.2313, CH= 55737.8702
Training epoch 1634, recon_loss:0.770345, zinb_loss:0.638450, cluster_loss:0.151301
Clustering   1634: ASW= 0.8313, DB= 0.2305, CH= 55899.3523
Training epoch 1635, recon_loss:0.770231, zinb_loss:0.638102, cluster_loss:0.151893
Clustering   1635: ASW= 0.8311, DB= 0.2309, CH= 55949.0231
Training epoch 1636, recon_loss:0.770250, zinb_loss:0.638202, cluster_loss:0.151211
Clustering   1636: ASW= 0.8314, DB= 0.2306, CH= 56049.1601
Training epoch 1637, recon_loss:0.770261, zinb_loss:0.638025, cluster_loss:0.151705
Clustering   1637: ASW= 0.8314, DB= 0.2306, CH= 56126.1620
Training epoch 1638, recon_loss:0.770425, zinb_loss:0.638042, cluster_loss:0.151154
Clustering   1638: ASW= 0.8315, DB= 0.2305, CH= 56279.7242
Training epoch 1639, recon_loss:0.770384, zinb_loss:0.637941, cluster_loss:0.151574
Clustering   1639: ASW= 0.8314, DB= 0.2303, CH= 56224.6343
Training epoch 1640, recon_loss:0.770651, zinb_loss:0.637913, cluster_loss:0.151214
Clustering   1640: ASW= 0.8316, DB= 0.2307, CH= 56413.2112
Training epoch 1641, recon_loss:0.770648, zinb_loss:0.638014, cluster_loss:0.151547
Clustering   1641: ASW= 0.8315, DB= 0.2299, CH= 56204.9497
Training epoch 1642, recon_loss:0.771019, zinb_loss:0.637913, cluster_loss:0.151418
Clustering   1642: ASW= 0.8315, DB= 0.2307, CH= 56456.4862
Training epoch 1643, recon_loss:0.771226, zinb_loss:0.638253, cluster_loss:0.151690
Clustering   1643: ASW= 0.8315, DB= 0.2292, CH= 56001.4068
Training epoch 1644, recon_loss:0.771596, zinb_loss:0.637969, cluster_loss:0.151842
Clustering   1644: ASW= 0.8311, DB= 0.2320, CH= 56307.7916
Training epoch 1645, recon_loss:0.771955, zinb_loss:0.638502, cluster_loss:0.152037
Clustering   1645: ASW= 0.8314, DB= 0.2301, CH= 55545.5936
Training epoch 1646, recon_loss:0.771684, zinb_loss:0.637909, cluster_loss:0.152070
Clustering   1646: ASW= 0.8310, DB= 0.2332, CH= 56178.3783
Training epoch 1647, recon_loss:0.771474, zinb_loss:0.638323, cluster_loss:0.151933
Clustering   1647: ASW= 0.8318, DB= 0.2298, CH= 55575.0934
Training epoch 1648, recon_loss:0.770580, zinb_loss:0.637706, cluster_loss:0.151750
Clustering   1648: ASW= 0.8315, DB= 0.2328, CH= 56385.2826
Training epoch 1649, recon_loss:0.770398, zinb_loss:0.637975, cluster_loss:0.151566
Clustering   1649: ASW= 0.8322, DB= 0.2284, CH= 55975.2145
Training epoch 1650, recon_loss:0.769755, zinb_loss:0.637630, cluster_loss:0.151469
Clustering   1650: ASW= 0.8320, DB= 0.2322, CH= 56680.0193
Training epoch 1651, recon_loss:0.769968, zinb_loss:0.637812, cluster_loss:0.151480
Clustering   1651: ASW= 0.8323, DB= 0.2286, CH= 56212.9997
Training epoch 1652, recon_loss:0.769633, zinb_loss:0.637684, cluster_loss:0.151403
Clustering   1652: ASW= 0.8324, DB= 0.2319, CH= 56886.3414
Training epoch 1653, recon_loss:0.770028, zinb_loss:0.637795, cluster_loss:0.151606
Clustering   1653: ASW= 0.8322, DB= 0.2288, CH= 56259.5148
Training epoch 1654, recon_loss:0.769829, zinb_loss:0.637825, cluster_loss:0.151461
Clustering   1654: ASW= 0.8325, DB= 0.2321, CH= 57001.7429
Training epoch 1655, recon_loss:0.770307, zinb_loss:0.637875, cluster_loss:0.151868
Clustering   1655: ASW= 0.8320, DB= 0.2295, CH= 56193.8020
Training epoch 1656, recon_loss:0.770046, zinb_loss:0.638021, cluster_loss:0.151562
Clustering   1656: ASW= 0.8324, DB= 0.2320, CH= 56950.8587
Training epoch 1657, recon_loss:0.770651, zinb_loss:0.638036, cluster_loss:0.152069
Clustering   1657: ASW= 0.8320, DB= 0.2303, CH= 56129.7716
Training epoch 1658, recon_loss:0.770301, zinb_loss:0.638252, cluster_loss:0.151610
Clustering   1658: ASW= 0.8321, DB= 0.2320, CH= 56744.8793
Training epoch 1659, recon_loss:0.770926, zinb_loss:0.638196, cluster_loss:0.152136
Clustering   1659: ASW= 0.8320, DB= 0.2303, CH= 56090.4722
Training epoch 1660, recon_loss:0.770471, zinb_loss:0.638473, cluster_loss:0.151543
Clustering   1660: ASW= 0.8319, DB= 0.2315, CH= 56618.5035
Training epoch 1661, recon_loss:0.770879, zinb_loss:0.638309, cluster_loss:0.152063
Clustering   1661: ASW= 0.8321, DB= 0.2303, CH= 56100.3900
Training epoch 1662, recon_loss:0.770461, zinb_loss:0.638506, cluster_loss:0.151464
Clustering   1662: ASW= 0.8316, DB= 0.2314, CH= 56370.6700
Training epoch 1663, recon_loss:0.770582, zinb_loss:0.638233, cluster_loss:0.151930
Clustering   1663: ASW= 0.8321, DB= 0.2301, CH= 56113.8545
Training epoch 1664, recon_loss:0.770511, zinb_loss:0.638428, cluster_loss:0.151274
Clustering   1664: ASW= 0.8319, DB= 0.2315, CH= 56462.8819
Training epoch 1665, recon_loss:0.770450, zinb_loss:0.638075, cluster_loss:0.151736
Clustering   1665: ASW= 0.8322, DB= 0.2300, CH= 56292.1795
Training epoch 1666, recon_loss:0.770594, zinb_loss:0.638202, cluster_loss:0.151203
Clustering   1666: ASW= 0.8320, DB= 0.2313, CH= 56472.2717
Training epoch 1667, recon_loss:0.770641, zinb_loss:0.637881, cluster_loss:0.151679
Clustering   1667: ASW= 0.8321, DB= 0.2299, CH= 56329.6259
Training epoch 1668, recon_loss:0.770840, zinb_loss:0.638069, cluster_loss:0.151160
Clustering   1668: ASW= 0.8324, DB= 0.2307, CH= 56644.0672
Training epoch 1669, recon_loss:0.770923, zinb_loss:0.637721, cluster_loss:0.151718
Clustering   1669: ASW= 0.8319, DB= 0.2298, CH= 56333.1850
Training epoch 1670, recon_loss:0.770975, zinb_loss:0.637929, cluster_loss:0.151236
Clustering   1670: ASW= 0.8326, DB= 0.2303, CH= 56670.7962
Training epoch 1671, recon_loss:0.770966, zinb_loss:0.637559, cluster_loss:0.151800
Clustering   1671: ASW= 0.8316, DB= 0.2301, CH= 56242.8785
Training epoch 1672, recon_loss:0.771193, zinb_loss:0.637922, cluster_loss:0.151271
Clustering   1672: ASW= 0.8332, DB= 0.2299, CH= 56861.3801
Training epoch 1673, recon_loss:0.770859, zinb_loss:0.637494, cluster_loss:0.151857
Clustering   1673: ASW= 0.8313, DB= 0.2308, CH= 56236.5120
Training epoch 1674, recon_loss:0.771239, zinb_loss:0.637926, cluster_loss:0.151389
Clustering   1674: ASW= 0.8333, DB= 0.2299, CH= 56789.3649
Training epoch 1675, recon_loss:0.770702, zinb_loss:0.637491, cluster_loss:0.151864
Clustering   1675: ASW= 0.8309, DB= 0.2310, CH= 56188.6124
Training epoch 1676, recon_loss:0.771117, zinb_loss:0.637972, cluster_loss:0.151389
Clustering   1676: ASW= 0.8337, DB= 0.2294, CH= 56937.3040
Training epoch 1677, recon_loss:0.770281, zinb_loss:0.637484, cluster_loss:0.151749
Clustering   1677: ASW= 0.8309, DB= 0.2313, CH= 56328.4641
Training epoch 1678, recon_loss:0.770687, zinb_loss:0.637886, cluster_loss:0.151421
Clustering   1678: ASW= 0.8336, DB= 0.2296, CH= 56861.3095
Training epoch 1679, recon_loss:0.770022, zinb_loss:0.637497, cluster_loss:0.151592
Clustering   1679: ASW= 0.8310, DB= 0.2308, CH= 56434.3613
Training epoch 1680, recon_loss:0.770383, zinb_loss:0.637826, cluster_loss:0.151392
Clustering   1680: ASW= 0.8337, DB= 0.2292, CH= 56966.7895
Training epoch 1681, recon_loss:0.769784, zinb_loss:0.637552, cluster_loss:0.151421
Clustering   1681: ASW= 0.8312, DB= 0.2306, CH= 56619.6128
Training epoch 1682, recon_loss:0.770288, zinb_loss:0.637766, cluster_loss:0.151541
Clustering   1682: ASW= 0.8335, DB= 0.2295, CH= 56924.8402
Training epoch 1683, recon_loss:0.770226, zinb_loss:0.637787, cluster_loss:0.151453
Clustering   1683: ASW= 0.8313, DB= 0.2303, CH= 56495.9768
Training epoch 1684, recon_loss:0.771132, zinb_loss:0.637815, cluster_loss:0.152191
Clustering   1684: ASW= 0.8328, DB= 0.2306, CH= 56423.9918
Training epoch 1685, recon_loss:0.771994, zinb_loss:0.638307, cluster_loss:0.152156
Clustering   1685: ASW= 0.8307, DB= 0.2324, CH= 55563.3971
Training epoch 1686, recon_loss:0.772044, zinb_loss:0.637759, cluster_loss:0.152744
Clustering   1686: ASW= 0.8322, DB= 0.2312, CH= 55814.7295
Training epoch 1687, recon_loss:0.771631, zinb_loss:0.638233, cluster_loss:0.152089
Clustering   1687: ASW= 0.8310, DB= 0.2320, CH= 55516.9378
Training epoch 1688, recon_loss:0.770501, zinb_loss:0.637587, cluster_loss:0.152068
Clustering   1688: ASW= 0.8326, DB= 0.2315, CH= 55958.3464
Training epoch 1689, recon_loss:0.770112, zinb_loss:0.638003, cluster_loss:0.151271
Clustering   1689: ASW= 0.8319, DB= 0.2301, CH= 56400.0686
Training epoch 1690, recon_loss:0.770101, zinb_loss:0.637936, cluster_loss:0.151650
Clustering   1690: ASW= 0.8329, DB= 0.2309, CH= 56344.1191
Training epoch 1691, recon_loss:0.770264, zinb_loss:0.638606, cluster_loss:0.151116
Clustering   1691: ASW= 0.8323, DB= 0.2291, CH= 56820.6809
Training epoch 1692, recon_loss:0.770479, zinb_loss:0.638903, cluster_loss:0.151597
Clustering   1692: ASW= 0.8330, DB= 0.2303, CH= 56578.8421
Training epoch 1693, recon_loss:0.770542, zinb_loss:0.639426, cluster_loss:0.151177
Clustering   1693: ASW= 0.8326, DB= 0.2289, CH= 57008.1041
Training epoch 1694, recon_loss:0.770972, zinb_loss:0.639729, cluster_loss:0.151617
Clustering   1694: ASW= 0.8332, DB= 0.2300, CH= 56694.0766
Training epoch 1695, recon_loss:0.770528, zinb_loss:0.639676, cluster_loss:0.151270
Clustering   1695: ASW= 0.8324, DB= 0.2298, CH= 57126.2269
Training epoch 1696, recon_loss:0.771007, zinb_loss:0.639874, cluster_loss:0.151655
Clustering   1696: ASW= 0.8331, DB= 0.2300, CH= 56673.3355
Training epoch 1697, recon_loss:0.770333, zinb_loss:0.639599, cluster_loss:0.151356
Clustering   1697: ASW= 0.8321, DB= 0.2306, CH= 57051.2279
Training epoch 1698, recon_loss:0.770806, zinb_loss:0.639687, cluster_loss:0.151559
Clustering   1698: ASW= 0.8332, DB= 0.2294, CH= 56633.1917
Training epoch 1699, recon_loss:0.769994, zinb_loss:0.639262, cluster_loss:0.151346
Clustering   1699: ASW= 0.8321, DB= 0.2307, CH= 57105.5004
Training epoch 1700, recon_loss:0.770634, zinb_loss:0.639445, cluster_loss:0.151503
Clustering   1700: ASW= 0.8332, DB= 0.2289, CH= 56669.0357
Training epoch 1701, recon_loss:0.770062, zinb_loss:0.639138, cluster_loss:0.151367
Clustering   1701: ASW= 0.8320, DB= 0.2313, CH= 56996.3163
Training epoch 1702, recon_loss:0.770829, zinb_loss:0.639356, cluster_loss:0.151424
Clustering   1702: ASW= 0.8332, DB= 0.2287, CH= 56650.1569
Training epoch 1703, recon_loss:0.769805, zinb_loss:0.638908, cluster_loss:0.151425
Clustering   1703: ASW= 0.8321, DB= 0.2312, CH= 57078.2940
Training epoch 1704, recon_loss:0.770250, zinb_loss:0.639028, cluster_loss:0.151342
Clustering   1704: ASW= 0.8334, DB= 0.2282, CH= 56793.4144
Training epoch 1705, recon_loss:0.769636, zinb_loss:0.638806, cluster_loss:0.151362
Clustering   1705: ASW= 0.8324, DB= 0.2308, CH= 57100.0732
Training epoch 1706, recon_loss:0.769985, zinb_loss:0.638849, cluster_loss:0.151314
Clustering   1706: ASW= 0.8331, DB= 0.2282, CH= 56880.8331
Training epoch 1707, recon_loss:0.769330, zinb_loss:0.638541, cluster_loss:0.151332
Clustering   1707: ASW= 0.8326, DB= 0.2304, CH= 57130.8785
Training epoch 1708, recon_loss:0.769784, zinb_loss:0.638581, cluster_loss:0.151314
Clustering   1708: ASW= 0.8331, DB= 0.2280, CH= 57031.5683
Training epoch 1709, recon_loss:0.769406, zinb_loss:0.638501, cluster_loss:0.151261
Clustering   1709: ASW= 0.8329, DB= 0.2300, CH= 57198.2714
Training epoch 1710, recon_loss:0.769880, zinb_loss:0.638460, cluster_loss:0.151363
Clustering   1710: ASW= 0.8329, DB= 0.2280, CH= 57084.8855
Training epoch 1711, recon_loss:0.769460, zinb_loss:0.638385, cluster_loss:0.151275
Clustering   1711: ASW= 0.8332, DB= 0.2294, CH= 57246.5715
Training epoch 1712, recon_loss:0.770049, zinb_loss:0.638273, cluster_loss:0.151533
Clustering   1712: ASW= 0.8326, DB= 0.2282, CH= 57143.1718
Training epoch 1713, recon_loss:0.769705, zinb_loss:0.638414, cluster_loss:0.151364
Clustering   1713: ASW= 0.8334, DB= 0.2291, CH= 57171.6516
Training epoch 1714, recon_loss:0.770517, zinb_loss:0.638179, cluster_loss:0.151825
Clustering   1714: ASW= 0.8321, DB= 0.2291, CH= 57043.0790
Training epoch 1715, recon_loss:0.770015, zinb_loss:0.638460, cluster_loss:0.151515
Clustering   1715: ASW= 0.8334, DB= 0.2290, CH= 56924.0429
Training epoch 1716, recon_loss:0.770772, zinb_loss:0.638005, cluster_loss:0.152181
Clustering   1716: ASW= 0.8314, DB= 0.2302, CH= 56686.8663
Training epoch 1717, recon_loss:0.770111, zinb_loss:0.638551, cluster_loss:0.151551
Clustering   1717: ASW= 0.8334, DB= 0.2287, CH= 56620.7630
Training epoch 1718, recon_loss:0.770507, zinb_loss:0.637865, cluster_loss:0.152153
Clustering   1718: ASW= 0.8311, DB= 0.2310, CH= 56495.2593
Training epoch 1719, recon_loss:0.769865, zinb_loss:0.638334, cluster_loss:0.151459
Clustering   1719: ASW= 0.8329, DB= 0.2287, CH= 56317.1874
Training epoch 1720, recon_loss:0.769964, zinb_loss:0.637633, cluster_loss:0.151938
Clustering   1720: ASW= 0.8311, DB= 0.2311, CH= 56394.1188
Training epoch 1721, recon_loss:0.769569, zinb_loss:0.638262, cluster_loss:0.151122
Clustering   1721: ASW= 0.8332, DB= 0.2280, CH= 56629.8850
Training epoch 1722, recon_loss:0.769718, zinb_loss:0.637625, cluster_loss:0.151770
Clustering   1722: ASW= 0.8311, DB= 0.2314, CH= 56326.3005
Training epoch 1723, recon_loss:0.769609, zinb_loss:0.638222, cluster_loss:0.150998
Clustering   1723: ASW= 0.8331, DB= 0.2283, CH= 56805.4043
Training epoch 1724, recon_loss:0.769947, zinb_loss:0.637663, cluster_loss:0.151817
Clustering   1724: ASW= 0.8311, DB= 0.2311, CH= 56187.3206
Training epoch 1725, recon_loss:0.770364, zinb_loss:0.638448, cluster_loss:0.150989
Clustering   1725: ASW= 0.8332, DB= 0.2280, CH= 57065.2750
Training epoch 1726, recon_loss:0.770563, zinb_loss:0.637837, cluster_loss:0.151957
Clustering   1726: ASW= 0.8312, DB= 0.2313, CH= 56024.2940
Training epoch 1727, recon_loss:0.770891, zinb_loss:0.638546, cluster_loss:0.151130
Clustering   1727: ASW= 0.8330, DB= 0.2278, CH= 57181.2366
Training epoch 1728, recon_loss:0.770853, zinb_loss:0.637892, cluster_loss:0.152091
Clustering   1728: ASW= 0.8314, DB= 0.2312, CH= 55919.7538
Training epoch 1729, recon_loss:0.770997, zinb_loss:0.638440, cluster_loss:0.151259
Clustering   1729: ASW= 0.8331, DB= 0.2281, CH= 57250.8287
Training epoch 1730, recon_loss:0.770641, zinb_loss:0.637790, cluster_loss:0.151974
Clustering   1730: ASW= 0.8318, DB= 0.2308, CH= 56059.5386
Training epoch 1731, recon_loss:0.770615, zinb_loss:0.638202, cluster_loss:0.151227
Clustering   1731: ASW= 0.8332, DB= 0.2284, CH= 57414.6606
Training epoch 1732, recon_loss:0.770219, zinb_loss:0.637669, cluster_loss:0.151714
Clustering   1732: ASW= 0.8324, DB= 0.2305, CH= 56335.8564
Training epoch 1733, recon_loss:0.770168, zinb_loss:0.637949, cluster_loss:0.151188
Clustering   1733: ASW= 0.8333, DB= 0.2281, CH= 57458.7569
Training epoch 1734, recon_loss:0.770043, zinb_loss:0.637600, cluster_loss:0.151509
Clustering   1734: ASW= 0.8327, DB= 0.2304, CH= 56593.9155
Training epoch 1735, recon_loss:0.770049, zinb_loss:0.637762, cluster_loss:0.151293
Clustering   1735: ASW= 0.8332, DB= 0.2284, CH= 57320.9731
Training epoch 1736, recon_loss:0.770272, zinb_loss:0.637587, cluster_loss:0.151511
Clustering   1736: ASW= 0.8328, DB= 0.2308, CH= 56621.0243
Training epoch 1737, recon_loss:0.770246, zinb_loss:0.637596, cluster_loss:0.151601
Clustering   1737: ASW= 0.8329, DB= 0.2288, CH= 56922.6867
Training epoch 1738, recon_loss:0.770538, zinb_loss:0.637534, cluster_loss:0.151515
Clustering   1738: ASW= 0.8326, DB= 0.2308, CH= 56589.5566
Training epoch 1739, recon_loss:0.770084, zinb_loss:0.637317, cluster_loss:0.151801
Clustering   1739: ASW= 0.8328, DB= 0.2293, CH= 56611.3928
Training epoch 1740, recon_loss:0.770415, zinb_loss:0.637355, cluster_loss:0.151493
Clustering   1740: ASW= 0.8325, DB= 0.2309, CH= 56695.3959
Training epoch 1741, recon_loss:0.769763, zinb_loss:0.637174, cluster_loss:0.151845
Clustering   1741: ASW= 0.8325, DB= 0.2303, CH= 56309.4346
Training epoch 1742, recon_loss:0.770074, zinb_loss:0.637317, cluster_loss:0.151378
Clustering   1742: ASW= 0.8324, DB= 0.2310, CH= 56820.0197
Training epoch 1743, recon_loss:0.770198, zinb_loss:0.637345, cluster_loss:0.152173
Clustering   1743: ASW= 0.8328, DB= 0.2294, CH= 56339.2180
Training epoch 1744, recon_loss:0.770368, zinb_loss:0.637496, cluster_loss:0.151252
Clustering   1744: ASW= 0.8327, DB= 0.2304, CH= 57002.2047
Training epoch 1745, recon_loss:0.769823, zinb_loss:0.637283, cluster_loss:0.151761
Clustering   1745: ASW= 0.8331, DB= 0.2289, CH= 56564.1329
Training epoch 1746, recon_loss:0.770033, zinb_loss:0.637492, cluster_loss:0.151111
Clustering   1746: ASW= 0.8330, DB= 0.2296, CH= 57157.3011
Training epoch 1747, recon_loss:0.769821, zinb_loss:0.637243, cluster_loss:0.151610
Clustering   1747: ASW= 0.8331, DB= 0.2298, CH= 56690.4776
Training epoch 1748, recon_loss:0.770299, zinb_loss:0.637612, cluster_loss:0.151100
Clustering   1748: ASW= 0.8330, DB= 0.2299, CH= 57131.9893
Training epoch 1749, recon_loss:0.770294, zinb_loss:0.637496, cluster_loss:0.151671
Clustering   1749: ASW= 0.8331, DB= 0.2295, CH= 56774.1517
Training epoch 1750, recon_loss:0.770533, zinb_loss:0.637789, cluster_loss:0.151096
Clustering   1750: ASW= 0.8331, DB= 0.2288, CH= 57116.1055
Training epoch 1751, recon_loss:0.770181, zinb_loss:0.637480, cluster_loss:0.151518
Clustering   1751: ASW= 0.8332, DB= 0.2303, CH= 56962.0872
Training epoch 1752, recon_loss:0.770406, zinb_loss:0.637840, cluster_loss:0.151025
Clustering   1752: ASW= 0.8335, DB= 0.2282, CH= 57255.2126
Training epoch 1753, recon_loss:0.770021, zinb_loss:0.637445, cluster_loss:0.151429
Clustering   1753: ASW= 0.8332, DB= 0.2302, CH= 57098.0949
Training epoch 1754, recon_loss:0.770175, zinb_loss:0.637786, cluster_loss:0.151080
Clustering   1754: ASW= 0.8334, DB= 0.2281, CH= 57189.4197
Training epoch 1755, recon_loss:0.769785, zinb_loss:0.637417, cluster_loss:0.151466
Clustering   1755: ASW= 0.8332, DB= 0.2310, CH= 57184.8633
Training epoch 1756, recon_loss:0.770161, zinb_loss:0.637993, cluster_loss:0.151084
Clustering   1756: ASW= 0.8340, DB= 0.2275, CH= 57250.2176
Training epoch 1757, recon_loss:0.769760, zinb_loss:0.637576, cluster_loss:0.151561
Clustering   1757: ASW= 0.8328, DB= 0.2314, CH= 57070.2410
Training epoch 1758, recon_loss:0.770159, zinb_loss:0.638231, cluster_loss:0.151252
Clustering   1758: ASW= 0.8340, DB= 0.2270, CH= 57232.0298
Training epoch 1759, recon_loss:0.769833, zinb_loss:0.637822, cluster_loss:0.151714
Clustering   1759: ASW= 0.8326, DB= 0.2323, CH= 57053.3032
Training epoch 1760, recon_loss:0.770333, zinb_loss:0.638551, cluster_loss:0.151379
Clustering   1760: ASW= 0.8341, DB= 0.2268, CH= 57234.4912
Training epoch 1761, recon_loss:0.769898, zinb_loss:0.638173, cluster_loss:0.151759
Clustering   1761: ASW= 0.8323, DB= 0.2324, CH= 56976.8936
Training epoch 1762, recon_loss:0.770391, zinb_loss:0.639049, cluster_loss:0.151395
Clustering   1762: ASW= 0.8343, DB= 0.2267, CH= 57299.4520
Training epoch 1763, recon_loss:0.769949, zinb_loss:0.638796, cluster_loss:0.151667
Clustering   1763: ASW= 0.8323, DB= 0.2325, CH= 56973.2918
Training epoch 1764, recon_loss:0.770345, zinb_loss:0.639431, cluster_loss:0.151456
Clustering   1764: ASW= 0.8340, DB= 0.2266, CH= 57388.6577
Training epoch 1765, recon_loss:0.770261, zinb_loss:0.639231, cluster_loss:0.151697
Clustering   1765: ASW= 0.8320, DB= 0.2329, CH= 56778.8489
Training epoch 1766, recon_loss:0.770710, zinb_loss:0.639908, cluster_loss:0.151413
Clustering   1766: ASW= 0.8341, DB= 0.2269, CH= 57494.5579
Training epoch 1767, recon_loss:0.770630, zinb_loss:0.639695, cluster_loss:0.151603
Clustering   1767: ASW= 0.8322, DB= 0.2324, CH= 56739.6303
Training epoch 1768, recon_loss:0.770541, zinb_loss:0.639980, cluster_loss:0.151394
Clustering   1768: ASW= 0.8338, DB= 0.2271, CH= 57634.3328
Training epoch 1769, recon_loss:0.770442, zinb_loss:0.639657, cluster_loss:0.151602
Clustering   1769: ASW= 0.8320, DB= 0.2320, CH= 56620.7073
Training epoch 1770, recon_loss:0.770532, zinb_loss:0.640203, cluster_loss:0.151285
Clustering   1770: ASW= 0.8343, DB= 0.2272, CH= 57750.3631
Training epoch 1771, recon_loss:0.770319, zinb_loss:0.639763, cluster_loss:0.151466
Clustering   1771: ASW= 0.8322, DB= 0.2316, CH= 56602.7831
Training epoch 1772, recon_loss:0.770424, zinb_loss:0.640182, cluster_loss:0.151231
Clustering   1772: ASW= 0.8341, DB= 0.2275, CH= 58029.9758
Training epoch 1773, recon_loss:0.770311, zinb_loss:0.639737, cluster_loss:0.151441
Clustering   1773: ASW= 0.8327, DB= 0.2306, CH= 56778.3773
Training epoch 1774, recon_loss:0.770355, zinb_loss:0.640149, cluster_loss:0.151353
Clustering   1774: ASW= 0.8341, DB= 0.2275, CH= 57996.2578
Training epoch 1775, recon_loss:0.770441, zinb_loss:0.639817, cluster_loss:0.151614
Clustering   1775: ASW= 0.8319, DB= 0.2310, CH= 56476.7423
Training epoch 1776, recon_loss:0.770646, zinb_loss:0.640112, cluster_loss:0.151457
Clustering   1776: ASW= 0.8341, DB= 0.2278, CH= 57699.5953
Training epoch 1777, recon_loss:0.770432, zinb_loss:0.639699, cluster_loss:0.151544
Clustering   1777: ASW= 0.8330, DB= 0.2292, CH= 57002.5827
Training epoch 1778, recon_loss:0.770038, zinb_loss:0.639744, cluster_loss:0.151588
Clustering   1778: ASW= 0.8336, DB= 0.2285, CH= 57637.0496
Training epoch 1779, recon_loss:0.770440, zinb_loss:0.639646, cluster_loss:0.151640
Clustering   1779: ASW= 0.8331, DB= 0.2285, CH= 56877.1449
Training epoch 1780, recon_loss:0.770247, zinb_loss:0.639570, cluster_loss:0.151700
Clustering   1780: ASW= 0.8335, DB= 0.2289, CH= 57609.6320
Training epoch 1781, recon_loss:0.770928, zinb_loss:0.639619, cluster_loss:0.151887
Clustering   1781: ASW= 0.8328, DB= 0.2293, CH= 56657.7491
Training epoch 1782, recon_loss:0.770621, zinb_loss:0.639222, cluster_loss:0.152202
Clustering   1782: ASW= 0.8321, DB= 0.2299, CH= 56966.8947
Training epoch 1783, recon_loss:0.770900, zinb_loss:0.639294, cluster_loss:0.151900
Clustering   1783: ASW= 0.8328, DB= 0.2285, CH= 56514.4549
Training epoch 1784, recon_loss:0.770164, zinb_loss:0.638671, cluster_loss:0.151982
Clustering   1784: ASW= 0.8327, DB= 0.2290, CH= 57147.4709
Training epoch 1785, recon_loss:0.769959, zinb_loss:0.638587, cluster_loss:0.151582
Clustering   1785: ASW= 0.8330, DB= 0.2290, CH= 56745.4120
Training epoch 1786, recon_loss:0.769380, zinb_loss:0.638118, cluster_loss:0.151437
Clustering   1786: ASW= 0.8332, DB= 0.2287, CH= 57358.9526
Training epoch 1787, recon_loss:0.769625, zinb_loss:0.638470, cluster_loss:0.151796
Clustering   1787: ASW= 0.8322, DB= 0.2295, CH= 56728.0998
Training epoch 1788, recon_loss:0.770239, zinb_loss:0.638301, cluster_loss:0.151735
Clustering   1788: ASW= 0.8324, DB= 0.2307, CH= 56012.7127
Training epoch 1789, recon_loss:0.769760, zinb_loss:0.637721, cluster_loss:0.151679
Clustering   1789: ASW= 0.8326, DB= 0.2295, CH= 56793.4254
Training epoch 1790, recon_loss:0.769888, zinb_loss:0.638009, cluster_loss:0.151400
Clustering   1790: ASW= 0.8335, DB= 0.2290, CH= 56807.9043
Training epoch 1791, recon_loss:0.769793, zinb_loss:0.637625, cluster_loss:0.151874
Clustering   1791: ASW= 0.8322, DB= 0.2299, CH= 56572.6451
Training epoch 1792, recon_loss:0.770219, zinb_loss:0.638021, cluster_loss:0.151619
Clustering   1792: ASW= 0.8338, DB= 0.2296, CH= 56804.5054
Training epoch 1793, recon_loss:0.769529, zinb_loss:0.637267, cluster_loss:0.151472
Clustering   1793: ASW= 0.8316, DB= 0.2316, CH= 56491.5108
Training epoch 1794, recon_loss:0.769446, zinb_loss:0.637440, cluster_loss:0.151020
Clustering   1794: ASW= 0.8333, DB= 0.2289, CH= 57083.6928
Training epoch 1795, recon_loss:0.769803, zinb_loss:0.637147, cluster_loss:0.151593
Clustering   1795: ASW= 0.8320, DB= 0.2318, CH= 56638.8992
Training epoch 1796, recon_loss:0.770086, zinb_loss:0.637549, cluster_loss:0.151097
Clustering   1796: ASW= 0.8333, DB= 0.2288, CH= 57081.3641
Training epoch 1797, recon_loss:0.769904, zinb_loss:0.637227, cluster_loss:0.151778
Clustering   1797: ASW= 0.8326, DB= 0.2309, CH= 56842.8822
Training epoch 1798, recon_loss:0.770386, zinb_loss:0.637652, cluster_loss:0.151235
Clustering   1798: ASW= 0.8337, DB= 0.2288, CH= 57250.7113
Training epoch 1799, recon_loss:0.770231, zinb_loss:0.637427, cluster_loss:0.152110
Clustering   1799: ASW= 0.8324, DB= 0.2304, CH= 56774.4181
Training epoch 1800, recon_loss:0.770621, zinb_loss:0.637746, cluster_loss:0.151341
Clustering   1800: ASW= 0.8340, DB= 0.2283, CH= 57261.9369
Training epoch 1801, recon_loss:0.770169, zinb_loss:0.637437, cluster_loss:0.152122
Clustering   1801: ASW= 0.8322, DB= 0.2303, CH= 56776.4431
Training epoch 1802, recon_loss:0.770400, zinb_loss:0.637633, cluster_loss:0.151238
Clustering   1802: ASW= 0.8343, DB= 0.2282, CH= 57392.0723
Training epoch 1803, recon_loss:0.769730, zinb_loss:0.637262, cluster_loss:0.151719
Clustering   1803: ASW= 0.8324, DB= 0.2296, CH= 57002.6752
Training epoch 1804, recon_loss:0.770026, zinb_loss:0.637443, cluster_loss:0.151069
Clustering   1804: ASW= 0.8346, DB= 0.2280, CH= 57555.6880
Training epoch 1805, recon_loss:0.769463, zinb_loss:0.637117, cluster_loss:0.151334
Clustering   1805: ASW= 0.8326, DB= 0.2294, CH= 57332.5751
Training epoch 1806, recon_loss:0.769946, zinb_loss:0.637345, cluster_loss:0.150998
Clustering   1806: ASW= 0.8346, DB= 0.2280, CH= 57608.0179
Training epoch 1807, recon_loss:0.769655, zinb_loss:0.637184, cluster_loss:0.151168
Clustering   1807: ASW= 0.8328, DB= 0.2289, CH= 57516.0318
Training epoch 1808, recon_loss:0.770328, zinb_loss:0.637464, cluster_loss:0.151061
Clustering   1808: ASW= 0.8344, DB= 0.2282, CH= 57555.6134
Training epoch 1809, recon_loss:0.770149, zinb_loss:0.637425, cluster_loss:0.151157
Clustering   1809: ASW= 0.8328, DB= 0.2288, CH= 57626.0272
Training epoch 1810, recon_loss:0.770809, zinb_loss:0.637655, cluster_loss:0.151276
Clustering   1810: ASW= 0.8340, DB= 0.2289, CH= 57348.9826
Training epoch 1811, recon_loss:0.770629, zinb_loss:0.637756, cluster_loss:0.151249
Clustering   1811: ASW= 0.8328, DB= 0.2281, CH= 57578.9874
Training epoch 1812, recon_loss:0.770942, zinb_loss:0.637795, cluster_loss:0.151525
Clustering   1812: ASW= 0.8336, DB= 0.2297, CH= 57048.2373
Training epoch 1813, recon_loss:0.770591, zinb_loss:0.638002, cluster_loss:0.151296
Clustering   1813: ASW= 0.8329, DB= 0.2281, CH= 57558.5392
Training epoch 1814, recon_loss:0.770477, zinb_loss:0.637800, cluster_loss:0.151606
Clustering   1814: ASW= 0.8334, DB= 0.2295, CH= 56827.4333
Training epoch 1815, recon_loss:0.770106, zinb_loss:0.638139, cluster_loss:0.151148
Clustering   1815: ASW= 0.8333, DB= 0.2284, CH= 57752.6969
Training epoch 1816, recon_loss:0.769861, zinb_loss:0.637810, cluster_loss:0.151534
Clustering   1816: ASW= 0.8335, DB= 0.2292, CH= 56828.4266
Training epoch 1817, recon_loss:0.769705, zinb_loss:0.638238, cluster_loss:0.150946
Clustering   1817: ASW= 0.8340, DB= 0.2279, CH= 58099.7173
Training epoch 1818, recon_loss:0.769549, zinb_loss:0.637877, cluster_loss:0.151508
Clustering   1818: ASW= 0.8335, DB= 0.2291, CH= 56873.1990
Training epoch 1819, recon_loss:0.769553, zinb_loss:0.638346, cluster_loss:0.150848
Clustering   1819: ASW= 0.8344, DB= 0.2279, CH= 58398.4806
Training epoch 1820, recon_loss:0.769627, zinb_loss:0.637922, cluster_loss:0.151640
Clustering   1820: ASW= 0.8333, DB= 0.2291, CH= 56766.2153
Training epoch 1821, recon_loss:0.769624, zinb_loss:0.638292, cluster_loss:0.150871
Clustering   1821: ASW= 0.8348, DB= 0.2280, CH= 58584.1731
Training epoch 1822, recon_loss:0.769789, zinb_loss:0.637743, cluster_loss:0.151807
Clustering   1822: ASW= 0.8332, DB= 0.2286, CH= 56668.2015
Training epoch 1823, recon_loss:0.769491, zinb_loss:0.638081, cluster_loss:0.150918
Clustering   1823: ASW= 0.8350, DB= 0.2277, CH= 58692.6577
Training epoch 1824, recon_loss:0.769534, zinb_loss:0.637487, cluster_loss:0.151923
Clustering   1824: ASW= 0.8330, DB= 0.2284, CH= 56547.8546
Training epoch 1825, recon_loss:0.769130, zinb_loss:0.637792, cluster_loss:0.150936
Clustering   1825: ASW= 0.8351, DB= 0.2275, CH= 58702.8390
Training epoch 1826, recon_loss:0.769094, zinb_loss:0.637199, cluster_loss:0.151884
Clustering   1826: ASW= 0.8330, DB= 0.2283, CH= 56573.7753
Training epoch 1827, recon_loss:0.768816, zinb_loss:0.637528, cluster_loss:0.150956
Clustering   1827: ASW= 0.8351, DB= 0.2276, CH= 58659.6510
Training epoch 1828, recon_loss:0.768897, zinb_loss:0.636998, cluster_loss:0.151783
Clustering   1828: ASW= 0.8330, DB= 0.2281, CH= 56648.8920
Training epoch 1829, recon_loss:0.768791, zinb_loss:0.637352, cluster_loss:0.150965
Clustering   1829: ASW= 0.8352, DB= 0.2276, CH= 58688.0276
Training epoch 1830, recon_loss:0.768976, zinb_loss:0.636864, cluster_loss:0.151695
Clustering   1830: ASW= 0.8331, DB= 0.2281, CH= 56765.6304
Training epoch 1831, recon_loss:0.768952, zinb_loss:0.637204, cluster_loss:0.151050
Clustering   1831: ASW= 0.8351, DB= 0.2276, CH= 58584.6865
Training epoch 1832, recon_loss:0.769167, zinb_loss:0.636809, cluster_loss:0.151620
Clustering   1832: ASW= 0.8333, DB= 0.2279, CH= 56854.8939
Training epoch 1833, recon_loss:0.769083, zinb_loss:0.637113, cluster_loss:0.151117
Clustering   1833: ASW= 0.8349, DB= 0.2278, CH= 58531.9392
Training epoch 1834, recon_loss:0.769327, zinb_loss:0.636848, cluster_loss:0.151534
Clustering   1834: ASW= 0.8335, DB= 0.2278, CH= 56901.0920
Training epoch 1835, recon_loss:0.769088, zinb_loss:0.637022, cluster_loss:0.151219
Clustering   1835: ASW= 0.8346, DB= 0.2283, CH= 58382.8635
Training epoch 1836, recon_loss:0.769471, zinb_loss:0.636946, cluster_loss:0.151504
Clustering   1836: ASW= 0.8337, DB= 0.2273, CH= 56751.1283
Training epoch 1837, recon_loss:0.769169, zinb_loss:0.636934, cluster_loss:0.151389
Clustering   1837: ASW= 0.8341, DB= 0.2293, CH= 58148.7729
Training epoch 1838, recon_loss:0.769668, zinb_loss:0.637042, cluster_loss:0.151546
Clustering   1838: ASW= 0.8338, DB= 0.2284, CH= 56546.2786
Training epoch 1839, recon_loss:0.769155, zinb_loss:0.636737, cluster_loss:0.151460
Clustering   1839: ASW= 0.8337, DB= 0.2300, CH= 57874.7191
Training epoch 1840, recon_loss:0.769416, zinb_loss:0.636952, cluster_loss:0.151300
Clustering   1840: ASW= 0.8341, DB= 0.2275, CH= 56760.4241
Training epoch 1841, recon_loss:0.768838, zinb_loss:0.636557, cluster_loss:0.151284
Clustering   1841: ASW= 0.8333, DB= 0.2301, CH= 57638.2748
Training epoch 1842, recon_loss:0.768852, zinb_loss:0.636856, cluster_loss:0.150984
Clustering   1842: ASW= 0.8344, DB= 0.2271, CH= 57108.2309
Training epoch 1843, recon_loss:0.768589, zinb_loss:0.636625, cluster_loss:0.151145
Clustering   1843: ASW= 0.8334, DB= 0.2301, CH= 57782.7571
Training epoch 1844, recon_loss:0.768844, zinb_loss:0.637070, cluster_loss:0.150928
Clustering   1844: ASW= 0.8345, DB= 0.2271, CH= 57273.2021
Training epoch 1845, recon_loss:0.768759, zinb_loss:0.636960, cluster_loss:0.151193
Clustering   1845: ASW= 0.8334, DB= 0.2302, CH= 57790.2959
Training epoch 1846, recon_loss:0.769053, zinb_loss:0.637479, cluster_loss:0.151021
Clustering   1846: ASW= 0.8343, DB= 0.2265, CH= 57304.7055
Training epoch 1847, recon_loss:0.768928, zinb_loss:0.637469, cluster_loss:0.151304
Clustering   1847: ASW= 0.8334, DB= 0.2305, CH= 57777.7847
Training epoch 1848, recon_loss:0.769206, zinb_loss:0.637887, cluster_loss:0.151187
Clustering   1848: ASW= 0.8340, DB= 0.2269, CH= 57350.2003
Training epoch 1849, recon_loss:0.769162, zinb_loss:0.638012, cluster_loss:0.151345
Clustering   1849: ASW= 0.8336, DB= 0.2306, CH= 57755.0674
Training epoch 1850, recon_loss:0.769796, zinb_loss:0.638226, cluster_loss:0.151376
Clustering   1850: ASW= 0.8336, DB= 0.2277, CH= 57436.4788
Training epoch 1851, recon_loss:0.770242, zinb_loss:0.638581, cluster_loss:0.151400
Clustering   1851: ASW= 0.8340, DB= 0.2298, CH= 57696.0330
Training epoch 1852, recon_loss:0.770748, zinb_loss:0.638542, cluster_loss:0.151603
Clustering   1852: ASW= 0.8333, DB= 0.2286, CH= 57508.9618
Training epoch 1853, recon_loss:0.770692, zinb_loss:0.639021, cluster_loss:0.151513
Clustering   1853: ASW= 0.8342, DB= 0.2284, CH= 57385.3486
Training epoch 1854, recon_loss:0.770391, zinb_loss:0.638633, cluster_loss:0.151707
Clustering   1854: ASW= 0.8331, DB= 0.2287, CH= 57438.2441
Training epoch 1855, recon_loss:0.770239, zinb_loss:0.639024, cluster_loss:0.151446
Clustering   1855: ASW= 0.8343, DB= 0.2278, CH= 57115.5095
Training epoch 1856, recon_loss:0.769859, zinb_loss:0.638352, cluster_loss:0.151636
Clustering   1856: ASW= 0.8332, DB= 0.2294, CH= 57460.4348
Training epoch 1857, recon_loss:0.769911, zinb_loss:0.638656, cluster_loss:0.151315
Clustering   1857: ASW= 0.8343, DB= 0.2273, CH= 57194.1458
Training epoch 1858, recon_loss:0.769246, zinb_loss:0.637891, cluster_loss:0.151470
Clustering   1858: ASW= 0.8336, DB= 0.2292, CH= 57556.0447
Training epoch 1859, recon_loss:0.769144, zinb_loss:0.638173, cluster_loss:0.151046
Clustering   1859: ASW= 0.8344, DB= 0.2265, CH= 57495.7504
Training epoch 1860, recon_loss:0.768723, zinb_loss:0.637583, cluster_loss:0.151277
Clustering   1860: ASW= 0.8340, DB= 0.2292, CH= 57706.0064
Training epoch 1861, recon_loss:0.768940, zinb_loss:0.637911, cluster_loss:0.150900
Clustering   1861: ASW= 0.8345, DB= 0.2264, CH= 57764.6823
Training epoch 1862, recon_loss:0.768603, zinb_loss:0.637460, cluster_loss:0.151204
Clustering   1862: ASW= 0.8342, DB= 0.2290, CH= 57789.4737
Training epoch 1863, recon_loss:0.769142, zinb_loss:0.637825, cluster_loss:0.150919
Clustering   1863: ASW= 0.8344, DB= 0.2255, CH= 57931.8225
Training epoch 1864, recon_loss:0.768689, zinb_loss:0.637477, cluster_loss:0.151216
Clustering   1864: ASW= 0.8345, DB= 0.2290, CH= 57844.7758
Training epoch 1865, recon_loss:0.769411, zinb_loss:0.637801, cluster_loss:0.151007
Clustering   1865: ASW= 0.8343, DB= 0.2259, CH= 57988.0656
Training epoch 1866, recon_loss:0.768848, zinb_loss:0.637625, cluster_loss:0.151221
Clustering   1866: ASW= 0.8348, DB= 0.2288, CH= 57937.7945
Training epoch 1867, recon_loss:0.769739, zinb_loss:0.637848, cluster_loss:0.151192
Clustering   1867: ASW= 0.8340, DB= 0.2256, CH= 58075.0533
Training epoch 1868, recon_loss:0.769078, zinb_loss:0.637803, cluster_loss:0.151265
Clustering   1868: ASW= 0.8352, DB= 0.2285, CH= 58057.1561
Training epoch 1869, recon_loss:0.769967, zinb_loss:0.637900, cluster_loss:0.151458
Clustering   1869: ASW= 0.8338, DB= 0.2263, CH= 58007.5293
Training epoch 1870, recon_loss:0.769353, zinb_loss:0.638154, cluster_loss:0.151307
Clustering   1870: ASW= 0.8353, DB= 0.2278, CH= 57935.3167
Training epoch 1871, recon_loss:0.770041, zinb_loss:0.638029, cluster_loss:0.151724
Clustering   1871: ASW= 0.8335, DB= 0.2269, CH= 57808.9607
Training epoch 1872, recon_loss:0.769574, zinb_loss:0.638508, cluster_loss:0.151386
Clustering   1872: ASW= 0.8348, DB= 0.2276, CH= 57581.0448
Training epoch 1873, recon_loss:0.770116, zinb_loss:0.638154, cluster_loss:0.151969
Clustering   1873: ASW= 0.8332, DB= 0.2274, CH= 57426.4847
Training epoch 1874, recon_loss:0.769822, zinb_loss:0.638970, cluster_loss:0.151447
Clustering   1874: ASW= 0.8348, DB= 0.2276, CH= 57528.0434
Training epoch 1875, recon_loss:0.770381, zinb_loss:0.638312, cluster_loss:0.152162
Clustering   1875: ASW= 0.8327, DB= 0.2303, CH= 56815.9054
Training epoch 1876, recon_loss:0.769683, zinb_loss:0.639021, cluster_loss:0.151487
Clustering   1876: ASW= 0.8333, DB= 0.2305, CH= 57059.6606
Training epoch 1877, recon_loss:0.771052, zinb_loss:0.638785, cluster_loss:0.152958
Clustering   1877: ASW= 0.8322, DB= 0.2281, CH= 56177.8559
Training epoch 1878, recon_loss:0.770320, zinb_loss:0.639217, cluster_loss:0.151445
Clustering   1878: ASW= 0.8337, DB= 0.2297, CH= 57046.4740
Training epoch 1879, recon_loss:0.770510, zinb_loss:0.638672, cluster_loss:0.152240
Clustering   1879: ASW= 0.8330, DB= 0.2270, CH= 56694.2280
Training epoch 1880, recon_loss:0.769889, zinb_loss:0.639014, cluster_loss:0.151023
Clustering   1880: ASW= 0.8341, DB= 0.2285, CH= 57548.6577
Training epoch 1881, recon_loss:0.770245, zinb_loss:0.638985, cluster_loss:0.151494
Clustering   1881: ASW= 0.8342, DB= 0.2263, CH= 57538.3953
Training epoch 1882, recon_loss:0.769861, zinb_loss:0.639180, cluster_loss:0.150864
Clustering   1882: ASW= 0.8343, DB= 0.2289, CH= 57905.8923
Training epoch 1883, recon_loss:0.770359, zinb_loss:0.639495, cluster_loss:0.151303
Clustering   1883: ASW= 0.8347, DB= 0.2265, CH= 57862.8488
Training epoch 1884, recon_loss:0.770375, zinb_loss:0.639652, cluster_loss:0.151002
Clustering   1884: ASW= 0.8342, DB= 0.2288, CH= 57988.6702
Training epoch 1885, recon_loss:0.771170, zinb_loss:0.640054, cluster_loss:0.151274
Clustering   1885: ASW= 0.8348, DB= 0.2258, CH= 57915.5406
Training epoch 1886, recon_loss:0.771230, zinb_loss:0.640061, cluster_loss:0.151215
Clustering   1886: ASW= 0.8339, DB= 0.2290, CH= 58140.0550
Training epoch 1887, recon_loss:0.771156, zinb_loss:0.640337, cluster_loss:0.151313
Clustering   1887: ASW= 0.8350, DB= 0.2263, CH= 57403.3491
Training epoch 1888, recon_loss:0.769877, zinb_loss:0.639244, cluster_loss:0.151215
Clustering   1888: ASW= 0.8335, DB= 0.2295, CH= 57803.0566
Training epoch 1889, recon_loss:0.769620, zinb_loss:0.639305, cluster_loss:0.151075
Clustering   1889: ASW= 0.8349, DB= 0.2262, CH= 57712.3329
Training epoch 1890, recon_loss:0.768785, zinb_loss:0.638573, cluster_loss:0.151003
Clustering   1890: ASW= 0.8338, DB= 0.2284, CH= 57952.7402
Training epoch 1891, recon_loss:0.768828, zinb_loss:0.638643, cluster_loss:0.150870
Clustering   1891: ASW= 0.8355, DB= 0.2257, CH= 58019.6368
Training epoch 1892, recon_loss:0.768418, zinb_loss:0.638177, cluster_loss:0.150806
Clustering   1892: ASW= 0.8342, DB= 0.2281, CH= 58169.3590
Training epoch 1893, recon_loss:0.768573, zinb_loss:0.638353, cluster_loss:0.150780
Clustering   1893: ASW= 0.8354, DB= 0.2253, CH= 58321.1122
Training epoch 1894, recon_loss:0.768252, zinb_loss:0.638179, cluster_loss:0.150635
Clustering   1894: ASW= 0.8344, DB= 0.2272, CH= 58341.9631
Training epoch 1895, recon_loss:0.768608, zinb_loss:0.638188, cluster_loss:0.150848
Clustering   1895: ASW= 0.8355, DB= 0.2256, CH= 58438.5488
Training epoch 1896, recon_loss:0.768623, zinb_loss:0.638151, cluster_loss:0.150663
Clustering   1896: ASW= 0.8339, DB= 0.2281, CH= 58166.6390
Training epoch 1897, recon_loss:0.768828, zinb_loss:0.638090, cluster_loss:0.150815
Clustering   1897: ASW= 0.8357, DB= 0.2267, CH= 58420.1429
Training epoch 1898, recon_loss:0.769114, zinb_loss:0.638411, cluster_loss:0.150746
Clustering   1898: ASW= 0.8344, DB= 0.2261, CH= 58284.9541
Training epoch 1899, recon_loss:0.769860, zinb_loss:0.638481, cluster_loss:0.151499
Clustering   1899: ASW= 0.8352, DB= 0.2283, CH= 58301.3694
Training epoch 1900, recon_loss:0.771110, zinb_loss:0.639330, cluster_loss:0.151623
Clustering   1900: ASW= 0.8334, DB= 0.2271, CH= 57283.2700
Training epoch 1901, recon_loss:0.771246, zinb_loss:0.638918, cluster_loss:0.152406
Clustering   1901: ASW= 0.8346, DB= 0.2297, CH= 57920.2612
Training epoch 1902, recon_loss:0.771318, zinb_loss:0.638888, cluster_loss:0.152250
Clustering   1902: ASW= 0.8316, DB= 0.2321, CH= 55923.5794
Training epoch 1903, recon_loss:0.771595, zinb_loss:0.637806, cluster_loss:0.153064
Clustering   1903: ASW= 0.8322, DB= 0.2309, CH= 57122.7869
Training epoch 1904, recon_loss:0.770531, zinb_loss:0.638521, cluster_loss:0.152605
Clustering   1904: ASW= 0.8322, DB= 0.2291, CH= 55735.5701
Training epoch 1905, recon_loss:0.769562, zinb_loss:0.638074, cluster_loss:0.151690
Clustering   1905: ASW= 0.8328, DB= 0.2313, CH= 56507.4032
Training epoch 1906, recon_loss:0.768438, zinb_loss:0.637894, cluster_loss:0.150965
Clustering   1906: ASW= 0.8331, DB= 0.2281, CH= 57168.1096
Training epoch 1907, recon_loss:0.768838, zinb_loss:0.637536, cluster_loss:0.151542
Clustering   1907: ASW= 0.8337, DB= 0.2293, CH= 57473.0762
Training epoch 1908, recon_loss:0.769733, zinb_loss:0.638150, cluster_loss:0.151365
Clustering   1908: ASW= 0.8338, DB= 0.2276, CH= 57178.5670
Training epoch 1909, recon_loss:0.771277, zinb_loss:0.637744, cluster_loss:0.152642
Clustering   1909: ASW= 0.8321, DB= 0.2298, CH= 56918.8256
Training epoch 1910, recon_loss:0.771203, zinb_loss:0.638284, cluster_loss:0.151649
Clustering   1910: ASW= 0.8347, DB= 0.2276, CH= 56877.9455
Training epoch 1911, recon_loss:0.769809, zinb_loss:0.637315, cluster_loss:0.151994
Clustering   1911: ASW= 0.8317, DB= 0.2299, CH= 56634.2748
Training epoch 1912, recon_loss:0.769400, zinb_loss:0.637639, cluster_loss:0.151039
Clustering   1912: ASW= 0.8348, DB= 0.2271, CH= 57437.9563
Training epoch 1913, recon_loss:0.768396, zinb_loss:0.636904, cluster_loss:0.151298
Clustering   1913: ASW= 0.8331, DB= 0.2281, CH= 57239.4991
Training epoch 1914, recon_loss:0.768542, zinb_loss:0.637246, cluster_loss:0.150704
Clustering   1914: ASW= 0.8354, DB= 0.2261, CH= 58041.3084
Training epoch 1915, recon_loss:0.767969, zinb_loss:0.636753, cluster_loss:0.151022
Clustering   1915: ASW= 0.8337, DB= 0.2275, CH= 57672.1955
Training epoch 1916, recon_loss:0.768326, zinb_loss:0.637119, cluster_loss:0.150627
Clustering   1916: ASW= 0.8356, DB= 0.2259, CH= 58308.3585
Training epoch 1917, recon_loss:0.768204, zinb_loss:0.636830, cluster_loss:0.150910
Clustering   1917: ASW= 0.8340, DB= 0.2271, CH= 57923.3822
Training epoch 1918, recon_loss:0.768757, zinb_loss:0.637211, cluster_loss:0.150618
Clustering   1918: ASW= 0.8357, DB= 0.2262, CH= 58479.7139
Training epoch 1919, recon_loss:0.768940, zinb_loss:0.637086, cluster_loss:0.150870
Clustering   1919: ASW= 0.8343, DB= 0.2271, CH= 58173.3248
Training epoch 1920, recon_loss:0.769651, zinb_loss:0.637442, cluster_loss:0.150733
Clustering   1920: ASW= 0.8356, DB= 0.2267, CH= 58464.6462
Training epoch 1921, recon_loss:0.769700, zinb_loss:0.637450, cluster_loss:0.150884
Clustering   1921: ASW= 0.8345, DB= 0.2268, CH= 58339.9083
Training epoch 1922, recon_loss:0.770076, zinb_loss:0.637649, cluster_loss:0.150840
Clustering   1922: ASW= 0.8354, DB= 0.2274, CH= 58373.8267
Training epoch 1923, recon_loss:0.769739, zinb_loss:0.637666, cluster_loss:0.150839
Clustering   1923: ASW= 0.8347, DB= 0.2269, CH= 58463.2502
Training epoch 1924, recon_loss:0.769951, zinb_loss:0.637678, cluster_loss:0.150865
Clustering   1924: ASW= 0.8352, DB= 0.2274, CH= 58340.8963
Training epoch 1925, recon_loss:0.769473, zinb_loss:0.637668, cluster_loss:0.150759
Clustering   1925: ASW= 0.8349, DB= 0.2267, CH= 58534.8114
Training epoch 1926, recon_loss:0.769647, zinb_loss:0.637560, cluster_loss:0.150851
Clustering   1926: ASW= 0.8350, DB= 0.2277, CH= 58389.8548
Training epoch 1927, recon_loss:0.769146, zinb_loss:0.637557, cluster_loss:0.150686
Clustering   1927: ASW= 0.8351, DB= 0.2264, CH= 58565.5004
Training epoch 1928, recon_loss:0.769357, zinb_loss:0.637387, cluster_loss:0.150837
Clustering   1928: ASW= 0.8347, DB= 0.2277, CH= 58439.4814
Training epoch 1929, recon_loss:0.768900, zinb_loss:0.637467, cluster_loss:0.150606
Clustering   1929: ASW= 0.8353, DB= 0.2262, CH= 58606.3940
Training epoch 1930, recon_loss:0.769195, zinb_loss:0.637258, cluster_loss:0.150918
Clustering   1930: ASW= 0.8344, DB= 0.2282, CH= 58383.9437
Training epoch 1931, recon_loss:0.768864, zinb_loss:0.637498, cluster_loss:0.150567
Clustering   1931: ASW= 0.8354, DB= 0.2258, CH= 58533.0763
Training epoch 1932, recon_loss:0.769345, zinb_loss:0.637183, cluster_loss:0.151275
Clustering   1932: ASW= 0.8337, DB= 0.2290, CH= 57940.4366
Training epoch 1933, recon_loss:0.769448, zinb_loss:0.637685, cluster_loss:0.150879
Clustering   1933: ASW= 0.8350, DB= 0.2265, CH= 57884.4448
Training epoch 1934, recon_loss:0.769667, zinb_loss:0.637067, cluster_loss:0.151962
Clustering   1934: ASW= 0.8329, DB= 0.2303, CH= 57138.2561
Training epoch 1935, recon_loss:0.769983, zinb_loss:0.637742, cluster_loss:0.151414
Clustering   1935: ASW= 0.8341, DB= 0.2278, CH= 56855.0262
Training epoch 1936, recon_loss:0.768838, zinb_loss:0.636645, cluster_loss:0.151873
Clustering   1936: ASW= 0.8331, DB= 0.2301, CH= 57009.0463
Training epoch 1937, recon_loss:0.768502, zinb_loss:0.637271, cluster_loss:0.150768
Clustering   1937: ASW= 0.8350, DB= 0.2267, CH= 57790.5302
Training epoch 1938, recon_loss:0.768035, zinb_loss:0.636544, cluster_loss:0.151435
Clustering   1938: ASW= 0.8341, DB= 0.2289, CH= 57499.0628
Training epoch 1939, recon_loss:0.768166, zinb_loss:0.637109, cluster_loss:0.150602
Clustering   1939: ASW= 0.8350, DB= 0.2263, CH= 58189.1817
Training epoch 1940, recon_loss:0.768120, zinb_loss:0.636658, cluster_loss:0.151448
Clustering   1940: ASW= 0.8345, DB= 0.2281, CH= 57666.8782
Training epoch 1941, recon_loss:0.768190, zinb_loss:0.637130, cluster_loss:0.150593
Clustering   1941: ASW= 0.8351, DB= 0.2259, CH= 58368.7032
Training epoch 1942, recon_loss:0.768077, zinb_loss:0.636696, cluster_loss:0.151205
Clustering   1942: ASW= 0.8350, DB= 0.2276, CH= 58024.6285
Training epoch 1943, recon_loss:0.768108, zinb_loss:0.637025, cluster_loss:0.150518
Clustering   1943: ASW= 0.8352, DB= 0.2254, CH= 58539.7395
Training epoch 1944, recon_loss:0.768417, zinb_loss:0.636841, cluster_loss:0.151025
Clustering   1944: ASW= 0.8353, DB= 0.2274, CH= 58317.0514
Training epoch 1945, recon_loss:0.768635, zinb_loss:0.637237, cluster_loss:0.150503
Clustering   1945: ASW= 0.8353, DB= 0.2262, CH= 58623.3216
Training epoch 1946, recon_loss:0.768946, zinb_loss:0.637434, cluster_loss:0.150854
Clustering   1946: ASW= 0.8358, DB= 0.2258, CH= 58771.9008
Training epoch 1947, recon_loss:0.769082, zinb_loss:0.637665, cluster_loss:0.150659
Clustering   1947: ASW= 0.8349, DB= 0.2265, CH= 58557.4373
Training epoch 1948, recon_loss:0.769596, zinb_loss:0.638126, cluster_loss:0.150810
Clustering   1948: ASW= 0.8357, DB= 0.2255, CH= 58876.0789
Training epoch 1949, recon_loss:0.769739, zinb_loss:0.638175, cluster_loss:0.150893
Clustering   1949: ASW= 0.8345, DB= 0.2277, CH= 58295.7341
Training epoch 1950, recon_loss:0.770230, zinb_loss:0.638775, cluster_loss:0.150852
Clustering   1950: ASW= 0.8353, DB= 0.2252, CH= 58793.8559
Training epoch 1951, recon_loss:0.770341, zinb_loss:0.638566, cluster_loss:0.151180
Clustering   1951: ASW= 0.8338, DB= 0.2294, CH= 57830.1228
Training epoch 1952, recon_loss:0.770628, zinb_loss:0.639164, cluster_loss:0.150896
Clustering   1952: ASW= 0.8351, DB= 0.2245, CH= 58759.0652
Training epoch 1953, recon_loss:0.770226, zinb_loss:0.638675, cluster_loss:0.151439
Clustering   1953: ASW= 0.8336, DB= 0.2303, CH= 57562.2314
Training epoch 1954, recon_loss:0.770253, zinb_loss:0.639192, cluster_loss:0.150933
Clustering   1954: ASW= 0.8349, DB= 0.2248, CH= 58777.1035
Training epoch 1955, recon_loss:0.770004, zinb_loss:0.638594, cluster_loss:0.151637
Clustering   1955: ASW= 0.8335, DB= 0.2306, CH= 57339.8506
Training epoch 1956, recon_loss:0.770061, zinb_loss:0.639223, cluster_loss:0.150979
Clustering   1956: ASW= 0.8348, DB= 0.2255, CH= 58774.4743
Training epoch 1957, recon_loss:0.769850, zinb_loss:0.638702, cluster_loss:0.151656
Clustering   1957: ASW= 0.8339, DB= 0.2302, CH= 57388.6280
Training epoch 1958, recon_loss:0.769705, zinb_loss:0.639285, cluster_loss:0.150950
Clustering   1958: ASW= 0.8349, DB= 0.2252, CH= 58868.6603
Training epoch 1959, recon_loss:0.769485, zinb_loss:0.638779, cluster_loss:0.151531
Clustering   1959: ASW= 0.8344, DB= 0.2296, CH= 57587.7969
Training epoch 1960, recon_loss:0.769251, zinb_loss:0.639165, cluster_loss:0.150893
Clustering   1960: ASW= 0.8349, DB= 0.2254, CH= 58966.3313
Training epoch 1961, recon_loss:0.769107, zinb_loss:0.638671, cluster_loss:0.151382
Clustering   1961: ASW= 0.8349, DB= 0.2288, CH= 57816.4580
Training epoch 1962, recon_loss:0.768931, zinb_loss:0.638873, cluster_loss:0.150876
Clustering   1962: ASW= 0.8349, DB= 0.2253, CH= 59086.9159
Training epoch 1963, recon_loss:0.768864, zinb_loss:0.638486, cluster_loss:0.151271
Clustering   1963: ASW= 0.8354, DB= 0.2281, CH= 58028.2366
Training epoch 1964, recon_loss:0.768827, zinb_loss:0.638589, cluster_loss:0.150983
Clustering   1964: ASW= 0.8347, DB= 0.2255, CH= 59105.2638
Training epoch 1965, recon_loss:0.768868, zinb_loss:0.638321, cluster_loss:0.151234
Clustering   1965: ASW= 0.8357, DB= 0.2273, CH= 58079.1630
Training epoch 1966, recon_loss:0.769073, zinb_loss:0.638275, cluster_loss:0.151289
Clustering   1966: ASW= 0.8343, DB= 0.2264, CH= 58850.4577
Training epoch 1967, recon_loss:0.769323, zinb_loss:0.638193, cluster_loss:0.151389
Clustering   1967: ASW= 0.8354, DB= 0.2272, CH= 57514.3187
Training epoch 1968, recon_loss:0.769329, zinb_loss:0.637766, cluster_loss:0.151686
Clustering   1968: ASW= 0.8337, DB= 0.2279, CH= 58342.7523
Training epoch 1969, recon_loss:0.769399, zinb_loss:0.637743, cluster_loss:0.151545
Clustering   1969: ASW= 0.8349, DB= 0.2274, CH= 56975.8918
Training epoch 1970, recon_loss:0.768877, zinb_loss:0.637227, cluster_loss:0.151441
Clustering   1970: ASW= 0.8343, DB= 0.2266, CH= 58345.5725
Training epoch 1971, recon_loss:0.768982, zinb_loss:0.637519, cluster_loss:0.151008
Clustering   1971: ASW= 0.8354, DB= 0.2271, CH= 57649.7366
Training epoch 1972, recon_loss:0.768708, zinb_loss:0.637044, cluster_loss:0.151429
Clustering   1972: ASW= 0.8340, DB= 0.2276, CH= 58177.2214
Training epoch 1973, recon_loss:0.768233, zinb_loss:0.637078, cluster_loss:0.150718
Clustering   1973: ASW= 0.8350, DB= 0.2264, CH= 57787.2610
Training epoch 1974, recon_loss:0.767982, zinb_loss:0.636650, cluster_loss:0.151035
Clustering   1974: ASW= 0.8348, DB= 0.2260, CH= 58412.4888
Training epoch 1975, recon_loss:0.768030, zinb_loss:0.636830, cluster_loss:0.150470
Clustering   1975: ASW= 0.8352, DB= 0.2265, CH= 58306.6470
Training epoch 1976, recon_loss:0.768113, zinb_loss:0.636543, cluster_loss:0.151014
Clustering   1976: ASW= 0.8351, DB= 0.2256, CH= 58390.4302
Training epoch 1977, recon_loss:0.768544, zinb_loss:0.636857, cluster_loss:0.150472
Clustering   1977: ASW= 0.8352, DB= 0.2262, CH= 58619.3071
Training epoch 1978, recon_loss:0.768970, zinb_loss:0.636646, cluster_loss:0.151316
Clustering   1978: ASW= 0.8352, DB= 0.2255, CH= 58123.3548
Training epoch 1979, recon_loss:0.769354, zinb_loss:0.637115, cluster_loss:0.150693
Clustering   1979: ASW= 0.8350, DB= 0.2269, CH= 58811.6559
Training epoch 1980, recon_loss:0.769724, zinb_loss:0.636973, cluster_loss:0.151797
Clustering   1980: ASW= 0.8351, DB= 0.2253, CH= 57710.9823
Training epoch 1981, recon_loss:0.769637, zinb_loss:0.637460, cluster_loss:0.150914
Clustering   1981: ASW= 0.8349, DB= 0.2273, CH= 58934.2546
Training epoch 1982, recon_loss:0.769869, zinb_loss:0.637328, cluster_loss:0.152082
Clustering   1982: ASW= 0.8350, DB= 0.2260, CH= 57427.7765
Training epoch 1983, recon_loss:0.769195, zinb_loss:0.637654, cluster_loss:0.150925
Clustering   1983: ASW= 0.8351, DB= 0.2274, CH= 58991.0786
Training epoch 1984, recon_loss:0.769311, zinb_loss:0.637486, cluster_loss:0.151933
Clustering   1984: ASW= 0.8352, DB= 0.2260, CH= 57544.3600
Training epoch 1985, recon_loss:0.768646, zinb_loss:0.637767, cluster_loss:0.150808
Clustering   1985: ASW= 0.8353, DB= 0.2273, CH= 59076.0323
Training epoch 1986, recon_loss:0.768776, zinb_loss:0.637717, cluster_loss:0.151531
Clustering   1986: ASW= 0.8357, DB= 0.2253, CH= 57931.4493
Training epoch 1987, recon_loss:0.768227, zinb_loss:0.637892, cluster_loss:0.150613
Clustering   1987: ASW= 0.8355, DB= 0.2271, CH= 59236.2225
Training epoch 1988, recon_loss:0.768627, zinb_loss:0.638033, cluster_loss:0.151187
Clustering   1988: ASW= 0.8361, DB= 0.2248, CH= 58292.1086
Training epoch 1989, recon_loss:0.768340, zinb_loss:0.638237, cluster_loss:0.150560
Clustering   1989: ASW= 0.8354, DB= 0.2273, CH= 59283.7958
Training epoch 1990, recon_loss:0.769171, zinb_loss:0.638558, cluster_loss:0.150972
Clustering   1990: ASW= 0.8365, DB= 0.2245, CH= 58624.7474
Training epoch 1991, recon_loss:0.768784, zinb_loss:0.638496, cluster_loss:0.150656
Clustering   1991: ASW= 0.8353, DB= 0.2274, CH= 59176.4936
Training epoch 1992, recon_loss:0.769866, zinb_loss:0.638848, cluster_loss:0.150976
Clustering   1992: ASW= 0.8367, DB= 0.2238, CH= 58882.8603
Training epoch 1993, recon_loss:0.769482, zinb_loss:0.638755, cluster_loss:0.150743
Clustering   1993: ASW= 0.8351, DB= 0.2280, CH= 59055.9768
Training epoch 1994, recon_loss:0.770182, zinb_loss:0.639064, cluster_loss:0.150861
Clustering   1994: ASW= 0.8368, DB= 0.2241, CH= 58971.7132
Training epoch 1995, recon_loss:0.769485, zinb_loss:0.638650, cluster_loss:0.150787
Clustering   1995: ASW= 0.8352, DB= 0.2273, CH= 58983.8484
Training epoch 1996, recon_loss:0.770352, zinb_loss:0.638888, cluster_loss:0.150945
Clustering   1996: ASW= 0.8368, DB= 0.2240, CH= 59127.6146
Training epoch 1997, recon_loss:0.769486, zinb_loss:0.638490, cluster_loss:0.150750
Clustering   1997: ASW= 0.8350, DB= 0.2276, CH= 58808.2613
Training epoch 1998, recon_loss:0.770200, zinb_loss:0.638635, cluster_loss:0.150786
Clustering   1998: ASW= 0.8367, DB= 0.2239, CH= 59205.3270
Training epoch 1999, recon_loss:0.769249, zinb_loss:0.638136, cluster_loss:0.150793
Clustering   1999: ASW= 0.8350, DB= 0.2275, CH= 58725.9285
Training epoch 2000, recon_loss:0.769908, zinb_loss:0.638326, cluster_loss:0.150852
Clustering   2000: ASW= 0.8367, DB= 0.2243, CH= 59218.0401
Final Result : ASW= 0.8367, DB= 0.2243, CH= 59218.0401
</pre></div></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, zhouzeming.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>